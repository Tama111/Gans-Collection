{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7262f4fc",
   "metadata": {},
   "source": [
    "# Attention GAN\n",
    "\n",
    "This is an attempt to re-implement the paper Attention GAN\n",
    "\n",
    "Paper: https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/taki0112/AttnGAN-Tensorflow\n",
    "* https://github.com/taoxugit/AttnGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cbb6109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cf676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding), (padding, padding)\n",
    "        elif isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            if isinstance(padding[0], tuple) | isinstance(padding[0], list):\n",
    "                self.padding = (padding[0][0], padding[0][1]), (padding[1][0], padding[1][1])\n",
    "            elif isinstance(padding[0], int):\n",
    "                self.padding = (padding[0], padding[0]), (padding[1], padding[1])\n",
    "            else:\n",
    "                raise Exception('invalid padding')\n",
    "            \n",
    "        else:\n",
    "            raise Exception('invalid padding')\n",
    "            \n",
    "    def call(self, x):\n",
    "        return tf.pad(x, ((0, 0), self.padding[0], self.padding[1], (0, 0)), mode = 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3659c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.matmul(inputs, self.W), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6452fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        \n",
    "        if isinstance(padding, str):\n",
    "            if padding.upper() in ['SAME', 'VALID']:\n",
    "                self.padding = padding.upper()\n",
    "            else:\n",
    "                raise Exception('Invalid padding')\n",
    "        elif isinstance(padding, int) | isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            self.padding = ReflectPadding2D(padding)\n",
    "        \n",
    "        else:\n",
    "            raise Exception('Invalid padding')\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, 1, 1, self.filters), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if isinstance(self.padding, str):\n",
    "            return tf.add(tf.nn.conv2d(inputs, self.W, self.strides, self.padding), self.B)\n",
    "        return tf.add(tf.nn.conv2d(self.padding(inputs), self.W, self.strides, 'VALID'), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31400109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        note: channels size will be reduced to half\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        shp_ln = len(inputs.shape)\n",
    "        assert inputs.shape[-1] % 2 == 0\n",
    "        nc = inputs.shape[-1]//2\n",
    "        \n",
    "        x = tf.transpose(inputs, perm = [shp_ln-1] + [i for i in range(shp_ln-1)])\n",
    "        x = x[:nc] * tf.nn.sigmoid(x[nc:]) # parsing through channels\n",
    "        x = tf.transpose(x, perm = [i for i in range(1,shp_ln)] + [0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f79752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, pt_model = None, pt_layers = [], preprocess_func = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.embed_model = tf.keras.applications.InceptionV3(include_top = False, weights = 'imagenet', pooling = 'avg') if pt_model is None else pt_model\n",
    "        self.embed_model.trainable = False\n",
    "        \n",
    "        if preprocess_func is None:\n",
    "            self.preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "        else:\n",
    "            self.preprocess_input = preprocess_func\n",
    "            \n",
    "        layers = ['mixed7'] if len(pt_layers) == 0 else pt_layers\n",
    "        outs = [self.embed_model.get_layer(layer).output for layer in layers]\n",
    "        \n",
    "        self.feature_model = tf.keras.models.Model(self.embed_model.inputs, outs)\n",
    "        self.feature_model.trainable = False\n",
    "        \n",
    "        #self.conv = Conv2D(filters = dim, kernel_size = (1, 1), strides = (1, 1), padding = (0, 0))\n",
    "        self.linear_1 = Linear(neurons = dim)\n",
    "        self.linear_2 = Linear(neurons = dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.image.resize((inputs+1)*127.5, [299, 299], tf.image.ResizeMethod.BILINEAR)\n",
    "        x = self.preprocess_input(x)\n",
    "        \n",
    "        features = self.feature_model(x)\n",
    "        features = tf.reshape(features, (-1, features.shape[1] * features.shape[2], features.shape[3]))\n",
    "        features = self.linear_1(features)\n",
    "        #features = self.conv(features)\n",
    "        \n",
    "        embed = self.embed_model(x)\n",
    "        embed = self.linear_2(embed)\n",
    "        \n",
    "        return features, embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfd33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, inp_dim, dim, apply_dropout = 0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(inp_dim, dim)\n",
    "        if apply_dropout:\n",
    "            self.dropout = tf.keras.layers.Dropout(apply_dropout)\n",
    "            \n",
    "        self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(dim, return_state = True, return_sequences = True))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        if hasattr(self, 'dropout'):\n",
    "            x = self.dropout(x)\n",
    "        outs = self.rnn(x)\n",
    "        \n",
    "        word_embed = outs[0]\n",
    "        sent_embed = tf.concat([outs[1], outs[2]], axis = -1)\n",
    "        \n",
    "        mask = tf.math.equal(inputs, 0)\n",
    "        return word_embed, sent_embed, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607b70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.linear = Linear(dim * 2)\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.act(self.linear(inputs))\n",
    "        \n",
    "        mu = x[:, :self.dim]\n",
    "        logvar = x[:, self.dim:]\n",
    "        \n",
    "        epsilon = tf.random.normal(tf.shape(mu), mean=0.0, stddev=1.0)\n",
    "        out = mu + tf.exp(logvar * 0.5) * epsilon\n",
    "        \n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc6161f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear = Linear(neurons = dim)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        _, self.hh, self.hw, _ = input_shape[0]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h, e, mask = inputs\n",
    "        \n",
    "        h = tf.reshape(h, (-1, h.shape[1]*h.shape[2], h.shape[3]))\n",
    "        context = self.linear(e) #b x seq_len x dim\n",
    "\n",
    "        attention = tf.matmul(h, context, transpose_b = True) # b x h*w x seq_len\n",
    "        attention += tf.reshape(tf.tile(tf.cast(mask, tf.float32)*-1e12, (self.hh*self.hw, 1)), \n",
    "                                (-1, self.hh*self.hw, mask.shape[-1]))\n",
    "        attention = tf.nn.softmax(attention, axis = -1)\n",
    "\n",
    "        out = tf.matmul(attention, context)\n",
    "        out = tf.reshape(out, (-1, self.hh, self.hw, context.shape[-1]))\n",
    "        \n",
    "        attention = tf.reshape(attention, (-1, self.hh, self.hw, context.shape[1]))\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfaff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampling(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.up_sample = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'nearest')\n",
    "        self.conv = Conv2D(filters = dim * 2, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1))\n",
    "        self.norm = tf.keras.layers.BatchNormalization()\n",
    "        self.glu = GLU() # channels gets reduced to half\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.glu(self.norm(self.conv(self.up_sample(inputs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c2b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, kernel_size, strides, padding, norm = True, act = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = Conv2D(filters = dim, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        if norm:\n",
    "            self.norm = tf.keras.layers.BatchNormalization()\n",
    "        if act:\n",
    "            self.act = tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        if hasattr(self, 'norm'):\n",
    "            x = self.norm(x)\n",
    "        if hasattr(self, 'act'):\n",
    "            x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b0465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(filters = dim * 2, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1))\n",
    "        self.norm_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1 = GLU()\n",
    "        \n",
    "        self.conv_2 = Conv2D(filters = dim, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1))\n",
    "        self.norm_2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.norm_2(self.conv_2(self.act_1(self.norm_1(self.conv_1(inputs))))) + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e714edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMAGE_GENERATOR(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1))\n",
    "        self.act = tf.keras.layers.Activation('tanh')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.act(self.conv(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4321b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F_INIT_STAGE(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        This generator generates 64x64 images.\n",
    "    '''\n",
    "    def __init__(self, dim, up_block = 4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.fc = tf.keras.models.Sequential([\n",
    "            Linear(neurons = 2 * 4 * 4 * dim), \n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            GLU(),\n",
    "            tf.keras.layers.Reshape((4, 4, dim)),\n",
    "        ])\n",
    "        \n",
    "        self.up_sample = tf.keras.models.Sequential()\n",
    "        for _ in range(up_block):\n",
    "            dim //= 2\n",
    "            self.up_sample.add(UpSampling(dim))\n",
    "            \n",
    "        self.gen_img = IMAGE_GENERATOR()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.up_sample(self.fc(inputs))\n",
    "        img = self.gen_img(x)\n",
    "        return x, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c26bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F_STAGE(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.attention = Attention(dim)\n",
    "        \n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        for _ in range(2):\n",
    "            self.model.add(ResidualBlock(dim * 2))\n",
    "        self.model.add(UpSampling(dim))\n",
    "        \n",
    "        self.gen_img = IMAGE_GENERATOR()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h, e, mask = inputs\n",
    "        \n",
    "        x, _ = self.attention([h, e, mask])\n",
    "        h_x = tf.concat([h, x], axis = -1)\n",
    "        \n",
    "        h = self.model(h_x)\n",
    "        img = self.gen_img(h)\n",
    "        \n",
    "        return h, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680f5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNET(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, n_regular_down, n_extra_down, n_final_block, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.conditional_conv = Conv2D(filters = 1, kernel_size = (4, 4), strides = (4, 4), padding = 'valid')\n",
    "        self.unconditional_conv = Conv2D(filters = 1, kernel_size = (4, 4), strides = (4, 4), padding = 'valid')\n",
    "        \n",
    "        self.block_1 = tf.keras.models.Sequential()\n",
    "        self.block_1.add(D_ConvBlock(dim = 1, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1), norm = False))\n",
    "        \n",
    "        for i in range(n_regular_down + n_extra_down):\n",
    "            if i <= n_regular_down:\n",
    "                dim *= 2\n",
    "                \n",
    "            self.block_1.add(D_ConvBlock(dim = dim, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1)))\n",
    "        dim //= 2\n",
    "        \n",
    "        for _ in range(n_final_block):\n",
    "            self.block_1.add(D_ConvBlock(dim = dim, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1)))\n",
    "            \n",
    "        self.block_2 = D_ConvBlock(dim = dim, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x, sent_embed = inputs\n",
    "        out_1 = self.block_1(x)\n",
    "        \n",
    "        unconditional_out = self.unconditional_conv(out_1)\n",
    "        \n",
    "        out_2 = tf.concat([out_1, sent_embed], axis = -1)\n",
    "        out_2 = self.block_2(out_2)\n",
    "        \n",
    "        conditional_out = self.conditional_conv(out_2)\n",
    "        return unconditional_out, conditional_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f96e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(text_shape, vocab_size, dim = 32, embed_dim = 256, z_dim = 100):\n",
    "    inp_text_encoder = tf.keras.layers.Input(shape = text_shape, dtype = tf.float32, name = 'text_encoder_input')\n",
    "    inp_noise = tf.keras.layers.Input(shape = (z_dim, ), dtype = tf.float32, name = 'noise_z_input')\n",
    "    \n",
    "    \n",
    "    word_embed, sent_embed, mask = TextEncoder(vocab_size, embed_dim)(inp_text_encoder)\n",
    "    ca, mu, logvar = ConditionalAugmentation(z_dim)(sent_embed)\n",
    "    \n",
    "    ca_z = tf.keras.layers.Concatenate(axis = -1)([ca, inp_noise])\n",
    "    \n",
    "    h, img_0 = F_INIT_STAGE(dim = dim * 16)(ca_z)\n",
    "    h, img_1 = F_STAGE(dim = dim)([h, word_embed, mask])\n",
    "    _, img_2 = F_STAGE(dim = dim)([h, word_embed, mask])\n",
    "    \n",
    "    feature, embed = ImageEncoder(embed_dim)(img_2)\n",
    "    \n",
    "    inputs = [inp_text_encoder, inp_noise]\n",
    "    outputs = [word_embed, sent_embed, mu, logvar, img_0, img_1, img_2, feature, embed]\n",
    "    return tf.keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd5a3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(sent_embed_shape, img_shps = [64, 128, 256], dim = 64):\n",
    "    inp_img_0 = tf.keras.layers.Input(shape = (img_shps[0], img_shps[0], 3), dtype = tf.float32, \n",
    "                                      name = f'input_image_{img_shps[0]}x{img_shps[0]}x3')\n",
    "    inp_img_1 = tf.keras.layers.Input(shape = (img_shps[1], img_shps[1], 3), dtype = tf.float32, \n",
    "                                      name = f'input_image_{img_shps[1]}x{img_shps[1]}x3')\n",
    "    inp_img_2 = tf.keras.layers.Input(shape = (img_shps[2], img_shps[2], 3), dtype = tf.float32, \n",
    "                                      name = f'input_image_{img_shps[2]}x{img_shps[2]}x3')\n",
    "    inp_sent_embed = tf.keras.layers.Input(shape = sent_embed_shape, dtype = tf.float32, name = 'input_sent_embed')\n",
    "    \n",
    "    \n",
    "    sent_embed = tf.reshape(inp_sent_embed, (-1, 1, 1, sent_embed_shape[-1]))\n",
    "    sent_embed = tf.tile(sent_embed, (1, 4, 4, 1))\n",
    "    \n",
    "    unconditional_out_0, conditional_out_0 = DNET(dim = dim, n_regular_down = 3, n_extra_down = 0, \n",
    "                                                  n_final_block = 0)([inp_img_0, sent_embed])\n",
    "    unconditional_out_1, conditional_out_1 = DNET(dim = dim, n_regular_down = 3, n_extra_down = 1, \n",
    "                                                  n_final_block = 1)([inp_img_1, sent_embed])\n",
    "    unconditional_out_2, conditional_out_2 = DNET(dim = dim, n_regular_down = 3, n_extra_down = 2, \n",
    "                                                  n_final_block = 2)([inp_img_2, sent_embed])\n",
    "    \n",
    "    unconditional_outs = [unconditional_out_0, unconditional_out_1, unconditional_out_2]\n",
    "    conditional_outs = [conditional_out_0, conditional_out_1, conditional_out_2]\n",
    "    \n",
    "    return tf.keras.models.Model([inp_img_0, inp_img_1, inp_img_2, inp_sent_embed], [unconditional_outs, conditional_outs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "25acb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_attention(query, context, gamma1 = 4.0):\n",
    "    \n",
    "    bs, hw, dim = query.shape\n",
    "    _, seq_len, _ = context.shape\n",
    "    \n",
    "    attn = tf.matmul(query, context, transpose_b = True)\n",
    "    attn = tf.nn.softmax(attn)\n",
    "    \n",
    "    attn = tf.transpose(attn, perm = [0, 2, 1]) * gamma1\n",
    "    attn = tf.nn.softmax(attn)\n",
    "    \n",
    "    out = tf.matmul(query, attn, 1, 1) # 'OR' tf.transpose(tf.matmul(attn, query), perm = [0, 2, 1])\n",
    "    return out\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    norm_x = tf.math.sqrt(tf.math.reduce_sum(tf.square(x), axis = -1, keepdims = True))\n",
    "    norm_y = tf.math.sqrt(tf.math.reduce_sum(tf.square(y), axis = -1, keepdims = True))\n",
    "    return tf.math.reduce_mean(x*y, axis = -1, keepdims = True)/(norm_x * norm_y)\n",
    "    \n",
    "    \n",
    "def word_loss(img_feature, word_embed, class_id, gamma2 = 5.0):\n",
    "    batch_size, seq_len, _ = word_embed.shape\n",
    "\n",
    "    label = tf.cast(range(batch_size), tf.int32)\n",
    "    masks = []\n",
    "    similarities = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        mask = (class_id.numpy() == class_id[i].numpy()).astype(np.uint8)\n",
    "        mask[i] = 0\n",
    "        masks.append(np.reshape(mask, (1, -1)))\n",
    "\n",
    "        word = tf.tile(word_embed[i:i+1, :, :], multiples=[batch_size, 1, 1])\n",
    "\n",
    "        weiContext, _ = func_attention(img_feature, word)\n",
    "        weiContext = tf.transpose(weiContext, perm = [0, 2, 1])\n",
    "\n",
    "        word = tf.reshape(word, shape=[batch_size * seq_len, -1])\n",
    "        weiContext = tf.reshape(weiContext, shape = [batch_size * seq_len, -1])\n",
    "\n",
    "        row_sim = cosine_similarity(word, weiContext)\n",
    "        row_sim = tf.reshape(row_sim, shape = [batch_size, seq_len])\n",
    "\n",
    "        row_sim = tf.exp(row_sim * gamma2)\n",
    "        row_sim = tf.reduce_sum(row_sim, axis = -1, keepdims=True)\n",
    "        row_sim = tf.math.log(row_sim)\n",
    "\n",
    "        similarities.append(row_sim)\n",
    "\n",
    "    similarities = tf.concat(similarities, axis = -1)\n",
    "    masks = tf.cast(tf.concat(masks, axis = 0), tf.float32)\n",
    "\n",
    "    similarities = similarities * gamma2\n",
    "    \n",
    "    similarities += tf.cast(masks, tf.float32) * -1e12\n",
    "    #similarities = tf.where(tf.equal(masks, True), -1e12, similarities)\n",
    "\n",
    "    similarities_ = tf.transpose(similarities, perm = [1, 0])\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(label, similarities))\n",
    "    loss += tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(label, similarities_))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sent_loss(img_feature, sent_emb, class_id, gamma3=10.0):\n",
    "    batch_size, _ = sent_emb\n",
    "    \n",
    "    label = tf.cast(range(batch_size), tf.int32)\n",
    "    masks = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        mask = (class_id.numpy() == class_id[i].numpy()).astype(np.uint8)\n",
    "        mask[i] = 0\n",
    "        masks.append(np.reshape(mask, (1, -1)))\n",
    "\n",
    "    masks = tf.cast(tf.concat(masks, axis = 0), tf.float32)\n",
    "\n",
    "    cnn_code = tf.expand_dims(img_feature, axis = 0)\n",
    "    rnn_code = tf.expand_dims(sent_emb, axis = 0)\n",
    "\n",
    "    cnn_code_norm = tf.norm(cnn_code, axis = -1, keepdims = True)\n",
    "    rnn_code_norm = tf.norm(rnn_code, axis = -1, keepdims = True)\n",
    "\n",
    "    scores0 = tf.matmul(cnn_code, rnn_code, transpose_b = True)\n",
    "    norm0 = tf.matmul(cnn_code_norm, rnn_code_norm, transpose_b = True)\n",
    "    scores0 = scores0 / tf.clip_by_value(norm0, clip_value_min = 1e-8, clip_value_max = float('inf')) * gamma3\n",
    "\n",
    "    scores0 = tf.squeeze(scores0, axis = 0)\n",
    "    scores0 += tf.cast(masks, tf.float32)*-1e12\n",
    "    # scores0 = tf.where(tf.equal(masks, True), -1e12, scores0)\n",
    "    \n",
    "    scores1 = tf.transpose(scores0, perm = [1, 0])\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(label, scores0))\n",
    "    loss += tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(label, scores1))\n",
    "    return loss\n",
    "\n",
    "\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "def generator_loss(disc_gen_out):\n",
    "    return bce_loss(tf.ones_like(disc_gen_out), disc_gen_out)\n",
    "\n",
    "def discriminator_loss(disc_real_out, disc_gen_out):\n",
    "    if disc_real_out is not None:\n",
    "        loss = bce_loss(tf.ones_like(disc_real_out), disc_real_out) + bce_loss(tf.zeros_like(disc_gen_out), disc_gen_out)\n",
    "        loss *= 0.5\n",
    "    else:\n",
    "        loss = bce_loss(tf.zeros_like(disc_gen_out), disc_gen_out)\n",
    "    \n",
    "    return loss \n",
    "    \n",
    "def kl_loss(mu, logvar):\n",
    "    loss = 0.5 * tf.reduce_sum(tf.square(mu) + tf.exp(logvar) - 1 - logvar, axis=-1)\n",
    "    return tf.math.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5bd88d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, generator, discriminator, z_dim, learning_rate = 2e-4):\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        \n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, text, img, class_id):\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            sent_index = tf.random.uniform(shape = [], minval = 0, maxval = 10, dtype = tf.int32)\n",
    "            txt = tf.gather(caption, sent_index, axis = 1)\n",
    "            noise_z = tf.random.normal(shape = (self.batch_size, self.generator.input_shape[1][1]))\n",
    "            \n",
    "            \n",
    "            real_0, real_1 = resize(img, target_size=[64, 64]), resize(img, target_size=[128, 128])\n",
    "\n",
    "            word_embed, sent_embed, mu, logvar, img_0, img_1, img_2, feature, embed = self.generator([txt, noise_z], training = True)\n",
    "            \n",
    "            unconditional_gen_out, conditional_gen_out = self.discriminator([img_0, img_1, img_2, sent_embed], training = True)\n",
    "            unconditional_real_out, conditional_real_out = self.discriminator([real_0, real_1, img, sent_embed], training = True)\n",
    "            _, conditional_wrong_out = self.discriminator([real_0[:-1], real_1[:-1], img[:-1], sent_embed[1:]])\n",
    "            \n",
    "            # gen_loss\n",
    "            gen_loss = 0\n",
    "            for ugo, cgo in zip(unconditional_gen_out, conditional_gen_out):\n",
    "                gen_loss += generator_loss(ugo) + generator_loss(cgo)\n",
    "                \n",
    "            gen_loss += word_loss(feature, word_embed, class_id)*5.0\n",
    "            gen_loss += sent_loss(embed, sent_embed, class_id)*5.0\n",
    "            gen_loss += kl_loss(mu, logvar)\n",
    "            \n",
    "            # disc_loss\n",
    "            disc_loss = 0\n",
    "            for i in range(3):\n",
    "                disc_l = discriminator_loss(unconditional_real_out[i], unconditional_gen_out[i])\n",
    "                disc_l += discriminator_loss(conditional_real_out[i], conditional_gen_out[i])\n",
    "                disc_l += discriminator_loss(None, conditional_wrong_out[i])\n",
    "                \n",
    "                disc_loss += disc_l/3\n",
    "                \n",
    "                \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_optimizer.apply(zip(gen_grads, self.generator.trainable_variables))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_optimizer.apply(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        gen_losses, disc_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Start')\n",
    "            for text, img, class_id in data:\n",
    "                gen_loss, disc_loss = self.train_step(text, img, class_id)\n",
    "                print('.', end = '')\n",
    "                \n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "            print(f'Epoch: {e} Ends\\n')\n",
    "            \n",
    "        return {'gen_losses': gen_losses, 'disc_losses': disc_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebed9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
