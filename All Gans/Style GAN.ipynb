{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aefeba1",
   "metadata": {},
   "source": [
    "# Style Gan\n",
    "\n",
    "This is an attempt to re-implement the paper Style-GAN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1812.04948.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/NVlabs/stylegan\n",
    "* https://keras.io/examples/generative/stylegan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df96e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0229b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStddev(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inp_shp = tf.shape(inputs)\n",
    "        \n",
    "        mean = tf.math.reduce_mean(inputs, axis = 0, keepdims = True)\n",
    "        std = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(inputs - mean), keepdims = True, axis = 0) + self.epsilon)\n",
    "        avg_std = tf.math.reduce_mean(std, keepdims = True)\n",
    "        tiled = tf.tile(avg_std, (inp_shp[0], inp_shp[1], inp_shp[2], 1))\n",
    "        combined = tf.concat([inputs, tiled], axis = -1)\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d817d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, gain = np.sqrt(2), **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gain = gain\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_chn = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (inp_chn, self.units), initializer = init, \n",
    "                                 trainable = True, name = 'Weight')\n",
    "        self.B = self.add_weight(shape = (self.units, ), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'Bias')\n",
    "        \n",
    "        self.w_scale = self.gain * tf.math.rsqrt(tf.cast(inp_chn, tf.float32))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.matmul(inputs, self.W * self.w_scale), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c751b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2), **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.gain = gain\n",
    "        self.padding = 'SAME' if (kernel_size[0]-1) // 2 else 'VALID'\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_chn = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (self.kernel_size[0], self.kernel_size[1], inp_chn, self.filters), \n",
    "                                 initializer = init, trainable = True, name = 'Weight')\n",
    "        self.B = self.add_weight(shape = (self.filters, ), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'Bias')\n",
    "        \n",
    "        fan_in = tf.cast(self.kernel_size[0] * self.kernel_size[1] * inp_chn, tf.float32)\n",
    "        self.w_scale = self.gain * tf.math.rsqrt(fan_in)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.nn.conv2d(inputs, self.W * self.w_scale, self.strides, self.padding, data_format = 'NHWC'), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176b0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIn(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.inp_chn = input_shape[0][-1]\n",
    "        \n",
    "        self.W1 = Dense(units = self.inp_chn, gain = 1.0)\n",
    "        self.W2 = Dense(units = self.inp_chn, gain = 1.0)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "        \n",
    "        mean = tf.math.reduce_mean(x, keepdims = True, axis = [1, 2])\n",
    "        std = tf.math.rsqrt(tf.math.reduce_variance(x, keepdims = True, axis = [1, 2]) + self.epsilon)\n",
    "        inst_norm = (x - mean) * std\n",
    "        \n",
    "        ys = tf.reshape(self.W1(w), (-1, 1, 1, self.inp_chn))\n",
    "        yb = tf.reshape(self.W2(w), (-1, 1, 1, self.inp_chn))\n",
    "        \n",
    "        out = ys * inst_norm + yb\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c082a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        inp_chn = input_shape[0][-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (1, 1, 1, inp_chn), initializer = init, \n",
    "                                 trainable = True, name = 'Weight')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs[0] + self.W * inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4d5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(tf.keras.layers.Layer):\n",
    "    def __init__(self, alpha = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if alpha is None:\n",
    "            self.alpha = tf.Variable(alpha, 'ws_alpha')\n",
    "        else:\n",
    "            self.alpha = alpha\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return ((1 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce5a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(tf.keras.layers.Layer):\n",
    "    def __init__(self, p = 2, dim = [1], epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if p == 1:\n",
    "            self.norm = lambda x: x * tf.math.rsqrt(tf.math.reduce_mean(tf.abs(x), axis = dim, keepdims = True) + epsilon)\n",
    "        elif p == 2:\n",
    "            self.norm = lambda x: x * tf.math.rsqrt(tf.math.reduce_mean(tf.square(x), axis = dim, keepdims = True) + epsilon)\n",
    "        else:\n",
    "            raise ValueError('`p` value should be 1 or 2.\\n\\t1 indicates L1 Norm\\n\\t2 indicates L2 Norm')\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return self.norm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b692712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = [512, 512, 512, 512, 256, 128, 64, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6e668716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGAN(tf.keras.models.Model):\n",
    "    def __init__(self, latent_dim = 512, d_steps = 1, gp_weight = 10, drift_weight = 0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = d_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.drift_weight = drift_weight\n",
    "        \n",
    "        self.num_block = 2\n",
    "        self.alpha = tf.Variable(0.0, 'ws_alpha')\n",
    "        \n",
    "        self.generator = self.__init_generator\n",
    "        self.discriminator = self.__init_discriminator\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def __init_generator(self):\n",
    "        res = 2**(self.num_block)\n",
    "        latent_inp = tf.keras.layers.Input(shape = (self.latent_dim), dtype = tf.float32, name = f'latent_input_{self.latent_dim}')\n",
    "        const_inp = tf.keras.layers.Input(shape = (res, res, FILTERS[self.num_block - 2]), dtype = tf.float32, \n",
    "                                          name = f'constant_input_{res}x{res}x{FILTERS[self.num_block - 2]}')\n",
    "        noise_inp = tf.keras.layers.Input(shape = (res, res, 1), dtype = tf.float32, name = f'noise_input_{res}x{res}')\n",
    "        \n",
    "        w = Normalize(p = 2, dim = 1)(latent_inp)\n",
    "        for i in range(8):\n",
    "            w = Dense(units = FILTERS[self.num_block - 2], gain = np.sqrt(2), name = f'latent_linear_{i}')(w)\n",
    "            w = tf.keras.layers.LeakyReLU(alpha = 0.2, name = f'latent_act_{i}')(w)\n",
    "            \n",
    "        x = AddNoise()([const_inp, noise_inp])\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        x = AdaIn()([x, w])\n",
    "        \n",
    "        x = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(x)\n",
    "        x = AddNoise()([x, noise_inp])\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        x = AdaIn()([x, w])\n",
    "        \n",
    "        x = Conv2D(filters = 3, kernel_size = (1, 1), strides = (1, 1), gain = 1.0, name = f'to_rgb_conv_{res}x{res}')(x)\n",
    "        x = tf.keras.layers.Activation('tanh', name = f'to_rgb_act_{res}x{res}')(x)\n",
    "        \n",
    "        return tf.keras.models.Model([latent_inp, const_inp, noise_inp], x, name = f'generator_{res}x{res}')\n",
    "    \n",
    "    @property\n",
    "    def __grow_generator(self):\n",
    "        res = 2**self.num_block\n",
    "        prev_res = 2**(self.num_block - 1)\n",
    "        \n",
    "        noise_inp = tf.keras.layers.Input(shape = (res, res, 1), dtype = tf.float32, name = f'noise_input_{res}x{res}')\n",
    "        \n",
    "        for n, layer in enumerate(self.generator.layers):\n",
    "            if layer.name == f'to_rgb_conv_{prev_res}x{prev_res}':\n",
    "                to_rgb_conv = layer\n",
    "                t = n - 1\n",
    "            elif layer.name == f'to_rgb_act_{prev_res}x{prev_res}':\n",
    "                to_rgb_act = layer\n",
    "            elif layer.name == f'latent_act_7':\n",
    "                w = layer.output\n",
    "                \n",
    "        end_block = self.generator.layers[t].output\n",
    "        up_sample = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(end_block)\n",
    "        \n",
    "        x1 = to_rgb_act(to_rgb_conv(up_sample))\n",
    "        \n",
    "        x2 = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(up_sample)\n",
    "        x2 = AddNoise()([x2, noise_inp])\n",
    "        x2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(x2)\n",
    "        x2 = AdaIn()([x2, w])\n",
    "        \n",
    "        x2 = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(x2)\n",
    "        x2 = AddNoise()([x2, noise_inp])\n",
    "        x2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(x2)\n",
    "        x2 = AdaIn()([x2, w])\n",
    "        \n",
    "        x2 = Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), gain = 1.0, name = f'to_rgb_conv_{res}x{res}')(x2)\n",
    "        x2 = tf.keras.layers.Activation('tanh', name = f'to_rgb_act_{res}x{res}')(x2)\n",
    "        \n",
    "        x = WeightedSum(self.alpha)([x1, x2])\n",
    "        \n",
    "        self.stabilized_generator = tf.keras.models.Model(self.generator.inputs + [noise_inp], x2, \n",
    "                                                          name = f'stabilized_generator_{res}x{res}')\n",
    "        self.generator = tf.keras.models.Model(self.generator.inputs + [noise_inp], x, name = f'generator_{res}x{res}')\n",
    "    \n",
    "    @property\n",
    "    def __init_discriminator(self):\n",
    "        res = 2**self.num_block\n",
    "        inp = tf.keras.layers.Input(shape = (res, res, 3), dtype = tf.float32, name = f'discriminator_input_{res}x{res}')\n",
    "        \n",
    "        x = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (1, 1), strides = (1, 1), gain = np.sqrt(2), \n",
    "                   name = f'from_rgb_conv_{res}x{res}')(inp)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2, name = f'from_rgb_act_{res}x{res}')(x)\n",
    "        \n",
    "        x = MinibatchStddev()(x)\n",
    "        \n",
    "        x = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        x = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (4, 4), strides = (4, 4), gain = np.sqrt(2))(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = Dense(units = 1, gain = 1.0)(x)\n",
    "        \n",
    "        return tf.keras.models.Model(inp, x, name = f'disciminator_{res}x{res}')\n",
    "            \n",
    "    @property\n",
    "    def __grow_discriminator(self):\n",
    "        res = 2**self.num_block\n",
    "        prev_res = 2**(self.num_block - 1)\n",
    "        \n",
    "        inp = tf.keras.layers.Input(shape = (res, res, 3), dtype = tf.float32, name = f'discriminator_input_{res}x{res}')\n",
    "        \n",
    "        for n, layer in enumerate(self.discriminator.layers):\n",
    "            if layer.name == f'from_rgb_conv_{prev_res}x{prev_res}':\n",
    "                from_rgb_conv = layer\n",
    "            elif layer.name == f'from_rgb_act_{prev_res}x{prev_res}':\n",
    "                from_rgb_act = layer\n",
    "                t = n + 1\n",
    "                \n",
    "        x1 = tf.keras.layers.AveragePooling2D()(inp)\n",
    "        x1 = from_rgb_act(from_rgb_conv(x1))\n",
    "        \n",
    "        x2 = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (1, 1), strides = (1, 1), gain = np.sqrt(2), \n",
    "                    name = f'from_rgb_conv_{res}x{res}')(inp)\n",
    "        x2 = tf.keras.layers.LeakyReLU(alpha = 0.2, name = f'from_rgb_act_{res}x{res}')(x2)\n",
    "        \n",
    "        x2 = Conv2D(filters = FILTERS[self.num_block - 2], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(x2)\n",
    "        x2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(x2)\n",
    "        x2 = Conv2D(filters = FILTERS[self.num_block - 3], kernel_size = (3, 3), strides = (1, 1), gain = np.sqrt(2))(x2)\n",
    "        x2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(x2)\n",
    "        \n",
    "        x2 = tf.keras.layers.AveragePooling2D()(x2)\n",
    "        \n",
    "        x = WeightedSum(self.alpha)([x1, x2])\n",
    "        \n",
    "        for i in range(t, len(self.discriminator.layers)):\n",
    "            x = self.discriminator.layers[i](x)\n",
    "            x2 = self.discriminator.layers[i](x2)\n",
    "            \n",
    "        self.stabilized_discriminator = tf.keras.models.Model(inp, x2, name = f'stabilized_discriminator_{res}x{res}')\n",
    "        self.discriminator = tf.keras.models.Model(inp, x, name = f'discriminator_{res}x{res}')\n",
    "                \n",
    "    def grow_model(self):\n",
    "        self.num_block += 1\n",
    "        self.__grow_generator\n",
    "        self.__grow_discriminator\n",
    "    \n",
    "    def stabilize_model(self):\n",
    "        self.generator = self.stabilized_generator\n",
    "        self.discriminator = self.stabilized_discriminator\n",
    "    \n",
    "    def generator_loss(self, disc_gen_out):\n",
    "        return -tf.math.reduce_mean(disc_gen_out)\n",
    "    \n",
    "    def gradient_penalty(self, real_img, gen_img):\n",
    "        \n",
    "        epsilon = tf.random.normal((tf.shape(real_img)[0], 1, 1, 1))\n",
    "        interpolated_img = ((1 - epsilon) * real_img) + (epsilon * gen_img)\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated_img)\n",
    "            disc_out = self.discriminator(interpolated_img)\n",
    "            \n",
    "        grads = gp_tape.gradient(disc_out, [interpolated_img])[0]\n",
    "        norm = tf.math.sqrt(tf.math.reduce_mean(tf.square(grads), keepdims = True, axis = [1, 2, 3]))\n",
    "        gp = tf.math.reduce_mean(tf.square(norm - 1))\n",
    "        return gp * self.gp_weight\n",
    "    \n",
    "    def discriminator_loss(self, disc_real_out, disc_gen_out):\n",
    "        return tf.math.reduce_mean(disc_gen_out) - tf.math.reduce_mean(disc_real_out)\n",
    "    \n",
    "    def drift_loss(self, disc_real_out):\n",
    "        return tf.math.reduce_mean(tf.square(disc_real_out)) * self.drift_weight\n",
    "    \n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def generate_noise(self, batch_size):\n",
    "        return [tf.random.normal((batch_size, 2**r, 2**r, 1)) for r in range(2, self.num_block+1)]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        for _ in range(self.d_steps):\n",
    "            latent_input = tf.random.normal((batch_size, self.latent_dim))\n",
    "            const_inp = tf.ones((batch_size, 4, 4, 512))\n",
    "            noise_inps = self.generate_noise(batch_size)\n",
    "            with tf.GradientTape() as disc_tape:\n",
    "                gen_out = self.generator([latent_input, const_inp] + noise_inps, training = True)\n",
    "                \n",
    "                disc_real_out = self.discriminator(real_images, training = True)\n",
    "                disc_gen_out = self.discriminator(gen_out, training = True)\n",
    "                \n",
    "                gp_loss = self.gradient_penalty(real_images, gen_out)\n",
    "                drf_loss = self.drift_loss(disc_real_out)\n",
    "                disc_loss = self.discriminator_loss(disc_real_out, disc_gen_out) + gp_loss + drf_loss\n",
    "                \n",
    "            disc_grads = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "            \n",
    "        \n",
    "        latent_input = tf.random.normal((batch_size, self.latent_dim))\n",
    "        const_inp = tf.random.normal((batch_size, 4, 4, 512))\n",
    "        noise_inps = self.generate_noise(batch_size)\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            gen_out = self.generator([latent_input, const_inp] + noise_inps, training = True)\n",
    "            disc_gen_out = self.discriminator(gen_out, training = True)\n",
    "            gen_loss = self.generator_loss(disc_gen_out)\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "        \n",
    "        return {'disc_loss': disc_loss, 'gen_loss': gen_loss}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "094bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.n_epoch = 0\n",
    "    \n",
    "    def set_steps(self, steps_per_epoch, epochs):\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.epochs = epochs\n",
    "        self.steps = self.steps_per_epoch * self.epochs\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        self.n_epoch = epoch\n",
    "        \n",
    "    def on_batch_begin(self, batch, logs = None):\n",
    "        alpha = ((self.n_epoch * self.steps_per_epoch) + batch) / float(self.steps - 1)\n",
    "        self.model.alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6074e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\Image Datasets\\Celeb A\\Dataset\\img_align_celeba'\n",
    "train_data_generator = \\\n",
    "tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function = lambda x: (tf.cast(x, tf.float32)/127.5)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0d42fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1ed1279fca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset = train_data_generator.flow_from_directory(directory = path, target_size = (128, 128), \n",
    "#                                                              batch_size = 4, shuffle = True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "605ea3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 1 classes.\n",
      "5/5 [==============================] - 3s 38ms/step - disc_loss: 7.2019 - gen_loss: 0.2222\n",
      "Found 202599 images belonging to 1 classes.\n",
      "5/5 [==============================] - 4s 65ms/step - disc_loss: 9.2597 - gen_loss: 0.4985\n",
      "5/5 [==============================] - 4s 61ms/step - disc_loss: 8.0987 - gen_loss: 1.5429\n",
      "Found 202599 images belonging to 1 classes.\n",
      "5/5 [==============================] - 5s 101ms/step - disc_loss: 9.0466 - gen_loss: 2.1590\n",
      "5/5 [==============================] - 3s 100ms/step - disc_loss: 6.7567 - gen_loss: 6.7530\n",
      "Found 202599 images belonging to 1 classes.\n",
      "5/5 [==============================] - 7s 201ms/step - disc_loss: 6.5766 - gen_loss: 12.4801\n",
      "5/5 [==============================] - 5s 197ms/step - disc_loss: -4.4813 - gen_loss: 38.7717\n",
      "Found 202599 images belonging to 1 classes.\n",
      "5/5 [==============================] - 9s 345ms/step - disc_loss: -4.4229 - gen_loss: 111.0938\n",
      "5/5 [==============================] - 6s 337ms/step - disc_loss: -3.3625 - gen_loss: 190.2000\n",
      "Found 202599 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[4,256,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/discriminator_128x128/average_pooling2d_46/AvgPool_2/AvgPoolGrad (defined at \\AppData\\Local\\Temp/ipykernel_11100/3881366758.py:163) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_241546]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11100/248483129.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mcbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0msgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{res}x{res}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'main'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[4,256,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/discriminator_128x128/average_pooling2d_46/AvgPool_2/AvgPoolGrad (defined at \\AppData\\Local\\Temp/ipykernel_11100/3881366758.py:163) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_241546]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "sgan = StyleGAN()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "epochs = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "BATCHES = [4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
    "steps_per_epoch = [5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
    "models = {}\n",
    "\n",
    "cbk = Callback()\n",
    "\n",
    "for i in range(9):\n",
    "    res = 2**(i+2)\n",
    "    train_dataset = train_data_generator.flow_from_directory(directory = path, target_size = (res, res), \n",
    "                                                             batch_size = BATCHES[i], shuffle = True)\n",
    "    \n",
    "    models[f'{res}x{res}'] = {}\n",
    "    if i != 0:\n",
    "        sgan.grow_model()\n",
    "        \n",
    "    cbk.set_steps(steps_per_epoch[i], epochs[i])\n",
    "    sgan.compile(optimizer)\n",
    "    sgan.fit(train_dataset, steps_per_epoch = steps_per_epoch[i], epochs = epochs[i], callbacks = [cbk])\n",
    "    \n",
    "    models[f'{res}x{res}']['main'] = {}\n",
    "    models[f'{res}x{res}']['main']['generator'] = sgan.generator\n",
    "    models[f'{res}x{res}']['main']['discriminator'] = sgan.discriminator\n",
    "    \n",
    "    if i != 0:\n",
    "        sgan.stabilize_model()\n",
    "        \n",
    "        sgan.compile(optimizer)\n",
    "        sgan.fit(train_dataset, steps_per_epoch = steps_per_epoch[i], epochs = epochs[i], callbacks = [cbk])\n",
    "        \n",
    "        models[f'{res}x{res}']['stabilized'] = {}\n",
    "        models[f'{res}x{res}']['stabilized']['generator'] = sgan.generator\n",
    "        models[f'{res}x{res}']['stabilized']['discriminator'] = sgan.discriminator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "599aab3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(((models['64x64']['main']['generator']([tf.random.normal((1, 512)), tf.random.normal((1, 4, 4, 512)), \n",
    "                                     tf.random.normal((1, 4, 4, 1)), tf.random.normal((1, 8, 8, 1)), \n",
    "                                     tf.random.normal((1, 16, 16, 1)), tf.random.normal((1, 32, 32, 1)), \n",
    "                                     tf.random.normal((1, 64, 64, 1))])[0]+1)*127.5).numpy().astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e6619f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(((models['16x16']['main']['generator']([tf.random.normal((1, 512)), tf.random.normal((1, 4, 4, 512)), \n",
    "                                     tf.random.normal((1, 4, 4, 1)), tf.random.normal((1, 8, 8, 1)), \n",
    "                                     tf.random.normal((1, 16, 16, 1))])[0]+1)*127.5).numpy().astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0168fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8787ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23da4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan = StyleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "11ea2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.grow_model()\n",
    "# gan.stabilize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cb4a8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.stabilize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96aedc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(gan.generator, dpi = 64, show_shapes = True)\n",
    "# tf.keras.utils.plot_model(gan.discriminator, dpi = 64, show_shapes = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
