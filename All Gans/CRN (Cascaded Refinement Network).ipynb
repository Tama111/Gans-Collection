{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157e00c5",
   "metadata": {},
   "source": [
    "# CRN (Cascaded Refinement Network)\n",
    "\n",
    "This is an attempt to re-implement the paper CRN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1707.09405v1.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/wojciechmo/crn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2a7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ac754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinementModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, final_module = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # intermediate layer\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        self.act_1 = tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "        \n",
    "        if not final_module:\n",
    "            self.conv_2 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "            self.norm_2 = tf.keras.layers.LayerNormalization()\n",
    "            self.act_2 = tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        out = self.act_1(self.norm_1(self.conv_1(inputs)))\n",
    "        if hasattr(self, 'conv_2'):\n",
    "            out = self.act_2(self.norm_2(self.conv_2(out)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b963f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(inp_shape = (1024, 2048, 19), n_modules = 9, k = 1):\n",
    "    \n",
    "    inp_label = tf.keras.layers.Input(shape = inp_shape, dtype = tf.float32, name = 'inp_label')\n",
    "    \n",
    "    down_sampled_labels = [inp_label]\n",
    "    for i in range(n_modules - 1):\n",
    "        down_sampled_labels.append(tf.keras.layers.AveragePooling2D()(down_sampled_labels[-1]))\n",
    "            \n",
    "    x = RefinementModule(filters = 1024)(down_sampled_labels.pop())\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 1024)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 1024)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 1024)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 1024)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 512)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 512)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 128)(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'bilinear')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([x, down_sampled_labels.pop()])\n",
    "    x = RefinementModule(filters = 32, final_module = True)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 3 * k, kernel_size = (1, 1), strides = (1, 1), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inp_label, x, name = 'Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90dbd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiversePerceptualLoss(object):\n",
    "    def __init__(self, pt_model = None, pt_layers = [], avg = True):\n",
    "        self.avg = avg\n",
    "        model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet') if pt_model is None else pt_model\n",
    "        model.trainable = False\n",
    "        \n",
    "        layers = ['block1_conv2', 'block2_conv2', 'block3_conv2', 'block4_conv2', 'block5_conv2'] if len(pt_layers) == 0 else pt_layers\n",
    "        \n",
    "        outs = [model.get_layer(layer).output for layer in layers]\n",
    "        self.model = tf.keras.models.Model(model.inputs, outs)\n",
    "        \n",
    "        self.preprocess_input = lambda x: tf.keras.applications.vgg19.preprocess_input(x)\n",
    "        \n",
    "    def __call__(self, real, gens, labels):\n",
    "        real_outs = self.model(self.preprocess_input((real + 1)*127.5))\n",
    "        \n",
    "        all_labels = []\n",
    "        for j in range(len(real_outs)):\n",
    "            all_labels.append(tf.expand_dims(tf.image.resize(labels, [real_outs[j].shape[1], real_outs[j].shape[2]], \n",
    "                                                             tf.image.ResizeMethod.NEAREST_NEIGHBOR), axis = -2))\n",
    "        \n",
    "        losses = []\n",
    "        for gen in gens:\n",
    "            gen_outs = self.model(self.preprocess_input((gen + 1)*127.5))\n",
    "            loss = 0\n",
    "            for i, (r, g) in enumerate(zip(real_outs, gen_outs)):\n",
    "                l = tf.math.reduce_mean(tf.math.abs(all_labels[i] * tf.expand_dims(r - g, axis = -1)), axis = [0, 1, 2])\n",
    "                if self.avg:\n",
    "                    loss += tf.math.reduce_mean(l, axis = 0, keepdims = True)\n",
    "                else:\n",
    "                    loss += tf.math.reduce_sum(l, axis = 0, keepdims = True)\n",
    "            losses.append(loss)\n",
    "            \n",
    "        loss = tf.math.reduce_min(tf.concat(losses, axis = 0), axis = 0)\n",
    "        if self.avg:\n",
    "            loss = tf.math.reduce_mean(loss)\n",
    "        else:\n",
    "            loss = tf.math.reduce_sum(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8f74167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, label_shape, k = 2, n_modules = 9, learning_rate = 1e-4, **kwargs):\n",
    "        self.k = k\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        \n",
    "        self.generator = generator(inp_shape = label_shape, n_modules = n_modules, k = k)\n",
    "        self.loss = DiversePerceptualLoss()\n",
    "        \n",
    "    def train_step(self, label, real):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            gen_imgs = self.generator(label, training = True)\n",
    "            k_imgs = []\n",
    "            for i in range(self.k):\n",
    "                k_imgs.append(gen_imgs[:, :, :, i*3:(i+1)*3])\n",
    "            loss = self.loss(real, k_imgs, labels)\n",
    "            \n",
    "        grads = tape.gradient(out, self.generator.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        losses = []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts')\n",
    "            for label, real in data:\n",
    "                loss = self.train_step(label, real)\n",
    "                print('.', end='')\n",
    "                \n",
    "            losses.append(loss)\n",
    "            print(f'\\Loss: {loss}')\n",
    "            print(f'Epoch: {e} Ends.\\n')\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d59c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
