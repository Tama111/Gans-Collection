{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4024c2cb",
   "metadata": {},
   "source": [
    "# Pix2PixHD - Image Translation\n",
    "\n",
    "This is an attempt to re-implement the paper pix2pixHD\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1711.11585.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://tcwang0509.github.io/pix2pixHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df19f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12785115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.gamma = self.add_weight(shape = (1, 1, 1, inp_filters), initializer = init, \n",
    "                                     trainable = True, name = 'gamma')\n",
    "        self.beta = self.add_weight(shape = (1, 1, 1, inp_filters), initializer = init, \n",
    "                                    trainable = True, name = 'beta')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean = tf.math.reduce_mean(inputs, axis = [1, 2], keepdims = True)\n",
    "        rstd = tf.math.rsqrt(tf.math.reduce_variance(inputs, axis = [1, 2], keepdims = True) + self.epsilon)\n",
    "        out = self.gamma * ((inputs - mean) * rstd) + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20efb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding = ((1, 1), (1, 1)), **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding), (padding, padding)\n",
    "        elif isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            if isinstance(padding[0], int):\n",
    "                self.padding = (padding[0], padding[0]), (padding[1], padding[1])\n",
    "            elif isinstance(padding[0], tuple) | isinstance(padding[0], list):\n",
    "                self.padding = (padding[0][0], padding[0][1]), (padding[1][0], padding[1][1])\n",
    "            else:\n",
    "                raise Exception('Invalid padding input:\\nValid inputs are\\n(for examples)-', \n",
    "                                '\\n-> 1\\n-> (1, 1)\\n->((1, 1), (1, 1))')\n",
    "        else:\n",
    "            raise Exception('Invalid padding input:\\nValid inputs are\\n(for examples)-', \n",
    "                                '\\n-> 1\\n-> (1, 1)\\n->((1, 1), (1, 1))')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        (pad_h0, pad_h1), (pad_w0, pad_w1) = self.padding\n",
    "        return tf.pad(inputs, [[0, 0], [pad_h0, pad_h1], [pad_w0, pad_w1], [0, 0]], mode = 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2508cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, norm = 'inst_norm', activation = 'relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "\n",
    "        if isinstance(padding, str):\n",
    "            if padding.upper() in ['SAME', 'VALID']:\n",
    "                self.padding = padding.upper()\n",
    "            else:\n",
    "                raise Exception('Invalid padding, available string paddings are : `SAME` & `VALID`.')\n",
    "        else:\n",
    "            self.padding = ReflectionPadding2D(padding = padding)\n",
    "\n",
    "        if norm is not None:\n",
    "            if norm == 'inst_norm':\n",
    "                self.norm = InstanceNormalization()\n",
    "            # elif norm == 'batch_norm':\n",
    "            #     self.norm = tf.keras.layers.BatchNormalization()\n",
    "            else:\n",
    "                self.norm = norm\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "        if activation is not None:\n",
    "            if activation == 'relu':\n",
    "                self.activation = tf.keras.layers.ReLU()\n",
    "            elif activation == 'leaky_relu':\n",
    "                self.activation = tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            elif activation == 'tanh':\n",
    "                self.activation = tf.keras.layers.Activation('tanh')\n",
    "            else:\n",
    "                self.activation = activation\n",
    "        else:\n",
    "            self.activation = None\n",
    "                \n",
    "    def build(self, input_shape):\n",
    "        input_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.W = self.add_weight(shape = self.kernel_size + (input_filters, self.filters), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, 1, 1, self.filters), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if isinstance(self.padding, str):\n",
    "            x = tf.add(tf.nn.conv2d(inputs, self.W, self.strides, self.padding, 'NHWC'), self.B)\n",
    "        else:\n",
    "            x = self.padding(inputs)\n",
    "            x = tf.add(tf.nn.conv2d(x, self.W, self.strides, 'VALID', data_format = 'NHWC'), self.B)\n",
    "            \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a0d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.reflect_pad_1 = ReflectionPadding2D(((1, 1), (1, 1)))\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'valid')\n",
    "        self.norm_1 = InstanceNormalization()\n",
    "        self.act_1 = tf.keras.layers.ReLU()\n",
    "        \n",
    "        self.reflect_pad_2 = ReflectionPadding2D(((1, 1), (1, 1)))\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'valid')\n",
    "        self.norm_2 = InstanceNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.act_1(self.norm_1(self.conv_1(self.reflect_pad_1(inputs))))\n",
    "        x = self.norm_2((self.conv_2(self.reflect_pad_2(x))))\n",
    "        return x + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef127ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (2, 2), padding = 'same')\n",
    "        self.norm = InstanceNormalization()\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.act(self.norm(self.conv(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf7bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_transpose = tf.keras.layers.Conv2DTranspose(filters = filters, kernel_size = (3, 3), strides = (2, 2), \n",
    "                                                              padding = 'same')\n",
    "        self.norm = InstanceNormalization()\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.act(self.norm(self.conv_transpose(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd2e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceWiseAveragePooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # inp.shape = (batch, h, w, chn)\n",
    "        # inst.shape = (batch, h, w, no. of instances) # one-hot encoded\n",
    "        inp, inst = inputs\n",
    "        assert inst.shape[-1] != 1\n",
    "        \n",
    "        inst_sum = tf.math.reduce_sum(inst, axis = [1, 2], keepdims = True)\n",
    "        \n",
    "        inp = tf.expand_dims(inp, axis = -1)\n",
    "        inst = tf.expand_dims(inst/inst_sum, axis = -2)\n",
    "        \n",
    "        out = tf.multiply(inp, inst)\n",
    "        out = tf.math.reduce_sum(out, axis = -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "641e299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixHD(object):\n",
    "    def __init__(self, img_shape, num_labels):\n",
    "        self.img_shape = img_shape\n",
    "        self.num_labels = num_labels\n",
    "    \n",
    "    def generator(self, n_chn = 64, up_down_block = 4, res_blocks = 9):\n",
    "        inp_seg = tf.keras.layers.Input(shape = self.img_shape[:-1] + (self.num_labels, ), dtype = tf.float32, \n",
    "                                        name = 'generator_seg_input')\n",
    "        inp_boundary_map = tf.keras.layers.Input(shape = self.img_shape[:-1] + (1, ), dtype = tf.float32, \n",
    "                                                 name = 'generator_boundary_map')\n",
    "        inp_encoded = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, \n",
    "                                            name = 'generator_encoded_input')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate(axis = -1)([inp_seg, inp_boundary_map, inp_encoded])\n",
    "        down_sampled_g1_inp = tf.keras.layers.AveragePooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        \n",
    "        # Local Enhancer G2\n",
    "        x = ConvBlock(filters = 32, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                      norm = 'inst_norm', activation = 'relu')(x)\n",
    "        x = ConvBlock(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same', \n",
    "                      norm = 'inst_norm', activation = 'relu')(x)\n",
    "        \n",
    "        \n",
    "        # Global Generator G1\n",
    "        def globalGeneratorG1(x):\n",
    "        \n",
    "            x = ConvBlock(filters = n_chn, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                          norm = 'inst_norm', activation = 'relu')(x)\n",
    "\n",
    "            for _ in range(up_down_block):\n",
    "                n_chn *= 2\n",
    "                x = DownSampleBlock(n_chn)(x)\n",
    "\n",
    "            for _ in range(res_blocks):\n",
    "                x = ResidualBlock(n_chn)(x)\n",
    "\n",
    "            for i in range(up_down_block):\n",
    "                n_chn //= 2\n",
    "                x = UpSampleBlock(n_chn)(x)\n",
    "\n",
    "            out = ConvBlock(filters = 3, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                            norm = 'inst_norm', activation = 'tanh')\n",
    "            return x, out\n",
    "\n",
    "        # Local Enhancer\n",
    "        g1_x, g1_out = globalGeneratorG1(down_sampled_g1_inp)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([x, g1_x])\n",
    "        \n",
    "        for _ in range(3):\n",
    "            x = ResidualBlock(filters = 64)(x)\n",
    "            \n",
    "        x = UpSampleBlock(filters = 32)(x)\n",
    "        x = ConvBlock(filters = 3, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                      norm = 'inst_norm', activation = 'tanh')(x)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_seg, inp_boundary_map, inp_encoded], x, name = 'Generator')\n",
    "        \n",
    "    def encoder(self, n_chn = 32, num_blocks = 4):\n",
    "        inp = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'encoder_input')\n",
    "        \n",
    "        x = ConvBlock(filters = n_chn, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                      norm = 'inst_norm', activation = 'relu')(inp)\n",
    "\n",
    "        # down_sample\n",
    "        for _ in range(num_blocks):\n",
    "            n_chn *= 2\n",
    "            x = DownSampleBlock(filters = n_chn)(x)\n",
    "\n",
    "        # up_sample\n",
    "        for _ in range(num_blocks):\n",
    "            x = UpSampleBlock(filters = n_chn)(x)\n",
    "            n_chn //= 2\n",
    "\n",
    "        x = ConvBlock(filters = 3, kernel_size = (7, 7), strides = (1, 1), padding = ((3, 3), (3, 3)), \n",
    "                      norm = 'inst_norm', activation = 'tanh')(x)\n",
    "        \n",
    "\n",
    "        inst_inp = tf.keras.layers.Input(shape = self.img_shape[:-1] + (self.num_labels, ), dtype = tf.float32, \n",
    "                                         name = 'inst_input')\n",
    "        x = InstanceWiseAveragePooling()([x, inst_inp])\n",
    "            \n",
    "        return tf.keras.models.Model([inp, inst_inp], x, name = 'encoder')\n",
    "    \n",
    "    def discriminator(self, img_shape):\n",
    "        inp_seg = tf.keras.layers.Input(shape = img_shape[:-1] + (self.num_labels, ), dtype = tf.float32, \n",
    "                                    name = f'discriminator_seg_input_{img_shape[0]}x{img_shape[1]}x{self.num_labels}')\n",
    "        inp_boundary_map = tf.keras.layers.Input(shape = img_shape[:-1] + (1, ), dtype = tf.float32, \n",
    "                                                 name = f'discriminator_boundary_map_{img_shape[0]}x{img_shape[1]}x1')\n",
    "        inp_img = tf.keras.layers.Input(shape = img_shape, dtype = tf.float32, \n",
    "                                        name = f'discriminator_img_inp_{img_shape[0]}x{img_shape[1]}x{img_shape[2]}')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate()([inp_seg, inp_boundary_map, inp_img])\n",
    "        \n",
    "        \n",
    "        x1 = ConvBlock(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                       norm = None, activation = 'leaky_relu')(x)\n",
    "        x2 = ConvBlock(filters = 128, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                       norm = 'inst_norm', activation = 'leaky_relu')(x1)\n",
    "        x3 = ConvBlock(filters = 256, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                       norm = 'inst_norm', activation = 'leaky_relu')(x2)\n",
    "        x4 = ConvBlock(filters = 512, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                       norm = 'inst_norm', activation = 'leaky_relu')(x3)\n",
    "        \n",
    "        x5 = ConvBlock(filters = 1, kernel_size = (4, 4), strides = (1, 1), padding = 'same', \n",
    "                       norm = None, activation = None)(x4)\n",
    "        # x5 = tf.keras.layers.Activation('sigmoid')(x5)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_seg, inp_boundary_map, inp_img], [x1, x2, x3, x4, x5], \n",
    "                                     name = f'discriminator_{img_shape[0]}x{img_shape[1]}x{img_shape[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ce4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Pix2PixHD(img_shape = (2048, 1024, 3), num_labels = 35)\n",
    "generator = gan.generator()\n",
    "encoder = gan.encoder()\n",
    "discriminator = gan.discriminator((2048, 1024, 3)) #(1024, 512, 3), (512, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0920e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b428e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses(object):\n",
    "    def __init__(self):\n",
    "        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "        self.__set_vgg\n",
    "        \n",
    "    @property\n",
    "    def __set_vgg(self):\n",
    "        vgg_model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet')\n",
    "        vgg_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "        self.vgg_weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]\n",
    "        self.preprocess_input = tf.keras.applications.vgg19.preprocess_input\n",
    "        \n",
    "        outs = [vgg_model.get_layer(layer).output for layer in vgg_layers]\n",
    "        self.our_model = tf.keras.models.Model(vgg_model.inputs, outs)\n",
    "        \n",
    "    def vgg_loss(self, real, gen):\n",
    "        real_processed = self.preprocess_input((real + 1) * 127.5)\n",
    "        gen_processed = self.preprocess_input((gen + 1) * 127.5)\n",
    "        real_outs = self.our_model(real_processed)\n",
    "        gen_outs = self.our_model(gen_processed)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(len(real_outs)):\n",
    "            loss += tf.math.reduce_mean(tf.abs(real_outs[i] - gen_outs[i])) * self.vgg_weights[i]\n",
    "        return loss\n",
    "\n",
    "    def gan_loss(self, true, pred, gan_loss_type):\n",
    "        if gan_loss_type == 'adversarial':\n",
    "            return self.bce(true, pred)\n",
    "        elif gan_loss_type == 'lsgan':\n",
    "            return tf.math.reduce_mean(tf.math.square(true - pred))\n",
    "    \n",
    "    def feature_matching_loss(self, real, pred):\n",
    "        loss = 0\n",
    "        for r, p in zip(real, pred):\n",
    "            loss += tf.math.reduce_mean(tf.abs(r - p))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, img_shape = (2048, 1024, 3), num_labels = 35, learning_rate = 2e-4, gan_loss_type = 'lsgan'):\n",
    "        self.gan_loss_type = gan_loss_type\n",
    "        \n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        \n",
    "        gan = Pix2PixHD(img_shape = img_shape, num_labels = num_labels)\n",
    "        self.encoder = gan.encoder(n_chn = 32, num_blocks = 4)\n",
    "        self.generator = gan.generator(n_chn = 64, up_down_block = 4, res_blocks = 9)\n",
    "        \n",
    "        self.discriminator_D1 = gan.discriminator(img_shape = img_shape)\n",
    "        self.discriminator_D2 = gan.discriminator(img_shape = (img_shape[0]//2, img_shape[1]//2, img_shape[2]))\n",
    "        self.discriminator_D3 = gan.discriminator(img_shape = (img_shape[0]//4, img_shape[1]//4, img_shape[2]))\n",
    "        \n",
    "        self.losses = Losses()\n",
    "        \n",
    "    def down_scale_img(self, imgs, scale):\n",
    "        outs = []\n",
    "        for img in imgs:\n",
    "            outs.append(tf.image.resize(img, [img.shape[1]//scale, img.shape[2]//scale], \n",
    "                                        tf.image.ResizeMethod.NEAREST_NEIGHBOR))\n",
    "        return outs\n",
    "    \n",
    "    def generator_loss(self, real_img, gen_img, discs_real_outs, discs_gen_outs, lambda_ = 10):\n",
    "        vgg_loss = self.losses.vgg_loss(real_img, gen_img)\n",
    "        gan_loss, fm_loss = 0, 0\n",
    "        for i, (dr, dg) in enumerate(zip(discs_real_outs, discs_gen_outs)): \n",
    "            gan_loss += self.losses.gan_loss(tf.ones_like(dr.pop()), dg.pop(), self.gan_loss_type)\n",
    "            fm_loss += self.losses.feature_matching_loss(dr, dg)\n",
    "        \n",
    "        gan_loss /= (i + 1)\n",
    "        fm_loss /= (i + 1)\n",
    "            \n",
    "        return lambda_ * (vgg_loss + fm_loss) + gan_loss\n",
    "    \n",
    "    def discriminator_loss(self, discs_real_outs, discs_gen_outs):\n",
    "        loss = 0\n",
    "        for dr, dg in zip(discs_real_outs, discs_gen_outs):\n",
    "            loss += self.losses.gan_loss(tf.ones_like(dr.pop()), dr.pop(), self.gan_loss_type)\n",
    "            loss += self.losses.gan_loss(tf.zeros_like(dg.pop()), dg.pop(), self.gan_loss_type)    \n",
    "        return loss / len(discs_real_outs)\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, inp_seg, inp_boundary_map, real_img):\n",
    "        img_shp = real_img.shape\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            enc_out = self.encoder([real_img, inp_seg], training = True)\n",
    "            gen_out = self.generator([inp_seg, inp_boundary_map, enc_out], training = True)\n",
    "            \n",
    "            disc1_real_out = self.discriminator_D1([inp_seg, inp_boundary_map, real_img], training = True)\n",
    "            disc2_real_out = self.discriminator_D2(self.down_scale_img([inp_seg, inp_boundary_map, real_img], 2), \n",
    "                                                   training = True)\n",
    "            disc3_real_out = self.discriminator_D3(self.down_scale_img([inp_seg, inp_boundary_map, real_img], 4), \n",
    "                                                   training = True)\n",
    "            \n",
    "            disc1_gen_out = self.discriminator_D1([inp_seg, inp_boundary_map, gen_out], training = True)\n",
    "            disc2_gen_out = self.discriminator_D2(self.down_scale_img([inp_seg, inp_boundary_map, gen_out], 2), \n",
    "                                                   training = True)\n",
    "            disc3_gen_out = self.discriminator_D3(self.down_scale_img([inp_seg, inp_boundary_map, gen_out], 4), \n",
    "                                                   training = True)\n",
    "            \n",
    "            discs_real_outs = [disc1_real_out, disc2_real_out, disc3_real_out]\n",
    "            discs_gen_outs = [disc1_gen_out, disc2_gen_out, disc3_gen_out]\n",
    "            \n",
    "            gen_loss = self.generator_loss(real_img, gen_out, discs_real_outs, discs_gen_outs)\n",
    "            disc_loss = self.discriminator_loss(discs_real_outs, discs_gen_outs)\n",
    "            \n",
    "        gen_params = self.encoder.trainable_variables + self.generator.trainable_variables\n",
    "        gen_grads = gen_tape.gradient(gen_loss, gen_params)\n",
    "        self.gen_optimizer.apply_gradients(zip(gen_grads, gen_params))\n",
    "        \n",
    "        disc_params = self.discriminator_D1.trainable_variables + self.discriminator_D2.trainable_variables \\\n",
    "                       + self.discriminator_D3.trainable_variables\n",
    "        disc_grads = disc_tape.gradient(disc_loss, disc_params)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, disc_params))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        gen_losses, disc_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts')\n",
    "            for inp_seg, inp_boundary_map, real_img in data:\n",
    "                gen_loss, disc_loss = self.train_step(inp_seg, inp_boundary_map, real_img)\n",
    "                print('.', end = '')\n",
    "                \n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "            print(f'Epoch: {e} Ends\\n')\n",
    "        return {'gen_loss': gen_loss, 'disc_loss': disc_loss}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
