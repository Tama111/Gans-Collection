{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301214f5",
   "metadata": {},
   "source": [
    "# AD-GAN (Attribute Decomposition Gan)\n",
    "\n",
    "This is an attempt to re-implement the paper AD-GAN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/2003.12267.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/menyifang/ADGAN\n",
    "* https://github.com/roimehrez/contextualLoss/blob/master/CX/CSFlow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbc650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdaaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding), (padding, padding)\n",
    "        elif isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            if isinstance(padding[0], tuple) | isinstance(padding[0], list):\n",
    "                self.padding = (padding[0][0], padding[0][1]), (padding[1][0], padding[1][1])\n",
    "            elif isinstance(padding[0], int):\n",
    "                self.padding = (padding[0], padding[0]), (padding[1], padding[1])\n",
    "            else:\n",
    "                raise Exception('')\n",
    "                \n",
    "        else:\n",
    "            raise Exception('')\n",
    "            \n",
    "                \n",
    "    def call(self, inputs):\n",
    "        return tf.pad(inputs, ((0, 0), self.padding[0], self.padding[1], (0, 0)), mode = 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e77628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.weight = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                      trainable = True, name = 'weight')\n",
    "        self.bias = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                    trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.matmul(inputs, self.weight), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e94de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        if isinstance(padding, str):\n",
    "            self.padding = padding.upper()\n",
    "        else:\n",
    "            self.padding = ReflectPadding2D(padding)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.weight = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                      trainable = True, name = 'weight')\n",
    "        self.bias = self.add_weight(shape = (1, 1, 1, self.filters), initializer = 'zeros', \n",
    "                                    trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if isinstance(self.padding, str):\n",
    "            return tf.add(tf.nn.conv2d(inputs, self.weight, self.strides, self.padding), self.bias)\n",
    "        return tf.add(tf.nn.conv2d(self.padding(inputs), self.weight, self.strides, 'VALID'), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65050d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIn(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.inp_filters = input_shape[0][-1]\n",
    "        \n",
    "        self.linear_1 = Linear(neurons = self.inp_filters)\n",
    "        self.linear_2 = Linear(neurons = self.inp_filters)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x, s = inputs\n",
    "        \n",
    "        mean_x = tf.math.reduce_mean(x, axis = [1, 2], keepdims = True)\n",
    "        rstd_x = tf.math.rsqrt(tf.math.reduce_variance(x) + self.epsilon)\n",
    "        inst_norm = (x - mean_x) * rstd_x\n",
    "        \n",
    "        ys = tf.reshape(self.linear_1(s), (-1, 1, 1, self.inp_filters))\n",
    "        yb = tf.reshape(self.linear_2(s), (-1, 1, 1, self.inp_filters))\n",
    "        \n",
    "        out = ys * inst_norm + yb\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ce6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_chn = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.gamma = self.add_weight(shape = (1, 1, 1, inp_chn), initializer = init, \n",
    "                                     trainable = True, name = 'gamma')\n",
    "        self.beta = self.add_weight(shape = (1, 1, 1, inp_chn), initializer = 'zeros', \n",
    "                                    trainable = True, name = 'beta')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean = tf.math.reduce_mean(inputs, axis = [1, 2], keepdims = True)\n",
    "        rstd = tf.math.rsqrt(tf.math.reduce_variance(inputs) + self.epsilon)\n",
    "        inst_norm = (inputs - mean) * rstd\n",
    "        return inst_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c0d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, norm, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm = norm\n",
    "        if norm == 'inst_norm':\n",
    "            self.normalize = InstanceNormalization()\n",
    "        elif norm == 'adain':\n",
    "            self.normalize = AdaIn()\n",
    "        elif norm == 'batch_norm':\n",
    "            self.normalize = tf.keras.layers.BatchNormalization()\n",
    "        elif norm == 'layer_norm':\n",
    "            self.normalize = tf.keras.layers.LayerNormalization()\n",
    "        else:\n",
    "            self.normalize = norm\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if self.norm == 'adain':\n",
    "            assert isinstance(inputs, list) | isinstance(inputs, tuple)\n",
    "            assert len(inputs) == 2\n",
    "        return self.normalize(inputs)\n",
    "    \n",
    "class Activation(tf.keras.layers.Layer):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if activation == 'relu':\n",
    "            self.act = tf.keras.layers.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.act = tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "        elif activation == 'tanh':\n",
    "            self.act = tf.keras.layers.Activation('tanh')\n",
    "        else:\n",
    "            self.act = activation\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return self.act(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b32fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, norm, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear = Linear(neurons = neurons)\n",
    "        if norm is not None:\n",
    "            self.normalize = Normalization(norm = norm)\n",
    "        if activation is not None:\n",
    "            self.activation = Activation(activation = activation)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = self.linear(inputs)\n",
    "        if hasattr(self, 'normalize'):\n",
    "            out = self.normalize(out)\n",
    "        if hasattr(self, 'activation'):\n",
    "            out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "class Conv2DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, norm, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm = norm\n",
    "        self.conv = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding) \n",
    "        \n",
    "        if norm is not None:\n",
    "            self.normalize = Normalization(norm = norm)\n",
    "        if activation is not None:\n",
    "            self.activation = Activation(activation = activation)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.norm == 'adain':\n",
    "            assert len(inputs) == 2\n",
    "            x, s = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "            \n",
    "        out = self.conv(x)\n",
    "        if hasattr(self, 'normalize'):\n",
    "            out = self.normalize([out, s]) if self.norm == 'adain' else self.normalize(out)\n",
    "        if hasattr(self, 'activation'):\n",
    "            out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265cfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim = 256, n_layers = 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(Linear(neurons = dim))\n",
    "            if i != (n_layers-1):\n",
    "                layers.append(Activation(activation = 'relu'))\n",
    "        \n",
    "        self.model = tf.keras.models.Sequential(layers)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ee9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualStyleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, norm, fusion_dim = 256, fusion_layers = 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm = norm\n",
    "        if norm == 'adain':\n",
    "            self.fm = FusionModule(fusion_dim, fusion_layers)\n",
    "            \n",
    "        self.conv_block_1 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                        norm = norm, activation = 'relu')\n",
    "        self.conv_block_2 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                        norm = norm, activation = None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.norm == 'adain':\n",
    "            assert isinstance(inputs, list) | isinstance(inputs, tuple)\n",
    "            assert len(inputs) == 2\n",
    "            x, s = inputs\n",
    "            s = self.fm(s)\n",
    "            \n",
    "            out = self.conv_block_1([x, s])\n",
    "            out = self.conv_block_2([out, s])\n",
    "        else:\n",
    "            x = inputs\n",
    "            out = self.conv_block_1(x)\n",
    "            out = self.conv_block_2(out)\n",
    "            \n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2734b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextureEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, pt_model = None, pt_layers = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet') if pt_model is None else pt_model\n",
    "        model.trainable = False\n",
    "        pt_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1'] if pt_layers is None else pt_layers\n",
    "        \n",
    "        outs = [model.get_layer(layer).output for layer in pt_layers]\n",
    "        self.model = tf.keras.models.Model(model.inputs, outs)\n",
    "        \n",
    "        self.conv1 = Conv2DBlock(filters = dim, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), \n",
    "                                 norm = None, activation = 'relu')\n",
    "        \n",
    "        self.conv2 = Conv2DBlock(filters = dim*2, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1), \n",
    "                                 norm = None, activation = 'relu')\n",
    "        \n",
    "        self.conv3 = Conv2DBlock(filters = dim*4, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1), \n",
    "                                 norm = None, activation = 'relu')\n",
    "        \n",
    "        self.conv4 = Conv2DBlock(filters = dim*8, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1), \n",
    "                                 norm = None, activation = 'relu')\n",
    "        \n",
    "        self.pool = tf.keras.layers.AveragePooling2D()\n",
    "        self.conv = Conv2D(filters = dim, kernel_size = (1, 1), strides = (1, 1), padding = (0, 0))\n",
    "\n",
    "    def pt_model_out(self, inputs):\n",
    "        # preprocess after converting image pixels from 0-255.\n",
    "        preprocess_input = tf.keras.applications.vgg19.preprocess_input((inputs + 1)*127.5)\n",
    "        return self.model(preprocess_input)\n",
    "    \n",
    "    def learnable_encoder(self, inputs, pt_outs):\n",
    "        x = tf.concat([self.conv1(inputs), pt_outs.pop()], axis = -1)\n",
    "        x = tf.concat([self.conv2(x), pt_outs.pop()], axis = -1)\n",
    "        x = tf.concat([self.conv3(x), pt_outs.pop()], axis = -1)\n",
    "        x = tf.concat([self.conv4(x), pt_outs.pop()], axis = -1)\n",
    "        x = self.conv(self.pool(x))\n",
    "        return x\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        pt_out = self.pt_model_out(inputs)\n",
    "        return self.learnable_encoder(inputs, pt_out[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d483067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposedComponentEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, style_dim = 512, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.style_dim = style_dim\n",
    "        self.texture_encoder = TextureEncoder(dim = style_dim//8)\n",
    "        self.linear = LinearBlock(neurons = style_dim, norm = None, activation = 'relu')\n",
    "        \n",
    "    def split_img_masks(self, src, semantics):\n",
    "        seg_labels = semantics.shape[-1]\n",
    "        src = tf.expand_dims(src, axis = -1)\n",
    "        semantics = tf.expand_dims(semantics, axis = -2)\n",
    "        \n",
    "        attributes = tf.split(src * semantics, seg_labels, axis = -1)\n",
    "        attributes = [attr[:, :, :, :, 0] for attr in attributes]\n",
    "            \n",
    "        return attributes\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        assert len(inputs) == 2\n",
    "        # input_0_shape = (b, h, w, 3), input_1_shape = (b, h, w, seg_labels)\n",
    "        src, semantics = inputs\n",
    "        attributes = self.split_img_masks(src, semantics)\n",
    "        \n",
    "        outs = [] \n",
    "        for attr in attributes:\n",
    "            outs.append(self.texture_encoder(attr))\n",
    "            \n",
    "        outs = tf.concat(outs, axis = -1)\n",
    "        outs = tf.reshape(outs, (-1, outs.shape[1] * outs.shape[2] * outs.shape[3]))\n",
    "        outs = self.linear(outs)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fe2d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSamplingBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, norm, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_block = Conv2DBlock(filters = filters, kernel_size = (4, 4), strides = (2, 2), padding = (1, 1), \n",
    "                                      norm = norm, activation = activation)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.conv_block(inputs)\n",
    "    \n",
    "class UpSamplingBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, norm, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.up_sample = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'nearest')\n",
    "        self.conv_block = Conv2DBlock(filters = filters, kernel_size = (5, 5), strides = (1, 1), padding = (2, 2), \n",
    "                                      norm = norm, activation = activation)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.conv_block(self.up_sample(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682a8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_shape, img_pose_shape, img_semantic_shape, dim = 64, n_up_down = 2, n_res = 8):\n",
    "    inp_pose = tf.keras.layers.Input(shape = img_pose_shape, dtype = tf.float32, name = 'pose_input') # b, h, w, points\n",
    "    inp_img = tf.keras.layers.Input(shape = img_pose_shape, dtype = tf.float32, name = 'image_input') # b, h, w, 3\n",
    "    inp_semantic = tf.keras.layers.Input(shape = img_semantic_shape, dtype = tf.float32, name = 'semantic_input')#b,h,w,lbl\n",
    "    \n",
    "    ### Encoder\n",
    "    x = Conv2DBlock(filters = dim, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), norm = 'inst_norm', \n",
    "                    activation = 'relu')(inp_pose)\n",
    "    \n",
    "    for _ in range(n_up_down):\n",
    "        dim *= 2\n",
    "        x = DownSamplingBlock(filters = dim, norm = 'inst_norm', activation = 'relu')(x)\n",
    "        \n",
    "    for _ in range(n_res):\n",
    "        x = ResidualStyleBlock(filters = dim, norm = 'inst_norm')(x)\n",
    "        \n",
    "    ######\n",
    "    \n",
    "    ### DCE (Decomposed Component Encoding)\n",
    "    dce = DecomposedComponentEncoding()([inp_img, inp_semantic])\n",
    "    #####\n",
    "    \n",
    "\n",
    "    ### Decoder\n",
    "    for _ in range(n_res):\n",
    "        x = ResidualStyleBlock(filters = dim, norm = 'adain')([x, dce])\n",
    "\n",
    "    for _ in range(n_up_down):\n",
    "        dim //= 2\n",
    "        x = UpSamplingBlock(filters = dim, norm = 'layer_norm', activation = 'relu')(x)\n",
    "        \n",
    "    x = Conv2DBlock(filters = 3, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), norm = None, \n",
    "                    activation = 'tanh')(x)\n",
    "    #####\n",
    "    \n",
    "    return tf.keras.models.Model([inp_pose, inp_img, inp_semantic], x, name = 'Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdae131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters = None, norm = 'batch_norm', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.norm = norm\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        filters = input_shape[-1] if self.filters is None else self.filters\n",
    "        \n",
    "        self.conv_1 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                  norm = self.norm, activation = 'relu')\n",
    "        self.conv_2 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                  norm = self.norm, activation = None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.conv_2(self.conv_1(inputs)) + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7482a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inpA_shape, inpB_shape, dim = 64, n_down = 2, n_blocks = 6, logits = False):\n",
    "    inpA = tf.keras.layers.Input(shape = inpA_shape, dtype = tf.float32, name = 'inputA')\n",
    "    inpB = tf.keras.layers.Input(shape = inpB_shape, dtype = tf.float32, name = 'inputB')\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([inpA, inpB])\n",
    "    \n",
    "    x = Conv2DBlock(filters = dim, kernel_size = (7, 7), strides = (1, 1), padding = (0, 0), norm = 'batch_norm', \n",
    "                    activation = 'relu')(x)\n",
    "    \n",
    "    for i in range(n_down):\n",
    "        if i < 2:\n",
    "            dim *= 2\n",
    "        x = Conv2DBlock(filters = dim, kernel_size = (3, 3), strides = (2, 2), padding = (1, 1), norm = 'batch_norm', \n",
    "                        activation = 'relu')(x)\n",
    "        \n",
    "    \n",
    "    for _ in range(n_blocks):\n",
    "        x = ResidualBlock(filters = dim, norm = 'batch_norm')(x)\n",
    "        \n",
    "    if logits:\n",
    "        x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "        \n",
    "    return tf.keras.models.Model([inpA, inpB], x, name = 'Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5c88e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptualLoss(object):\n",
    "    def __init__(self, p_model = None, p_layers = None, loss_type = 'l1'):\n",
    "        self.loss_type = loss_type\n",
    "        \n",
    "        model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet') if p_model is None else p_model\n",
    "        model.trainable = False\n",
    "        layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] if p_layers is None else p_layers\n",
    "        \n",
    "        outs = [model.get_layer(layer).output for layer in layers]\n",
    "        self.model = tf.keras.models.Model(model.inputs, outs)\n",
    "        \n",
    "        self.preprocess_input = lambda x: tf.keras.applications.vgg19.preprocess_input(x)\n",
    "        \n",
    "    def __call__(self, real, gen):\n",
    "        # preprocess after converting image pixels from 0-255.\n",
    "        preprocess_real = self.preprocess_input((real + 1)*127.5)\n",
    "        preprocess_gen = self.preprocess_input((gen + 1)*127.5)\n",
    "        \n",
    "        real_outs = self.model(preprocess_real)\n",
    "        gen_outs = self.model(preprocess_gen)\n",
    "        \n",
    "        loss = 0\n",
    "        for r, g in zip(real_outs, gen_outs):\n",
    "            if self.loss_type == 'l1':\n",
    "                loss += tf.math.reduce_mean(tf.math.abs(r - g))\n",
    "            elif self.loss_type == 'l2':\n",
    "                loss += tf.math.reduce_mean(tf.math.square(r - g))\n",
    "            else:\n",
    "                loss += self.loss_type(r, g)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "# References:\n",
    "# https://github.com/menyifang/ADGAN/blob/master/losses/CX_style_loss.py\n",
    "# https://github.com/roimehrez/contextualLoss/blob/master/CX/CSFlow.py\n",
    "class ContextualLoss(object):\n",
    "    def __init__(self, b = 1.0, sigma = 0.1, **kwargs):\n",
    "        super().__init__(self, **kwargs)\n",
    "        self.b = b\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, real, gen):\n",
    "        ### centering by real\n",
    "        mean_r = tf.math.reduce_mean(real, axis = [0, 1, 2], keepdims = True)\n",
    "        real, gen = real - mean_r, gen - mean_r\n",
    "        \n",
    "        ### l2 normalization\n",
    "        real = real * tf.math.rsqrt(tf.math.reduce_mean(tf.square(real), axis = -1, keepdims = True))\n",
    "        gen = gen * tf.math.rsqrt(tf.math.reduce_mean(tf.square(gen), axis = -1, keepdims = True))\n",
    "        \n",
    "        ### patch decomposition\n",
    "        w = tf.transpose(tf.reshape(real, (-1, 1, 1, real.shape[-1])), perm = (1, 2, 3, 0))\n",
    "        i = tf.expand_dims(tf.concat(list(gen), axis = -1), axis = 0)\n",
    "        # cosine similarity calculation\n",
    "        out = tf.nn.conv2d(i, w, (1, 1), 'VALID')\n",
    "        \n",
    "        assert len(list(real)) == len(list(gen))\n",
    "        out = tf.concat(tf.split(out, len(list(real)), axis = -1), axis = 0)\n",
    "        \n",
    "        ### calculate relative distance\n",
    "        raw_dist = (1.0 - out)/2.0\n",
    "        d = tf.math.reduce_min(raw_dist, axis = -1, keepdims = True)[0]\n",
    "        relatice_dist = raw_dist/(d + 1e-5)\n",
    "        \n",
    "        ### calculate CX\n",
    "        cx_exp = tf.math.exp((self.b - relatice_dist) / self.sigma)\n",
    "        cx_sum = tf.math.reduce_sum(cx_exp, axis = -1, keepdims = True)\n",
    "        cx = cx_exp / cx_sum\n",
    "        \n",
    "        cx = tf.math.reduce_max(cx, axis = [1, 2])\n",
    "        cx = tf.math.reduce_mean(cx, axis = 1)\n",
    "        cx = -tf.log(cx)\n",
    "        cx = tf.math.reduce_mean(cx)\n",
    "        return cx\n",
    "    \n",
    "class ReconstructionLoss(object):\n",
    "    def __init__(self, p = 1):\n",
    "        if p == 1:\n",
    "            self.loss = lambda x, y: tf.math.reduce_mean(tf.math.abs(x - y))\n",
    "        elif p == 2:\n",
    "            self.loss = lambda x, y: tf.math.reduce_mean(tf.math.square(x - y))\n",
    "        \n",
    "    def __call__(self, real, gen):\n",
    "        return self.loss(real, gen)\n",
    "    \n",
    "class GANLoss(object):\n",
    "    def __init__(self, loss_type = 'lsgan', from_logits = True):\n",
    "        if loss_type == 'lsgan':\n",
    "            self.loss_object = tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_type == 'adversarial':\n",
    "            self.loss_object = tf.keras.losses.BinaryCrossentropy(from_logits = from_logits)\n",
    "            \n",
    "    def discriminator_loss(self, disc_real_out, disc_gen_out):\n",
    "        real_loss = self.loss_object(tf.ones_like(disc_real_out), disc_real_out)\n",
    "        gen_loss = self.loss_object(tf.zeros_like(disc_gen_out), disc_gen_out)\n",
    "        return real_loss + gen_loss\n",
    "    \n",
    "    def generator_loss(self, disc_gen_out):\n",
    "        return self.loss_object(tf.ones_like(disc_gen_out), disc_gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08301785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, img_shape, img_pose_shape, img_semantic_shape, learning_rate = 0.001, loss_type = 'lsgan', \n",
    "                 from_logits = True):\n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        \n",
    "        self.recon_loss = ReconstructionLoss()\n",
    "        self.cx_loss = ContextualLoss()\n",
    "        self.perceptual_loss = PerceptualLoss()\n",
    "        self.gan_loss = GANLoss(loss_type = loss_type, from_logits = from_logits)\n",
    "        \n",
    "        self.generator = generator(img_shape, img_pose_shape, img_semantic_shape)\n",
    "        self.discriminator_P = discriminator(img_pose_shape, img_shape)\n",
    "        self.discriminator_T = discriminator(img_shape, img_shape)\n",
    "        \n",
    "    def discriminator_loss(self, disc_real_out_P, disc_gen_out_P, disc_real_out_T, disc_gen_out_T):\n",
    "        loss = self.gan_loss.discriminator_loss(disc_real_out_P, disc_gen_out_P)\n",
    "        loss += self.gan_loss.discriminator_loss(disc_real_out_T, disc_gen_out_T)\n",
    "        return loss\n",
    "    \n",
    "    def generator_loss(self, real, gen, disc_gen_out_P, disc_gen_out_T, lambda_rec = 2.0, lambda_per = 2.0, \n",
    "                       lambda_cx = 0.02):\n",
    "        loss = self.recon_loss(real, gen) * lambda_rec\n",
    "        loss += self.perceptual_loss(real, gen) * lambda_per\n",
    "        loss += self.cx_loss(real, gen) * lambda_cx\n",
    "        loss += self.gan_loss.generator_loss(disc_gen_out_P) + self.gan_loss.generator_loss(disc_gen_out_T)\n",
    "        return loss\n",
    "    \n",
    "    def train_step(self, src_img, pose_img, semantic_img, target_img):\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            gen_out = self.generator([pose_img, src_img, semantic_img], training = True)\n",
    "            \n",
    "            disc_real_out_P = self.discriminator_P([pose_img, target_img], training = True)\n",
    "            disc_gen_out_P = self.discriminator_P([pose_img, gen_out], training = True)\n",
    "            disc_real_out_T = self.discriminator_T([src_img, target_img], training = True)\n",
    "            disc_gen_out_T = self.discriminator_T([src_img, gen_out], training = True)\n",
    "            \n",
    "            disc_loss = self.discriminator_loss(disc_real_out_P, disc_gen_out_P, disc_real_out_T, disc_gen_out_T)\n",
    "            gen_loss = self.generator_loss(target_img, gen_out, disc_gen_out_P, disc_gen_out_T)\n",
    "            \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "        \n",
    "        disc_params = self.discriminator_P.trainable_variables + self.discriminator_T.trainable_variables\n",
    "        disc_grads = disc_tape.gradient(disc_loss, disc_params)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, disc_params))\n",
    "\n",
    "        return gen_loss, disc_loss\n",
    "        \n",
    "    def train(self, data, epochs = 1):\n",
    "        gen_losses, disc_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts.')\n",
    "            for src_img, pose_img, semantic_img, target_img in data:\n",
    "                gen_loss, disc_loss = self.train_step(src_img, pose_img, semantic_img, target_img)\n",
    "                print('.', end='')\n",
    "                \n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "            print(f'Epoch: {e} Ends.\\n')\n",
    "            \n",
    "        return {'gen_losses': gen_losses, 'disc_losses': disc_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd7635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
