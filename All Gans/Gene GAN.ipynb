{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67307812",
   "metadata": {},
   "source": [
    "# Gene Gan\n",
    "\n",
    "This is an attempt to re-implement the paper Gene-GAN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1705.04932v1.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/Prinsphield/GeneGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33749d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "042cb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        self.B = self.add_weight(shape = (1, 1, 1, inp_filters), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, self.B)\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, img_shape):\n",
    "        self.img_shape = img_shape\n",
    "        self.encoded_shape = self.encoder.output_shape[0][1:]\n",
    "        \n",
    "    @property\n",
    "    def encoder(self):\n",
    "        inp = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'encoder')\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(inp)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 265, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        # out_1 contains background info & out_2 contains object info \n",
    "        out_1, out_2 = x[:, :, :, :256], x[:, :, :, 256:]\n",
    "        return tf.keras.models.Model(inp, [out_1, out_2], name = 'encoder')\n",
    "        \n",
    "    @property\n",
    "    def decoder(self):\n",
    "        inp_bckgr_encoded = tf.keras.layers.Input(shape = self.encoded_shape, dtype = tf.float32, \n",
    "                                                  name = 'decoder_background_info_input')\n",
    "        inp_object_encoded = tf.keras.layers.Input(shape = self.encoded_shape, dtype = tf.float32, \n",
    "                                                   name = 'decoder_object_info_input')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate(axis = -1)([inp_bckgr_encoded, inp_object_encoded])\n",
    "        \n",
    "        x = tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = AddNoise()(x)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_bckgr_encoded, inp_object_encoded], x, name = 'Decoder')\n",
    "    \n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        inp = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'discriminator_input')\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(inp)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 256, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(units = 1)(x)\n",
    "        #x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "        \n",
    "        return tf.keras.models.Model(inp, x, name = 'Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc25f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses(object):\n",
    "    def __init__(self):\n",
    "        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "    \n",
    "    def reconstruction_loss(self, real, re_gen):\n",
    "        return tf.math.reduce_mean(tf.math.abs(real, re_gen))\n",
    "    \n",
    "    def nulling_loss(self, eps):\n",
    "        return tf.math.reduce_mean(tf.abs(eps))\n",
    "    \n",
    "    def gen_log_loss(self, disc_out):\n",
    "        #return -tf.math.reduce_mean(tf.math.log(disc_out))\n",
    "        return self.bce(tf.ones_like(disc_out), disc_out)\n",
    "    \n",
    "    def parallelogram_loss(self, au, b0, a0, bu):\n",
    "        return tf.math.reduce_mean(tf.math.abs(au + b0 - a0 - bu))\n",
    "    \n",
    "    def disc_log_loss(self, disc_out_1, disc_out_2):\n",
    "        real_loss = self.bce(tf.ones_like(disc_out_1), disc_out_1)\n",
    "        fake_loss = self.bce(tf.zeros_like(disc_out_2), disc_out_2)\n",
    "        return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38fee918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, img_shape, learning_rate = 5e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gen_opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "        self.disc_opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "        \n",
    "        gan = GAN(img_shape = img_shape)\n",
    "        self.encoder = gan.encoder\n",
    "        self.decoder = gan.decoder\n",
    "        self.discriminator = gan.discriminator\n",
    "        \n",
    "        self.losses = Losses()\n",
    "        \n",
    "    @property\n",
    "    def train_step(self, img_au, img_b0):\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            gen_a, gen_u = self.encoder(img_au, training = True)\n",
    "            gen_b, gen_eps = self.encoder(img_b0, training = True)\n",
    "            \n",
    "            gen_a0 = self.decoder([gen_a, tf.zeros_like(gen_eps)], training = True)\n",
    "            gen_bu = self.decoder([gen_b, gen_u], training = True)\n",
    "            \n",
    "            re_gen_au = self.decoder([gen_a, gen_u], training = True)\n",
    "            re_gen_b0 = self.decoder([gen_b, tf.zeros_like(gen_eps)], training = True)\n",
    "            \n",
    "            disc_au = self.discriminator(img_au, training = True)\n",
    "            disc_a0 = self.discriminator(gen_a0, training = True)\n",
    "            disc_b0 = self.discriminator(img_b0, training = True)\n",
    "            disc_bu = self.discriminator(gen_bu, training = True)\n",
    "            \n",
    "            gen_loss = self.losses.reconstruction_loss(img_au, re_gen_au)\n",
    "            gen_loss += self.losses.reconstruction_loss(img_b0, re_gen_b0)\n",
    "            gen_loss += (self.losses.gen_log_loss(disc_a0) + self.losses.gen_log_loss(disc_bu))\n",
    "            gen_loss += self.losses.nulling_loss(gen_eps)            \n",
    "            gen_loss += self.losses.parallelogram_loss(img_au, img_b0, gen_a0, gen_bu)\n",
    "            \n",
    "            disc_loss = self.losses.disc_log_loss(disc_au, disc_bu)\n",
    "            disc_loss += self.losses.disc_log_loss(disc_a0, disc_b0)\n",
    "            \n",
    "        gen_params = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "        gen_grads = gen_tape.gradient(gen_loss, gen_params)\n",
    "        self.gen_opt.apply_gradients(zip(gen_grads, gen_params))\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(dis_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_opt.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        gen_losses, disc_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts')\n",
    "            for img_au, img_b0 in data:\n",
    "                gen_loss, disc_loss = self.train_step(img_au, img_b0)\n",
    "                print('.', end = '')\n",
    "                \n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Losss: {disc_loss}')\n",
    "            print(f'Epoch: {e} Ends\\n')\n",
    "            \n",
    "        return {'gen_losses': gen_losses, 'disc_losses': disc_losses}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b30a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
