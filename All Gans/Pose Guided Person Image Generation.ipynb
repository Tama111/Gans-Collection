{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558c0805",
   "metadata": {},
   "source": [
    "# Pose Guided Person Image Generation (PG²)\n",
    "\n",
    "This is an attempt to re-implement the paper PG²\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1705.09368.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/charliememory/Pose-Guided-Person-Image-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd72908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82663928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "        self.act1 = tf.keras.layers.ReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "        self.act2 = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.act1(self.conv1(inputs))\n",
    "        x = self.act2(self.conv2(x))\n",
    "        out = tf.add(x, inputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4a8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, img_shape, pose_img_shape):\n",
    "        self.img_shape = img_shape\n",
    "        self.pose_img_shape = pose_img_shape\n",
    "        \n",
    "    def __down_sample(self, x, filters, name):\n",
    "        \n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (2, 2), padding = 'same'),\n",
    "            tf.keras.layers.ReLU()\n",
    "        ], name = name)\n",
    "        \n",
    "        #x = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        #x = tf.keras.layers.ReLU()(x)\n",
    "        #return x\n",
    "        return model(x)\n",
    "    \n",
    "    def __up_sample(self, x, filters, name):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.UpSampling2D(size = (2, 2)),\n",
    "            tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "        ], name = name)\n",
    "        return model(x)\n",
    "    \n",
    "    def __conv_block(self, x, filters, name):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "        ], name = name)\n",
    "        return model(x)\n",
    "        \n",
    "    @property\n",
    "    def stage1_generator(self):\n",
    "        \n",
    "        inp_img = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'stage1_generator_inp_img')\n",
    "        inp_pose = tf.keras.layers.Input(shape = self.pose_img_shape, dtype = tf.float32, \n",
    "                                         name = 'stage1_generator_pose_img')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate(axis = -1)([inp_img, inp_pose])\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        # Encoder\n",
    "        e0 = ResBlock(filters = 32)(x)\n",
    "        \n",
    "        e1 = self.__down_sample(x = e0, filters = 64, name = 'g1_down_sample_encoder_1')\n",
    "        e1 = ResBlock(filters = 64)(e1)\n",
    "        \n",
    "        e2 = self.__down_sample(x = e1, filters = 64, name = 'g1_down_sample_encoder_2')\n",
    "        e2 = ResBlock(filters = 64)(e2)\n",
    "        \n",
    "        e3 = self.__down_sample(x = e2, filters = 128, name = 'g1_down_sample_encoder_3')\n",
    "        e3 = ResBlock(filters = 128)(e3)\n",
    "        \n",
    "        e4 = self.__down_sample(x = e3, filters = 128, name = 'g1_down_sample_encoder_4')\n",
    "        e4 = ResBlock(filters = 128)(e4)\n",
    "        \n",
    "        e5 = self.__down_sample(x = e4, filters = 256, name = 'g1_down_sample_encoder_5')\n",
    "        e5 = ResBlock(filters = 256)(e5)\n",
    "        \n",
    "        #e6 = self.__down_sample(x = e5, filters = 256)\n",
    "        #e6 = ResBlock(filters = 256)(e6)\n",
    "        ###\n",
    "        \n",
    "        # Bottle neck\n",
    "        b = tf.keras.layers.Flatten()(e5)\n",
    "        b = tf.keras.layers.Dense(units = 256)(b)\n",
    "        b = tf.keras.layers.Dense(units = e5.get_shape()[1] * e5.get_shape()[2] * e5.get_shape()[3])(b)\n",
    "        b = tf.keras.layers.Reshape((e5.get_shape()[1], e5.get_shape()[2], e5.get_shape()[3]))(b)\n",
    "        ###\n",
    "        \n",
    "        #d1 = tf.keras.layers.UpSampling2D(size = (2, 2))(b)\n",
    "        d0 = ResBlock(filters = 256)(b)\n",
    "        d0 = tf.keras.layers.Concatenate()([d0, e5])\n",
    "        \n",
    "        d1 = self.__up_sample(x = d0, filters = 128, name = 'g1_up_sample_decoder_1')\n",
    "        d1 = ResBlock(filters = 128)(d1)\n",
    "        d1 = tf.keras.layers.Concatenate()([d1, e4])\n",
    "        \n",
    "        d2 = self.__up_sample(x = d1, filters = 128, name = 'g1_up_sample_decoder_2')\n",
    "        d2 = ResBlock(filters = 128)(d2)\n",
    "        d2 = tf.keras.layers.Concatenate()([d2, e3])\n",
    "        \n",
    "        d3 = self.__up_sample(x = d2, filters = 64, name = 'g1_up_sample_decoder_3')\n",
    "        d3 = ResBlock(filters = 64)(d3)\n",
    "        d3 = tf.keras.layers.Concatenate()([d3, e2])\n",
    "        \n",
    "        d4 = self.__up_sample(x = d3, filters = 64, name = 'g1_up_sample_decoder_4')\n",
    "        d4 = ResBlock(filters = 64)(d4)\n",
    "        d4 = tf.keras.layers.Concatenate()([d4, e1])\n",
    "        \n",
    "        d5 = self.__up_sample(x = d4, filters = 32, name = 'g1_up_sample_decoder_5')\n",
    "        d5 = ResBlock(filters = 32)(d5)\n",
    "        d5 = tf.keras.layers.Concatenate()([d5, e0])\n",
    "        ###\n",
    "        \n",
    "        out = tf.keras.layers.Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(d5)\n",
    "        out = tf.keras.layers.Activation('tanh')(out)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_img, inp_pose], out, name = 'stage2_generator')\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def stage2_generator(self):\n",
    "        \n",
    "        inp_img = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'stage2_generator_inp_img')\n",
    "        inp_coarse = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, \n",
    "                                           name = 'stage2_generator_inp_coarse')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate()([inp_img, inp_coarse])\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        # Encoder\n",
    "        e0 = self.__conv_block(x, filters = 64, name = 'g2_conv_block_encoder_0')\n",
    "        \n",
    "        e1 = self.__down_sample(e0, filters = 64, name = 'g2_down_sample_encoder_1')\n",
    "        e1 = self.__conv_block(e1, filters = 64, name = 'g2_conv_block_encoder_1')\n",
    "        \n",
    "        e2 = self.__down_sample(e1, filters = 128, name = 'g2_down_sample_encoder_2')\n",
    "        e2 = self.__conv_block(e2, filters = 128, name = 'g2_conv_block_encoder_2')\n",
    "        \n",
    "        e3 = self.__down_sample(e2, filters = 128, name = 'g2_down_sample_encoder_3')\n",
    "        e3 = self.__conv_block(e3, filters = 128, name = 'g2_conv_block_encoder_3')\n",
    "        \n",
    "        e4 = self.__down_sample(e3, filters = 256, name = 'g2_down_sample_encoder_4')\n",
    "        e4 = self.__conv_block(e4, filters = 256, name = 'g2_conv_block_encoder_4')\n",
    "        ###\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.__conv_block(e4, filters = 256, name = 'g2_conv_block_bottleneck')\n",
    "        \n",
    "        # Decoder\n",
    "        d0 = self.__conv_block(b, filters = 256, name = 'g2_conv_block_decoder_0')\n",
    "        d0 = tf.keras.layers.Concatenate()([d0, e4])\n",
    "        \n",
    "        d1 = self.__up_sample(d0, filters = 128, name = 'g2_up_sample_decoder_1')\n",
    "        d1 = self.__conv_block(d1, filters = 128, name = 'g2_conv_block_decoder_1')\n",
    "        d1 = tf.keras.layers.Concatenate()([d1, e3])\n",
    "        \n",
    "        d2 = self.__up_sample(d1, filters = 128, name = 'g2_up_sample_decoder_2')\n",
    "        d2 = self.__conv_block(d2, filters = 128, name = 'g2_conv_block_decoder_2')\n",
    "        d2 = tf.keras.layers.Concatenate()([d2, e2])\n",
    "        \n",
    "        d3 = self.__up_sample(d2, filters = 64, name = 'g2_up_sample_decoder_3')\n",
    "        d3 = self.__conv_block(d3, filters = 64, name = 'g2_conv_block_decoder_3')\n",
    "        d3 = tf.keras.layers.Concatenate()([d3, e1])\n",
    "        \n",
    "        d4 = self.__up_sample(d3, filters = 64, name = 'g2_up_sample_decoder_4')\n",
    "        d4 = self.__conv_block(d4, filters = 64, name = 'g2_conv_block_decoder_4')\n",
    "        d4 = tf.keras.layers.Concatenate()([d4, e0])\n",
    "        ###\n",
    "        \n",
    "        out = tf.keras.layers.Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(d4)\n",
    "        out = tf.keras.layers.Activation('tanh')(out)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_img, inp_coarse], out)\n",
    "    \n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        inp_img_a = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'discriminator_real_input')\n",
    "        inp_img_b = tf.keras.layers.Input(shape = self.img_shape, dtype = tf.float32, name = 'discriminator_gen_input')\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate()([inp_img_a, inp_img_b])\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(units = 1)(x)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_img_a, inp_img_b], x, name = 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412cc9da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan = GAN((256, 256, 3), (256, 256, 1))\n",
    "# gan.stage2_generator.summary()\n",
    "# gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c2ef81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(gan.stage2_generator, dpi = 64, show_shapes = True)\n",
    "# tf.keras.utils.plot_model(gan.discriminator, dpi = 64, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7e6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses(object):\n",
    "    def __init__(self, LAMBDA = 1):\n",
    "        self.LAMBDA = LAMBDA\n",
    "        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "        \n",
    "    def pose_mask_loss(self, gen_out, tar_img, pose_mask):\n",
    "        return tf.math.reduce_mean(tf.math.abs((gen_out - tar_img) * (1 + pose_mask)))\n",
    "    \n",
    "    def discriminator_adversarial_loss(self, disc_real_out, disc_gen_out):\n",
    "        real_loss = self.bce(tf.ones_like(disc_real_out), disc_real_out)\n",
    "        gen_loss = self.bce(tf.zeros_like(disc_gen_out), disc_gen_out)\n",
    "        return real_loss + gen_loss\n",
    "    \n",
    "    def generator_adversarial_loss(self, disc_gen_out):\n",
    "        return self.bce(tf.ones_like(disc_gen_out), disc_gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f0f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, learning_rate = 2e-5, img_shape = (256, 256, 3), pose_img_shape = (256, 256, 1)):\n",
    "        self.gen1_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.gen2_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        \n",
    "        gan = GAN(img_shape = img_shape, pose_img_shape = pose_img_shape)\n",
    "        self.generator_1 = gan.stage1_generator\n",
    "        self.generator_2 = gan.stage2_generator\n",
    "        self.discriminator = gan.discriminator\n",
    "        \n",
    "        self.losses = Losses()\n",
    "        \n",
    "    @property\n",
    "    def train_step(self, inp_img, pose_inp_img, tar_img, pose_mask):\n",
    "        \n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            gen1_out = self.generator_1([inp_img, pose_inp_img], training = True)\n",
    "            gen2_out = self.generator_2([inp_img, gen1_out], training = True)\n",
    "            \n",
    "            disc_real_out = self.discriminator([inp_img, tar_img], training = True)\n",
    "            disc_gen_out = self.discriminator([inp_img, gen2_out], training = True)\n",
    "            \n",
    "            gen1_loss = self.losses.pose_mask_loss(gen1_out, tar_img, pose_mask) \n",
    "            #gen1_loss =+ self.losses.generator_adversarial_loss(self.discriminator([inp_img, gen1_out], training = True))\n",
    "            #gen1_loss =+ self.losses.generator_adversarial_loss(disc_gen_out)\n",
    "            \n",
    "            gen2_loss = self.losses.pose_mask_loss(gen2_out, tar_img, pose_mask) * self.losses.LAMDA\n",
    "            gen2_loss += self.losses.generator_adversarial_loss(disc_gen_out)\n",
    "            \n",
    "            disc_loss = self.losses.discriminator_adversarial_loss(disc_real_out, disc_gen_out)\n",
    "            \n",
    "        gen1_grads = tape.gradient(gen1_loss, self.generator_1.trainable_variables)\n",
    "        self.gen1_optimizer.apply_gradients(zip(gen1_grads, self.generator_1.trainable_variables))\n",
    "        \n",
    "        gen2_grads = tape.gradient(gen2_loss, self.generator_2.trainable_variables)\n",
    "        self.gen2_optimizer.apply_gradients(zip(gen2_grads, self.generator_2.trainable_variables))\n",
    "        \n",
    "        disc_grads = tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return gen1_loss, gen2_loss, disc_loss\n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        gen1_losses, gen2_losses, disc_losses = [], [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts')\n",
    "            for inp_img, pose_inp_img, tar_img, pose_mask in data:\n",
    "                gen1_loss, gen2_loss, disc_loss = self.train_step(inp_img, pose_inp_img, tar_img, pose_mask)\n",
    "                print('.', end = '')\n",
    "                \n",
    "            gen1_losses.append(gen1_loss)\n",
    "            gen2_losses.append(gen2_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator(1) Loss: {gen1_loss} \\t Generator(2) Loss: {gen2_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "            print(f'Epochs: {e} Ends \\n')\n",
    "        \n",
    "        return {'gen1_losses': gen1_losses, 'gen2_losses': gen2_losses, 'disc_losses': disc_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9163a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "# trainer.train(dataset, epochs = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
