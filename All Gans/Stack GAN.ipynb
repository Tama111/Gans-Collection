{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6c0f13",
   "metadata": {},
   "source": [
    "# Stack Gan\n",
    "\n",
    "This is an attempt to re-implement the paper Stack-GAN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1612.03242.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/hanzhanggit/StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac61b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e442437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, gain = tf.sqrt(2.0), use_bias = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "        self.gain = gain\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                 trainable = True, name = 'Linear_weight')\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.B = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                     trainable = True, name = 'Linear_bias')\n",
    "        \n",
    "        self.wscale = self.gain * tf.math.rsqrt(tf.cast(inp_neurons, tf.float32))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = tf.matmul(inputs, self.W * self.wscale)\n",
    "        if self.use_bias:\n",
    "            out = tf.add(out, self.B)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c694d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, gain = tf.sqrt(2.0), use_bias = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = 'SAME' if (kernel_size[0] - 1)//2 else 'VALID'\n",
    "        self.gain = gain\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.kernel = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                      trainable = True, name = 'Conv2D_kernel')\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape = (1, self.filters), initializer = 'zeros', \n",
    "                                        trainable = True, name = 'Conv2D_bias')\n",
    "        \n",
    "        fan_in = tf.cast(self.kernel_size[0] * self.kernel_size[1] * inp_filters, tf.float32)\n",
    "        self.wscale = self.gain * tf.math.rsqrt(fan_in)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.conv2d(inputs, self.kernel * self.wscale, self.strides, self.padding, 'NHWC')\n",
    "        if self.use_bias:\n",
    "            out = tf.add(out, self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b583cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditioningAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mu, sigma = inputs\n",
    "        epsilon = tf.random.normal(tf.shape(mu), mean=0.0, stddev=1.0)\n",
    "\n",
    "        return mu + tf.exp(sigma * 0.5) * epsilon\n",
    "    \n",
    "class SpatialRepLication(tf.keras.layers.Layer):\n",
    "    def __init__(self, rep_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rep_dim = rep_dim\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, (-1, 1, 1, inputs.shape[-1]))\n",
    "        x = tf.tile(x, [-1, self.rep_dim, self.rep_dim, 1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39842e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_generator(embed_dim = 1024, noise_dim = 100, ca_dim = 256):\n",
    "    inp_text_embed = tf.keras.layers.Input(shape = (embed_dim), dtype = tf.float32, \n",
    "                                           name = 'stage1_generator_text_embed_inp')\n",
    "    inp_noise = tf.keras.layers.Input(shape = (noise_dim), dtype = tf.float32, name = 'stage1_generator_noise_inp')\n",
    "    \n",
    "    mu = tf.keras.layers.ReLU()(Linear(neurons = ca_dim//2)(inp_text_embed))\n",
    "    sigma = tf.keras.layers.ReLU()(Linear(neurons = ca_dim//2)(inp_text_embed))\n",
    "    \n",
    "    x = ConditioningAugmentation()([mu, sigma])\n",
    "    x = tf.keras.layers.Concatenate()([x, inp_noise])\n",
    "    \n",
    "    x = Linear(neurons = 4 * 4 * 1024)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Reshape((4, 4, 1024))(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
    "    x = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), use_bias = True)(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    return tf.keras.models.Model([inp_text_embed, inp_noise], [mu, sigma, x], name = 'stage1_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bfffeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_generator(embed_dim = 1024, ca_dim = 256, inp_img_dim = 64):\n",
    "    inp_text_embed = tf.keras.layers.Input(shape = (embed_dim), dtype = tf.float32, \n",
    "                                           name = 'stage1_generator_text_embed_inp')\n",
    "    inp_stage1_img = tf.keras.layers.Input(shape = (inp_img_dim, inp_img_dim, 3), dtype = tf.float32, \n",
    "                                           name = 'stage2_generator_stage1_img_inp')\n",
    "    \n",
    "    # Conditioning Augmentation\n",
    "    mu = tf.keras.layers.ReLU()(Linear(neurons = ca_dim//2)(inp_text_embed))\n",
    "    sigma = tf.keras.layers.ReLU()(Linear(neurons = ca_dim//2)(inp_text_embed))\n",
    "    \n",
    "    ca = ConditioningAugmentation()([mu, sigma])\n",
    "    ca = SpatialRepLication(rep_dim = 16)(ca)\n",
    "    \n",
    "    # Downsampling\n",
    "    x = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), use_bias = True)(inp_stage1_img)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 256, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # ResBlock\n",
    "    out_r = tf.keras.layers.Concatenate(axis = -1)([x, ca])\n",
    "    \n",
    "    out_r = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out_r)\n",
    "    out_r = tf.keras.layers.BatchNormalization()(out_r)\n",
    "    out_r = tf.keras.layers.ReLU()(out_r)\n",
    "    \n",
    "    #1\n",
    "    out_r1 = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out_r)\n",
    "    out_r1 = tf.keras.layers.BatchNormalization()(out_r1)\n",
    "    out_r1 = tf.keras.layers.ReLU()(out_r1)\n",
    "    \n",
    "    out_r1 = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out_r1)\n",
    "    out_r1 = tf.keras.layers.BatchNormalization()(out_r1)\n",
    "    out_r1 = tf.keras.layers.ReLU()(out_r1 + out_r)\n",
    "    \n",
    "    #2\n",
    "    out_r2 = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out_r1)\n",
    "    out_r2 = tf.keras.layers.BatchNormalization()(out_r2)\n",
    "    out_r2 = tf.keras.layers.ReLU()(out_r2)\n",
    "    \n",
    "    out_r2 = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out_r2)\n",
    "    out_r2 = tf.keras.layers.BatchNormalization()(out_r2)\n",
    "    out = tf.keras.layers.ReLU()(out_r2 + out_r1)\n",
    "    \n",
    "    # UpSampling\n",
    "    out = tf.keras.layers.UpSampling2D(size = (2, 2))(out)\n",
    "    out = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    \n",
    "    out = tf.keras.layers.UpSampling2D(size = (2, 2))(out)\n",
    "    out = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    \n",
    "    out = tf.keras.layers.UpSampling2D(size = (2, 2))(out)\n",
    "    out = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    \n",
    "    out = tf.keras.layers.UpSampling2D(size = (2, 2))(out)\n",
    "    out = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    \n",
    "    out = Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), use_bias = True)(out)\n",
    "    out = tf.keras.layers.Activation('tanh')(out)\n",
    "    \n",
    "    return tf.keras.models.Model([inp_stage1_img, inp_text_embed], [mu, sigma, out], name = 'stage2_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e601f6c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stage1_discriminator(img_inp = 64, mu_dim = 128):\n",
    "    inp = tf.keras.layers.Input(shape = (img_inp, img_inp, 3), dtype = tf.float32, name = 'stage1_discriminator_input')\n",
    "    mu_inp = tf.keras.layers.Input(shape = (mu_dim), dtype = tf.float32, name = 'stage1_discriminator_mu_input')\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), use_bias = True)(inp)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    mu = SpatialRepLication(rep_dim = 4)(mu_inp)\n",
    "    out = tf.keras.layers.Concatenate(axis = -1)([x, mu])\n",
    "    \n",
    "    out = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.LeakyReLU(alpha = 0.2)(out)\n",
    "    \n",
    "    out = Conv2D(filters = 1, kernel_size = (4, 4), strides = (4, 4), use_bias = True)(out)\n",
    "    return tf.keras.models.Model([inp, mu_inp], out, name = 'stage1_discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0b93f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_discriminator(img_inp = 256, mu_dim = 128):\n",
    "    inp = tf.keras.layers.Input(shape = (img_inp, img_inp, 3), dtype = tf.float32, name = 'stage2_discriminator_input')\n",
    "    mu_inp = tf.keras.layers.Input(shape = (mu_dim), dtype = tf.float32, name = 'stage2_discriminator_mu_input')\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), use_bias = True)(inp)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 256, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 1024, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 2048, kernel_size = (4, 4), strides = (2, 2), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 1024, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    mu = SpatialRepLication(rep_dim = 4)(mu_inp)\n",
    "    out = tf.keras.layers.Concatenate(axis = -1)([x, mu])\n",
    "    \n",
    "    out = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), use_bias = False)(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.LeakyReLU(alpha = 0.2)(out)\n",
    "    \n",
    "    out = Conv2D(filters = 1, kernel_size = (4, 4), strides = (4, 4), use_bias = False)(out)\n",
    "    return tf.keras.models.Model([inp, mu_inp], out, name = 'stage2_discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
