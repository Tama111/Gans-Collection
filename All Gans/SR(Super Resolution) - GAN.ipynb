{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb06559d",
   "metadata": {},
   "source": [
    "# SR-Gan (Super Resolution Gan)\n",
    "\n",
    "This is an attempt to re-implement the paper SR-GAN\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1609.04802.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://www.youtube.com/watch?v=fx-rXMcKlQc\n",
    "* https://arxiv.org/pdf/1609.05158.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a6bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fb7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_img_size = 64\n",
    "hr_img_size = lr_img_size * 4\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97c2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82b9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, \n",
    "                                            padding = padding)\n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.prelu = tf.keras.layers.PReLU()\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, \n",
    "                                            padding = padding)\n",
    "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.prelu(self.batch_norm1(self.conv1(inputs)))\n",
    "        x = self.batch_norm2(self.conv2(x))\n",
    "        return tf.add(x, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e304d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelShufflerx2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inp_shape = inputs.shape\n",
    "        \n",
    "        out = tf.reshape(inputs, (-1, inp_shape[1], inp_shape[2], inp_shape[3]//4, 4))\n",
    "        out = tf.reshape(out, (-1, inp_shape[1], inp_shape[2], inp_shape[3]//4, 2, 2))\n",
    "        out = tf.transpose(out, perm = [0, 1, 4, 2, 5, 3])\n",
    "        out = tf.reshape(out, (-1, inp_shape[1]*2, inp_shape[2]*2, inp_shape[3]//4))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff33790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_size = lr_img_size, channels = channels, num_res_block = 16):\n",
    "    inp = tf.keras.layers.Input(shape = (img_size, img_size, channels), dtype = tf.float32, \n",
    "                                name = f'Generator_input_{img_size}x{img_size}x{channels}')\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (9, 9), strides = (1, 1), padding = 'same')(inp)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    \n",
    "    r = x\n",
    "    for _ in range(num_res_block):\n",
    "        r = ResidualBlock()(r)\n",
    "        \n",
    "    out = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(r)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.add([out, x])\n",
    "    \n",
    "    for _ in range(2):\n",
    "        out = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(out)\n",
    "        out = PixelShufflerx2()(out)\n",
    "        out = tf.keras.layers.PReLU()(out)\n",
    "        \n",
    "    out = tf.keras.layers.Conv2D(filters = 3, kernel_size = (9, 9), strides = (1, 1), padding = 'same')(out)\n",
    "    out = tf.keras.layers.Activation('tanh')(out)\n",
    "    return tf.keras.models.Model(inp, out, name = 'Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51855d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = generator()\n",
    "# gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd06a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img_size = hr_img_size, channels = channels):\n",
    "    inp = tf.keras.layers.Input(shape = (img_size, img_size, channels), dtype = tf.float32, \n",
    "                                name = f'discriminator_input_{img_size}x{img_size}x{channels}')\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(inp)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units = 1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    x = tf.keras.layers.Dense(units = 1)(x)\n",
    "    #x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inp, x, name = 'Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f0797e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disc = discriminator()\n",
    "# disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82864738",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "def get_vgg_model(out_layer = 'block5_conv4'):\n",
    "    vgg_model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet')\n",
    "    vgg_model.trainable = False\n",
    "    \n",
    "    outputs = vgg_model.get_layer(out_layer).output\n",
    "    return tf.keras.models.Model(vgg_model.inputs, outputs, name = 'VGG_model')\n",
    "vgg_model = get_vgg_model()\n",
    "vgg_model.trainable = False\n",
    "\n",
    "def mse_loss(real, gen_img):\n",
    "    return tf.math.reduce_mean(tf.math.square(real - gen_img))\n",
    "\n",
    "def discriminator_loss(disc_real_out, disc_gen_out):\n",
    "    real_loss = bce(tf.ones_like(disc_real_out), disc_real_out)\n",
    "    gen_loss = bce(tf.zeros_like(disc_gen_out), disc_gen_out)\n",
    "    return real_loss + gen_loss\n",
    "\n",
    "def generator_loss(disc_gen_out):\n",
    "    return bce(tf.ones_like(disc_gen_out), disc_gen_out)\n",
    "\n",
    "def vgg_loss(real, gen_img, rescale_factor = 1/12.75):\n",
    "    # real and gen_img, pixel range [-1, 1]\n",
    "    real_preprocessed = tf.keras.applications.vgg19.preprocess_input((real + 1)*127.5) * rescale_factor\n",
    "    gen_preprocessed = tf.keras.applications.vgg19.preprocess_input((gen_img + 1)*127.5) * rescale_factor\n",
    "    \n",
    "    real_out = vgg_model(real_preprocessed)\n",
    "    gen_out = vgg_model(gen_preprocessed)\n",
    "    \n",
    "    return mse(real_out, gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1420c5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(learning_rate = 1e-4, beta_1 = 0.9)\n",
    "disc_opt = tf.keras.optimizers.Adam(learning_rate = 1e-4, beta_1 = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88655374",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr_img, hr_img):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_out = gen(lr_img, training = True)\n",
    "        \n",
    "        disc_real_out = disc(hr_img, training = True)\n",
    "        disc_gen_out = disc(gen_out, training = True)\n",
    "        \n",
    "        disc_loss = discriminator_loss(disc_real_out, disc_gen_out)\n",
    "        gen_loss = 6e-3 * vgg_loss(hr_img, gen_out) + 3e-3 * generator_loss(disc_gen_out)\n",
    "        \n",
    "    gen_grads = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    gen_opt.apply_gradients(zip(gen_grads, gen.trainable_variables))\n",
    "    \n",
    "    disc_grads = disc_tape.gradient(disc_loss, disc.trainable_variables)\n",
    "    disc_opt.apply_gradients(zip(disc_grads, disc.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f52616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, epochs = 1):\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print(f'Epoch: {e} Starts')\n",
    "        for lr_img, hr_img in data:\n",
    "            gen_loss, disc_loss = train_step(lr_img, hr_img)\n",
    "            print('.', end='')\n",
    "        \n",
    "        print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "        print(f'Epoch: {e} Ends\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e7018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
