{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5ad95e",
   "metadata": {},
   "source": [
    "# Pose Transfer\n",
    "\n",
    "This is an attempt to re-implement the paper pose transfer\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1904.03349.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/tengteng95/Pose-Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23a612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2292bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.gamma = self.add_weight(shape = (1, 1, 1, inp_filters), initializer = init, \n",
    "                                     trainable = True, name = 'gamma')\n",
    "        self.beta = self.add_weight(shape = (1, 1, 1, inp_filters), initializer = 'zeros', \n",
    "                                    trainable = True, name = 'beta')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean_x = tf.math.reduce_mean(inputs, axis = [1, 2], keepdims = True)\n",
    "        rstd_x = tf.math.rsqrt(tf.math.reduce_variance(inputs, axis = [1, 2], keepdims = True) + self.epsilon)\n",
    "        norm = (inputs - mean_x) * rstd_x\n",
    "        out = self.gamma * norm + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412ecc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if not isinstance(padding, str):\n",
    "            if isinstance(padding, int):\n",
    "                self.padding = ((padding, padding), (padding, padding))\n",
    "            elif isinstance(padding, tuple) | isinstance(padding, list):\n",
    "                if isinstance(padding[0], int):\n",
    "                    self.padding = ((padding[0], padding[0]), (padding[1], padding[1]))\n",
    "                elif isinstance(padding[0], tuple):\n",
    "                    self.padding = ((padding[0][0], padding[0][1]), (padding[1][0], padding[1][1]))\n",
    "                else:\n",
    "                    raise Exception('')\n",
    "                    \n",
    "            else:\n",
    "                raise Exception('')\n",
    "                \n",
    "        else:\n",
    "            raise Exception('padding must not be a `string`')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.pad(inputs, ((0, 0), self.padding[0], self.padding[1], (0, 0)), mode = 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff66b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.W = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.matmul(inputs, self.W), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88262b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        \n",
    "        if isinstance(padding, str):\n",
    "            if padding.upper() in ['SAME', 'VALID']:\n",
    "                self.padding = padding.upper()\n",
    "            else:\n",
    "                raise Exception('invalid padding type.')\n",
    "        elif isinstance(padding, tuple) | isinstance(padding, list) | isinstance(padding, int):\n",
    "            self.padding = ReflectionPadding2D(padding)\n",
    "            \n",
    "        else:\n",
    "            raise Exception('invalid padding type.')\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.W = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, 1, 1, self.filters), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if isinstance(self.padding, str):\n",
    "            return tf.add(tf.nn.conv2d(inputs, self.W, self.strides, self.padding), self.B)\n",
    "        return tf.add(tf.nn.conv2d(self.padding(inputs), self.W, self.strides, 'VALID'), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ebc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, norm, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if norm == 'batch_norm':\n",
    "            self.norm = tf.keras.layers.BatchNormalization()\n",
    "        elif norm == 'inst_norm':\n",
    "            self.norm = InstanceNormalization()\n",
    "        else:\n",
    "            self.norm = norm\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return self.norm(inputs)\n",
    "    \n",
    "    \n",
    "class Activation(tf.keras.layers.Layer):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if activation == 'relu':\n",
    "            self.activation = tf.keras.layers.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.activation = tf.keras.layers.LeakyReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tf.keras.layers.Activation('tanh')\n",
    "        else:\n",
    "            self.activation = activation\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return self.activation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf3d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, norm, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        self.norm = Normalization(norm = norm) if norm is not None else lambda x: x\n",
    "        self.act = Activation(activation = activation) if activation is not None else lambda x: x\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.act(self.norm(self.conv(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4aea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATBlock(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        Pose-Attentional Transfer Block\n",
    "    '''\n",
    "    def __init__(self, filters, norm, activation, use_dropout, first_block, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.norm = norm\n",
    "        self.activation = activation\n",
    "        self.use_dropout = use_dropout \n",
    "        self.first_block = first_block\n",
    "        \n",
    "        self.image_pathway = self.image_pathway_block()\n",
    "        self.pose_pathway = self.pose_pathway_block()\n",
    "    \n",
    "    def image_pathway_block(self):\n",
    "        '''\n",
    "            conv_p\n",
    "        '''\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(Conv2DBlock(filters = self.filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                              norm = self.norm, activation = self.activation))\n",
    "        if self.use_dropout:\n",
    "            model.add(tf.keras.layers.Dropout(0.5))\n",
    "            \n",
    "        model.add(Conv2DBlock(filters = self.filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                              norm = self.norm, activation = None))\n",
    "        return model\n",
    "    \n",
    "    def pose_pathway_block(self):\n",
    "        '''\n",
    "            conv_s\n",
    "        '''\n",
    "        dim = self.filters if self.first_block else self.filters * 2\n",
    "        model = tf.keras.models.Sequential()\n",
    "        \n",
    "        model.add(Conv2DBlock(filters = self.filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                              norm = self.norm, activation = self.activation))\n",
    "\n",
    "        if self.use_dropout:\n",
    "            model.add(tf.keras.layers.Dropout(0.5))\n",
    "            \n",
    "        model.add(Conv2DBlock(filters = self.filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                              norm = None, activation = None))\n",
    "        return model\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        assert len(inputs) == 2\n",
    "        img, pose = inputs\n",
    "        \n",
    "        img_out = self.image_pathway(img)\n",
    "        pose_out = self.pose_pathway(pose)\n",
    "        \n",
    "        m = tf.nn.sigmoid(pose_out)\n",
    "        \n",
    "        fp = (img_out * m) + img\n",
    "        fs = tf.concat([pose_out, fp], axis = -1)\n",
    "        \n",
    "        return fp, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b359ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATNetwork(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        Pose-Attentional Transfer Network\n",
    "    '''\n",
    "    def __init__(self, dim = 256, norm = 'inst_norm', activation = 'relu', n_patb = 9, use_dropout = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.pat_blocks = []\n",
    "        for i in range(n_patb):\n",
    "            first_block = i == 0\n",
    "            self.pat_blocks.append(PATBlock(filters = dim, norm = norm, activation = activation, \n",
    "                                            use_dropout = use_dropout, first_block = first_block))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        assert len(inputs) == 2\n",
    "        img, pose = inputs\n",
    "        \n",
    "        for patb in self.pat_blocks:\n",
    "            img, pose = patb([img, pose])\n",
    "            \n",
    "        return img, pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9d2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSamplingBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, norm, activation, n_blocks = 2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.model = []\n",
    "        for i in range(n_blocks):\n",
    "            self.model.append(Conv2DBlock(filters = dim * (i + 1), kernel_size = (3, 3), strides = (2, 2), \n",
    "                                          padding = (1, 1), norm = norm, activation = activation))\n",
    "            \n",
    "    def call(self, x):\n",
    "        for m in self.model:\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24923c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSamplingBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, norm, activation, n_blocks = 2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.model = []\n",
    "        for i in range(n_blocks):\n",
    "            self.model.append(tf.keras.layers.Conv2DTranspose(filters = dim//(i+1), kernel_size = (3, 3), \n",
    "                                                              strides = (2, 2), padding = 'same'))\n",
    "            if norm is not None:\n",
    "                self.model.append(Normalization(norm = norm))\n",
    "            if activation is not None:\n",
    "                self.model.append(Activation(activation = activation))\n",
    "                \n",
    "    def call(self, x):\n",
    "        for m in self.model:\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9da257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters = None, norm = 'batch_norm', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.norm = norm\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        filters = input_shape[-1] if self.filters is None else self.filters\n",
    "        \n",
    "        self.conv_1 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                  norm = self.norm, activation = 'relu')\n",
    "        self.conv_2 = Conv2DBlock(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = (1, 1), \n",
    "                                  norm = self.norm, activation = None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.conv_2(self.conv_1(inputs)) + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80d2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, n_up_down = 2, dim = 64, norm = 'inst_norm', activation = 'relu', n_patb = 9, use_dropout = False):\n",
    "        self.n_up_down = n_up_down\n",
    "        self.dim = dim\n",
    "        self.norm = norm\n",
    "        self.activation = activation\n",
    "        self.n_patb = n_patb\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "    def generator(self, condition_img_shape, pose_shape):\n",
    "        inp_condition_img = tf.keras.layers.Input(shape = condition_img_shape, dtype = tf.float32, \n",
    "                                                  name = 'condition_image_Pc')\n",
    "        inp_condition_pose = tf.keras.layers.Input(shape = pose_shape, dtype = tf.float32, \n",
    "                                                   name = 'condition_pose_Sc')\n",
    "        inp_target_pose = tf.keras.layers.Input(shape = pose_shape, dtype = tf.float32, \n",
    "                                                name = 'target_pose_St')\n",
    "        \n",
    "        # conv Fp_0\n",
    "        fp = Conv2DBlock(filters = self.dim, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), \n",
    "                         norm = self.norm, activation = self.activation)(inp_condition_img)\n",
    "        \n",
    "        # conv Fs_0\n",
    "        fs = tf.keras.layers.Concatenate()([inp_condition_pose, inp_target_pose])\n",
    "        fs = Conv2DBlock(filters = self.dim, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), \n",
    "                         norm = self.norm, activation = self.activation)(fs)\n",
    "        \n",
    "        # Downsampling Blocks (inputs)\n",
    "        fp = DownSamplingBlock(dim = self.dim * 2, norm = self.norm, activation = self.activation, \n",
    "                               n_blocks = self.n_up_down)(fp)\n",
    "        fs = DownSamplingBlock(dim = self.dim * 2, norm = self.norm, activation = self.activation, \n",
    "                               n_blocks = self.n_up_down)(fs)\n",
    "        \n",
    "        # Pose-Attentional Transfer Network\n",
    "        fp, fs = PATNetwork(dim = self.dim * (2**self.n_up_down), norm = self.norm, activation = self.activation, \n",
    "                            n_patb = self.n_patb, use_dropout = self.use_dropout)([fp, fs])\n",
    "        \n",
    "        # Upsampling Block\n",
    "        fp = UpSamplingBlock(dim = self.dim * (2*self.n_up_down), norm = self.norm, activation = self.activation)(fp)\n",
    "        \n",
    "        # Converting into image (channels of 3)\n",
    "        out = Conv2DBlock(filters = 3, kernel_size = (7, 7), strides = (1, 1), padding = (3, 3), \n",
    "                          norm = None, activation = 'tanh')(fp)\n",
    "        \n",
    "        return tf.keras.models.Model([inp_condition_img, inp_condition_pose, inp_target_pose], out, name = 'Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7ecdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, dim = 64, n_down = 2, n_blocks = 6, logits = False):\n",
    "        self.dim = dim\n",
    "        self.n_down = n_down\n",
    "        self.n_blocks = n_blocks\n",
    "        self.logits = logits\n",
    "    \n",
    "    def discriminator(self, inpA_shape, inpB_shape):\n",
    "        inpA = tf.keras.layers.Input(shape = inpA_shape, dtype = tf.float32, name = 'inputA')\n",
    "        inpB = tf.keras.layers.Input(shape = inpB_shape, dtype = tf.float32, name = 'inputB')\n",
    "\n",
    "        x = tf.keras.layers.Concatenate()([inpA, inpB])\n",
    "\n",
    "        x = Conv2DBlock(filters = self.dim, kernel_size = (7, 7), strides = (1, 1), padding = (0, 0), norm = 'batch_norm', \n",
    "                        activation = 'leaky_relu')(x)\n",
    "\n",
    "        dim = self.dim\n",
    "        for i in range(self.n_down):\n",
    "            if i < 2:\n",
    "                dim *= 2\n",
    "            x = Conv2DBlock(filters = dim, kernel_size = (3, 3), strides = (2, 2), padding = (1, 1), norm = 'batch_norm', \n",
    "                            activation = 'leaky_relu')(x)\n",
    "\n",
    "\n",
    "        for _ in range(self.n_blocks):\n",
    "            x = ResidualBlock(filters = dim, norm = 'batch_norm')(x)\n",
    "\n",
    "        if self.logits:\n",
    "            x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "        return tf.keras.models.Model([inpA, inpB], x, name = 'Discriminator')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d56ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptualLoss(object):\n",
    "    def __init__(self, pt_model = None, pt_layers = [], p = 1):\n",
    "        if p == 1:\n",
    "            self.loss_object = lambda x, y: tf.math.reduce_mean(tf.math.abs(x - y))\n",
    "        elif p == 2:\n",
    "            self.loss_object = lambda x, y: tf.math.reduce_mean(tf.math.square(x - y))\n",
    "        \n",
    "        \n",
    "        model = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet') if pt_model is None else pt_model\n",
    "        model.trainable = False\n",
    "        \n",
    "        layers = ['block1_conv2'] if len(pt_layers) == 0 else pt_layers\n",
    "        outs = [model.get_layer(layer).output for layer in layers]\n",
    "        \n",
    "        self.model = tf.keras.models.Model(model.inputs, outs)\n",
    "        self.preprocess_input = lambda x: tf.keras.applications.vgg19.preprocess_input(x)\n",
    "        \n",
    "    def __call__(self, real, pred):\n",
    "        # convert images pixel range from (-1, 1) to (0, 255) before preprocessing\n",
    "        real_outs = self.model(self.preprocess_input((real + 1)*127.5))\n",
    "        gen_outs = self.model(self.preprocess_input((gen + 1)*127.5))\n",
    "        \n",
    "        if isinstance(real_outs, list):\n",
    "            loss = 0\n",
    "            for r, g in zip(real_outs, gen_outs):\n",
    "                loss += self.loss_object(r, g)\n",
    "        else:\n",
    "            loss = self.loss_object(real_outs, gen_outs)\n",
    "        return loss\n",
    "    \n",
    "class L_Loss(object):\n",
    "    def __init__(self, p = 1):\n",
    "        if p == 1:\n",
    "            self.loss = lambda x, y: tf.math.reduce_mean(tf.math.abs(x - y))\n",
    "        elif p == 2:\n",
    "            self.loss = lambda x, y: tf.math.reduce_mean(tf.math.square(x - y))\n",
    "        else:\n",
    "            raise Exception('')\n",
    "            \n",
    "    def __call__(self, real, pred):\n",
    "        return self.loss(real, pred)\n",
    "    \n",
    "class GANLoss(object):\n",
    "    def __init__(self, loss_type = 'adversarial'):\n",
    "        if loss_type == 'adversarial':\n",
    "            self.loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "        elif loss_type == 'lsgan':\n",
    "            self.loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    def discriminator_loss(self, disc_real_out_A, disc_gen_out_A, disc_real_out_S, disc_gen_out_S):\n",
    "        assert disc_real_out_A.shape == disc_real_out_S.shape\n",
    "        assert disc_gen_out_A.shape == disc_gen_out_S.shape\n",
    "        real = self.loss(tf.ones_like(disc_real_out_A), disc_real_out_A*disc_real_out_S)\n",
    "        gen = self.loss(tf.zeros_like(disc_gen_out_A), disc_gen_out_A*disc_gen_out_S)\n",
    "        return real + gen\n",
    "    \n",
    "    def generator_loss(self, disc_gen_out_A, disc_gen_out_S):\n",
    "        assert disc_gen_out_A.shape == disc_gen_out_S.shape\n",
    "        return self.loss(tf.ones_like(disc_gen_out_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e5afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, generator, discriminator, img_shape, pose_shape, learning_rate = 2e-4, loss_type = 'adversarial', \n",
    "                 alpha = 5, lambda_1 = 1, lambda_2 = 1):\n",
    "        self.alpha = alpha\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        \n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, beta_1 =0.5, beta_2 = 0.999)\n",
    "        \n",
    "        self.generator = generator.generator(img_shape, pose_shape)\n",
    "        self.discriminator_A = discriminator.discriminator(img_shape, img_shape)\n",
    "        self.discriminator_S = discriminator.discriminator(pose_shape, img_shape)\n",
    "        \n",
    "        self.perceptual_loss = PerceptualLoss(p = 1)\n",
    "        self.l1_loss = L_Loss(p = 1)\n",
    "        self.gan_loss = GANLoss(loss_type = loss_type)\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, condition_img, condition_pose, target_img, target_pose):\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            gen_out = self.generator([condition_img, condition_pose, target_pose], training = True)\n",
    "            \n",
    "            disc_real_out_A = self.discriminator_A([condition_img, target_img], training = True)\n",
    "            disc_gen_out_A = self.discriminator_A([condition_img, gen_out], training = True)\n",
    "            disc_real_out_S = self.discriminator_S([target_pose, target_img], training = True)\n",
    "            disc_gen_out_S = self.discriminator_S([target_pose, gen_out], training = True)\n",
    "            \n",
    "            gen_loss = self.perceptual_loss(target_img, gen_out) * self.lambda_2\n",
    "            gen_loss += self.l1_loss(target_img, gen_out) * self.lambda_1\n",
    "            gen_loss += self.alpha * self.gan_loss.generator_loss(disc_gen_out_A, disc_gen_out_S)\n",
    "            \n",
    "            disc_loss = self.gan_loss.discriminator_loss(disc_real_out_A, disc_gen_out_A, disc_real_out_S, disc_gen_out_S)\n",
    "            \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "        \n",
    "        disc_params = self.discriminator_A.trainable_variables + self.discriminator_S.trainable_variables\n",
    "        disc_grads = disc_tape.gradient(disc_loss, disc_params)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, disc_params))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "    \n",
    "\n",
    "    def train(self, data, epochs = 1):\n",
    "        gen_losses, disc_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts')\n",
    "            for condition_img, condition_pose, target_img, target_pose in data:\n",
    "                gen_loss, disc_loss = self.train_step(condition_img, condition_pose, target_img, target_pose)\n",
    "                print('.', end = '')\n",
    "                \n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "            print(f'\\nGenerator Loss: {gen_loss} \\t Discriminator Loss: {disc_loss}')\n",
    "            print(f'Epoch: {e} Ends.\\n')\n",
    "            \n",
    "        return {'gen_losses': gen_losses, 'disc_losses': disc_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b759f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
