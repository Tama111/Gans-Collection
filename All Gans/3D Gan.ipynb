{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2824dd",
   "metadata": {},
   "source": [
    "# 3D GAN\n",
    "\n",
    "This is an attempt to re-implement the paper 3D Gan\n",
    "\n",
    "Paper: http://3dgan.csail.mit.edu/papers/3dgan_nips.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608c8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f8348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11207bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(tf.matmul(inputs, self.W), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98220e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        self.B = self.add_weight(shape = (self.filters, ), initializer = 'zeros', \n",
    "                                 trainable = True, name = 'bias')\n",
    "        \n",
    "    @property\n",
    "    def padding(self):\n",
    "        d = (self.kernel_size[0] - 1)//2\n",
    "        h = (self.kernel_size[1] - 1)//2\n",
    "        w = (self.kernel_size[1] - 1)//2\n",
    "        return [[0, 0], [d, d], [h, h], [w, w], [0, 0]]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.pad(inputs, self.padding, mode = 'REFLECT')\n",
    "        return tf.add(tf.nn.conv3d(x, self.W, self.strides, padding = 'VALID', data_format = 'NDHWC'), self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8457603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.models.Model):\n",
    "    def __init__(self, latent_dim = 200, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = self.__init_generator\n",
    "        self.gen_shp = self.generator.output_shape\n",
    "        self.discriminator = self.__init_discriminator\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.generator(inputs)\n",
    "    \n",
    "    @property\n",
    "    def __init_generator(self):\n",
    "        inp = tf.keras.layers.Input(shape = (self.latent_dim, ), dtype = tf.float32, name = 'generator_input')\n",
    "        \n",
    "        x = Linear(neurons = 512 * 4 * 4 * 4)(inp)\n",
    "        x = tf.keras.layers.Reshape((4, 4, 4, 512))(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3DTranspose(filters = 512, kernel_size = (4, 4, 4), strides = (1, 1, 1), \n",
    "                                            padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3DTranspose(filters = 256, kernel_size = (4, 4, 4), strides = (2, 2, 2), \n",
    "                                            padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3DTranspose(filters = 128, kernel_size = (4, 4, 4), strides = (2, 2, 2), \n",
    "                                            padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3DTranspose(filters = 64, kernel_size = (4, 4, 4), strides = (2, 2, 2), \n",
    "                                            padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3DTranspose(filters = 1, kernel_size = (4, 4, 4), strides = (2, 2, 2), \n",
    "                                            padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "        \n",
    "        return tf.keras.models.Model(inp, x, name = 'generator')\n",
    "    \n",
    "    @property\n",
    "    def __init_discriminator(self):\n",
    "        inp = tf.keras.layers.Input(shape = self.gen_shp[1:], dtype = tf.float32, name = 'discriminator_input')\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters = 64, kernel_size = (4, 4, 4), strides = 2, padding = 'same')(inp)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters = 128, kernel_size = (4, 4, 4), strides = 2, padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters = 256, kernel_size = (4, 4, 4), strides = 2, padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters = 512, kernel_size = (4, 4, 4), strides = 2, padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters = 1, kernel_size = (4, 4, 4), strides = 1, padding = 'same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        \n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = Linear(neurons = 1)(x)\n",
    "        #x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "        \n",
    "        return tf.keras.models.Model(inp, x, name = 'discriminator')\n",
    "    \n",
    "    def compile(self):\n",
    "        super().compile()\n",
    "        self.gen_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.025, beta_1 = 0.5)\n",
    "        self.disc_optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5, beta_1 = 0.5)\n",
    "        self.gan_loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "        \n",
    "        \n",
    "    def latent_noise(self, batch_size):\n",
    "        return tf.random.normal((batch_size, self.latent_dim))\n",
    "        \n",
    "    def train_step(self, img_3d):\n",
    "        if isinstance(img_3d, tuple):\n",
    "            img_3d = img_3d[0]\n",
    "        batch_size = tf.shape(img_3d)[0]\n",
    "            \n",
    "        with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "            gen_3d = self.generator(self.latent_noise(batch_size), training = True)\n",
    "            \n",
    "            disc_real_out = self.discriminator(img_3d, training = True)\n",
    "            disc_gen_out = self.discriminator(gen_3d, training = True)\n",
    "            \n",
    "            disc_loss = (self.gan_loss(tf.ones_like(disc_real_out), disc_real_out) + \n",
    "            self.gan_loss(tf.zeros_like(disc_gen_out), disc_gen_out)) * 0.5\n",
    "            gen_loss = self.gan_loss(tf.ones_like(disc_gen_out), disc_gen_out)\n",
    "            \n",
    "        \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_optimizer.apply_gradients(zip(gen_grads, self.generator.trainable_variables))\n",
    "            \n",
    "        disc_grads = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return {'gen_loss': gen_loss, 'disc_loss': disc_loss}\n",
    "    \n",
    "    \n",
    "    def train(self, data, epochs = 1):\n",
    "        for e in range(epochs):\n",
    "            print(f'Epoch: {e} Starts.')\n",
    "            for img3d in data:\n",
    "                loss = self.train_step(img3d)\n",
    "                print('.', end='')\n",
    "                \n",
    "            print(f'\\nLoss: {loss}')\n",
    "            print(f'Epoch: {e} Ends.\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc45de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GAN()\n",
    "g.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de4c919",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 21s 136ms/step - gen_loss: 0.1710 - disc_loss: 2.3562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f3ac75d5b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''inp = `your input`'''\n",
    "g.fit(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb4692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d1ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
