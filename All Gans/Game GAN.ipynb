{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d5f12f",
   "metadata": {},
   "source": [
    "# Game GAN\n",
    "\n",
    "This is an attempt to re-implement Game Gan\n",
    "\n",
    "**note: Some part of this re-implementation might be different from the original implementation.**\n",
    "\n",
    "For more information about Game Gan, \n",
    "\n",
    "Refer: \n",
    "\n",
    "Paper: https://arxiv.org/pdf/2005.12126.pdf\n",
    "    \n",
    "original implementation: https://github.com/nv-tlabs/GameGAN_code\n",
    "\n",
    "This code borrows heavily from https://github.com/nv-tlabs/GameGAN_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48adcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager import def_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f0bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_dim = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.ys = self.add_weight(shape = (1, 1, 1, inp_dim), initializer = init, \n",
    "                                  trainable = True, name = 'scale')\n",
    "        self.yb = self.add_weight(shape = (1, 1, 1, inp_dim), initializer = 'zeros', \n",
    "                                  trainable = True, name = 'shift')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mean = tf.math.reduce_mean(inputs, axis = [1, 2], keepdims = True)\n",
    "        rstd = tf.math.rsqrt(tf.math.reduce_variance(inputs, axis = [1, 2], keepdims = True) + self.epsilon)\n",
    "        norm = (inputs - mean) * rstd\n",
    "        \n",
    "        out = self.ys * norm + self.yb \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5d630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced: spectral norm\n",
    "# https://gist.github.com/FloydHsiu/828eea345e1ca6950e05bb42f0a75b50\n",
    "# https://gist.github.com/FloydHsiu/ab33c7d98d78f9873757810e2f8db50d\n",
    "class SpectralNormalization(tf.keras.layers.Wrapper):\n",
    "    def __init__(self, layer, **kwargs):\n",
    "        super().__init__(layer, **kwargs)\n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        if not self.layer.built:\n",
    "            self.layer.build(input_shape)\n",
    "            \n",
    "        if not hasattr(self.layer, 'weight'):\n",
    "            self.w = tf.convert_to_tensor(self.layer.get_weights()[0])\n",
    "        else:\n",
    "            self.w = tf.identity(self.layer.weight)\n",
    "        \n",
    "        if not hasattr(self, 'w'):\n",
    "            raise ValueError()\n",
    "        \n",
    "        self.w_shape = self.w.shape.as_list()\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "        self.u = self.add_weight(shape = (1, self.w_shape[-1]), initializer = init, \n",
    "                                   trainable = False, name = 'spectral_norm_u')\n",
    "        \n",
    "        # super().build()\n",
    "        \n",
    "    @def_function.function\n",
    "    def call(self, inputs, training = None):\n",
    "        if training is None:\n",
    "            training = tf.keras.backend.learning_phase()\n",
    "            \n",
    "        if training == True:\n",
    "            self._compute_weights()\n",
    "            \n",
    "        output = self.layer(inputs)\n",
    "        return output\n",
    "    \n",
    "    def _compute_weights(self):\n",
    "        w_reshaped = tf.reshape(self.w, (-1, self.w_shape[-1]))\n",
    "        eps = 1e-12\n",
    "        \n",
    "        _u = tf.identity(self.u)\n",
    "        _v = tf.matmul(_u, tf.transpose(w_reshaped, perm = [1, 0]))\n",
    "        _v /= tf.maximum(tf.math.reduce_sum(_v ** 2) ** 0.5, eps)\n",
    "        _u = tf.matmul(_v, w_reshaped)\n",
    "        _u /= tf.maximum(tf.math.reduce_sum(_u ** 2) ** 0.5, eps)\n",
    "        \n",
    "        _u = tf.stop_gradient(_u)\n",
    "        _v = tf.stop_gradient(_v)\n",
    "        \n",
    "        self.u.assign(_u)\n",
    "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u, perm = [1, 0]))\n",
    "        \n",
    "        self.layer.weight.assign(self.w / sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca269b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, use_bias = True, gain = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.neurons = neurons\n",
    "        self.use_bias = use_bias\n",
    "        self.gain = gain\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_neurons = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.W = self.add_weight(shape = (inp_neurons, self.neurons), initializer = init, \n",
    "                                 trainable = True, name = 'weight')\n",
    "        if self.use_bias:\n",
    "            self.B = self.add_weight(shape = (1, self.neurons), initializer = 'zeros', \n",
    "                                     trainable = True, name = 'bias')\n",
    "            \n",
    "        self.w_scale = self.gain * tf.math.rsqrt(tf.cast(inp_neurons, tf.float32))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if self.use_bias:\n",
    "            return tf.add(tf.matmul(inputs * self.w_scale, self.W), self.B)\n",
    "        return tf.matmul(inputs * self.w_scale, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a13412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding), (padding, padding)\n",
    "        elif isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            if isinstance(padding[0], tuple) | isinstance(padding[0], list):\n",
    "                self.padding = (padding[0][0], padding[0][1]), (padding[1][0], padding[1][1])\n",
    "            elif isinstance(padding[0], int):\n",
    "                self.padding = (padding[0], padding[0]), (padding[1], padding[1])\n",
    "                \n",
    "    def call(self, inputs):\n",
    "        return tf.pad(inputs, ((0, 0), self.padding[0], self.padding[1], (0, 0)), 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65707f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, use_bias = True, gain = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.use_bias = use_bias\n",
    "        self.gain = gain\n",
    "        \n",
    "        if padding.upper() in ['SAME', 'VALID']:\n",
    "            self.padding = padding.upper()\n",
    "        elif isinstance(padding, int) | isinstance(padding, tuple) | isinstance(padding, list):\n",
    "            self.padding = ReflectionPadding2D(padding)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        inp_filters = input_shape[-1]\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 1.0)\n",
    "        self.kernel = self.add_weight(shape = self.kernel_size + (inp_filters, self.filters), initializer = init, \n",
    "                                      trainable = True, name = 'weight')\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape = (1, 1, 1, self.filters), initializer = 'zeros', \n",
    "                                        trainable = True, name = 'bias')\n",
    "            \n",
    "        fan_in = tf.cast(self.kernel_size[0] * self.kernel_size[1] * inp_filters, tf.float32)\n",
    "        self.w_scale = self.gain * tf.math.rsqrt(fan_in)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if isinstance(self.padding, str):\n",
    "            out = tf.nn.conv2d(inputs * self.w_scale, self.kernel, self.strides, self.padding)\n",
    "        else:\n",
    "            out = tf.nn.conv2d(self.padding(inputs) * self.w_scale, self.kernel, self.strides, 'VALID')\n",
    "            \n",
    "        if self.use_bias:\n",
    "            return tf.add(out, self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPADE(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon = 1e-8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm = InstanceNormalization()\n",
    "        \n",
    "        self.conv = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        \n",
    "        def build(self, inputs):\n",
    "            inp_filters = inputs[0][-1]\n",
    "        \n",
    "            self.conv_gamma = Conv2D(filters = inp_filters, kernel_size = (3, 3), strides = (1 ,1), padding = 'same')\n",
    "            self.conv_beta = Conv2D(filters = inp_filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        assert len(inputs) == 2\n",
    "        x, mask = inputs\n",
    "        mask = tf.image.resize(mask, tf.shape(x)[1:3], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        \n",
    "        out = self.act(self.conv(mask))\n",
    "        gamma = self.conv_gamma(out)\n",
    "        beta = self.conv_beta(out)\n",
    "        \n",
    "        return self.norm(x) * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02329cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, encoder_for = 'pacman', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        model = tf.keras.models.Sequential()\n",
    "        if encoder_for == 'pacman':\n",
    "            for _ in range(2):\n",
    "                model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'valid'))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'))\n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            \n",
    "            #model.add(tf.keras.layers.Reshape(8*8*64))\n",
    "            \n",
    "        elif encoder_for == 'vizdoom':\n",
    "            model.add(Conv2D(filters = 64, kernel_size = (4, 4), strides = (1, 1), padding = 'same'))\n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            \n",
    "            for _ in range(3):\n",
    "                model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'))\n",
    "                model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                \n",
    "            #model.add(tf.keras.layers.Reshape(7*7*64))\n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'Image Encoder for `{encoder_for}` is still not defined.')\n",
    "        \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(Linear(512))\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b67930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionLSTM(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim = 512, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.W_fv = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        self.W_fs = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        \n",
    "        self.W_iv = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        self.W_is = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        \n",
    "        self.W_cv = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        self.W_cs = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        \n",
    "        self.W_ov = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        self.W_os = Linear(neurons = hidden_dim, use_bias = False)\n",
    "        \n",
    "    def initialize_states(self, batch_size):\n",
    "        return [tf.zeros((batch_size, self.hidden_dim)), tf.zeros((batch_size, self.hidden_dim))]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        v, s, prev_cell_state = inputs\n",
    "        \n",
    "        f = tf.nn.sigmoid(tf.add(tf.matmul(v, self.W_fv), tf.matmul(s, self.W_fs)))\n",
    "        i = tf.nn.sigmoid(tf.add(tf.matmul(v, self.W_iv), tf.matmul(s, self.W_is)))\n",
    "        c = tf.nn.tanh(tf.add(tf.matmul(v, self.W_cv), tf.matmul(s, self.W_cs)))\n",
    "        o = tf.nn.sigmoid(tf.add(tf.matmul(v, self.W_ov), tf.matmul(s, self.W_os)))\n",
    "        \n",
    "        new_cell_state = tf.multiply(f, prev_cell_state) + tf.multiply(i * c)\n",
    "        h_state = tf.multiply(o, tf.nn.tanh(new_cell_state))\n",
    "        \n",
    "        return h_state, new_cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acba655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicsEngine(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim = 512, use_memory = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.use_memory = use_memory\n",
    "        \n",
    "        self.mlp_action = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                                      tf.keras.layers.LeakyReLU(alpha = 0.2)])\n",
    "        self.mlp_z = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                                 tf.keras.layers.LeakyReLU(alpha = 0.2)])\n",
    "        \n",
    "        if use_memory:\n",
    "            self.mlp_mem = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                                       tf.keras.layers.LeakyReLU(alpha = 0.2)])\n",
    "        \n",
    "        self.mlp = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                               tf.keras.layers.LeakyReLU(alpha = 0.2), \n",
    "                                               Linear(neurons = dim)])\n",
    "        \n",
    "        self.img_encoder = ImageEncoder()\n",
    "        \n",
    "        self.rnn = ActionLSTM(hidden_dim = dim)\n",
    "        \n",
    "    def initialize_states(self, batch_size):\n",
    "        return self.rnn.initialize_states(batch_size)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        h_shp_dim = input_shape[0][-1]\n",
    "        \n",
    "        if h_shp_dim != self.dim:\n",
    "            self.mlp_h = tf.keras.models.Sequential([Linear(neurons = self.dim), \n",
    "                                                     tf.keras.layers.LeakyReLU(alpha = 0.2)])\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if self.use_memory:\n",
    "            assert len(inputs) == 6\n",
    "            hidden_state, cell_state, img, stoch_var, action, mem = inputs\n",
    "            \n",
    "        else:\n",
    "            assert len(inputs) == 5\n",
    "            hidden_state, cell_state, img, stoch_var, action = inputs\n",
    "        \n",
    "        a = self.mlp_action(action)\n",
    "        z = self.mlp_z(stoch_var)\n",
    "        \n",
    "        if hasattr(self, 'mlp_h'):\n",
    "            h = self.mlp_h(hidden_state)\n",
    "        else:\n",
    "            h = hidden_state\n",
    "            \n",
    "        if self.use_memory:\n",
    "            x = tf.concat([a, z, mem], axis = -1)\n",
    "        else:\n",
    "            x = tf.concat([a, z], axis = -1)\n",
    "            \n",
    "        v = tf.multiply(h, self.mlp(x))\n",
    "        s = self.img_encoder(img)\n",
    "        \n",
    "        new_hidden_state, new_cell_state = self.rnn([v, s, cell_state])\n",
    "        return new_hidden_state, new_cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363fbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim = 512, use_mem_h = False, memory_for = 'pacman', \n",
    "                 mem_h = 441, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.use_mem_h = use_mem_h\n",
    "        self.memory_for = memory_for\n",
    "        self.mem_h = mem_h\n",
    "        \n",
    "        self.K_block = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                                   tf.keras.layers.LeakyReLU(alpha = 0.2), \n",
    "                                                   Linear(neurons = 9)])\n",
    "    \n",
    "        self.G_block = tf.keras.models.Sequential([Linear(neurons = dim), \n",
    "                                                   tf.keras.layers.LeakyReLU(alpha = 0.2), \n",
    "                                                   Linear(neurons = 1), \n",
    "                                                   tf.keras.layers.Activation('sigmoid')])\n",
    "        \n",
    "        self.E_block = tf.keras.models.Sequential([Linear(neurons = dim*2)])\n",
    "        \n",
    "        gain = tf.sqrt(1.0/(mem_h + dim))\n",
    "        init = tf.keras.initializers.RandomUniform(minval = -gain, maxval = gain)\n",
    "        self.add_weight(shape = (mem_h, dim), initializer = init, \n",
    "                        trainable = True)\n",
    "        \n",
    "    def initialize_memory(self, batch_size):\n",
    "        return tf.tile(tf.expand_dims(self.add_weight, axis = 0), [batch_size, 1, 1])\n",
    "    \n",
    "    def merge_K_G(self, prev_alpha, kernels):\n",
    "        bs, d = prev_alpha\n",
    "        mem_hw = int(tf.sqrt(tf.cast(d, tf.float32)))\n",
    "        \n",
    "        p = tf.reshape(prev_alpha, (bs, mem_hw, mem_hw, 1))\n",
    "        p = tf.reshape(tf.transpose(p, perm = [1, 2, 0, 4]), (1, mem_hw, mem_hw, bs))\n",
    "        \n",
    "        out = tf.nn.conv2d(p, kernels, padding = 'same')\n",
    "        alpha = tf.reshape(tf.transpose(out, perm = [3, 0, 1, 2]), (bs, -1))\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def write(self, erase, add, alpha, M):\n",
    "        alpha_write = tf.expand_dims(alpha, axis = -1)\n",
    "        erase = tf.matmul(alpha_write, tf.expand_dims(erase, axis = 1))\n",
    "        add = tf.matmul(alpha_write, tf.expand_dims(add, axis = 1))\n",
    "        M = M * (1 - erase) + add\n",
    "        return M\n",
    "    \n",
    "    def read(self, alpha, M):\n",
    "        out = tf.matmul(tf.expand_dims(alpha, axis = 1), M)\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "    \n",
    "    def call(self, hidden, action, prev_hidden, prev_alpha, M, read_only = False):\n",
    "        bs = action.shape[0]\n",
    "        if self.use_mem_h:\n",
    "            h = hidden\n",
    "        else:\n",
    "            #h_norm = hidden * tf.rsqrt(tf.math.reduce_sum(hidden*hidden, axis = 1, keepdims = True))\n",
    "            h_norm = hidden / tf.norm(hidden, axis = 1, keepdims = True)\n",
    "            prev_h_norm = hidden / tf.norm(prev_hidden, axis = 1, keepdims = True)\n",
    "            \n",
    "            h = h_norm - prev_h_norm\n",
    "            \n",
    "        kernels = tf.reshape(tf.transpose(self.K_block(action), perm = [1, 0]), (3, 3, 1, bs))\n",
    "            \n",
    "        new_a = action.numpy()\n",
    "        action_label = tf.argmax(action, axis = 1).numpy()\n",
    "        mask = np.zeros((bs, 1))\n",
    "        \n",
    "        for i in range(bs):\n",
    "            if self.memory_for == 'pacman':\n",
    "                if action_label[i] == 2:\n",
    "                    new_a[i][1] = 1.0\n",
    "                    new_a[i][2] = 0.0\n",
    "                    mask[i][0] = 1.0\n",
    "                    \n",
    "                elif action_label[i] == 4:\n",
    "                    new_a[i][3] = 1.0\n",
    "                    new_a[i][4] = 0.0\n",
    "                    mask[i][0] = 1.0\n",
    "                    \n",
    "            elif self.memory_for == 'vizdoom':\n",
    "                if action_label[i] == 0:\n",
    "                    new_a[i][1] == 1.0\n",
    "                    new_a[i][0] == 0.0\n",
    "                    new_a[i][0] == 1.0\n",
    "                    \n",
    "        mask = tf.reshape(tf.cast(mask, tf.float32), (-1, 1, 1, 1))\n",
    "        new_a = tf.cast(new_a, tf.float32)\n",
    "        \n",
    "        flipped_kernels = tf.keras.backend.reverse(tf.reshape(tf.transpose(self.K_block(new_a), perm = [1, 0]), (3, 3, 1, -1)), [0, 1])\n",
    "        kernels = (1 - mask) * kernels + mask * flipped_kernels\n",
    "        \n",
    "        kernels = tf.transpose(tf.reshape(kernels, (-1, bs)), perm = [1, 0])\n",
    "        kernels = tf.nn.softmax(kernels, axis = 1)\n",
    "        kernels = tf.reshape(tf.transpose(kernels, perm = [1, 0]), (3, 3, 1, bs))\n",
    "        \n",
    "        g = self.G_block(h)\n",
    "        \n",
    "        alpha =  g * self.merge_K_G(prev_alpha, kernels) +  (1 - g) * prev_alpha\n",
    "        #alpha = alpha * g + prev_alpha * (1 - g)\n",
    "        \n",
    "        if not read_only:\n",
    "            e = self.E_block(hidden)\n",
    "            erase = tf.nn.sigmoid(e[:, :self.dim])\n",
    "            add = e[:, self.dim:]\n",
    "            \n",
    "            M = self.write(erase, add, alpha, M)\n",
    "            \n",
    "        read = self.read(alpha, M)\n",
    "            \n",
    "        return read, M, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd95be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenderingResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, up_sample = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(InstanceNormalization())\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "        if up_sample:\n",
    "            model.add(tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'nearest'))\n",
    "            \n",
    "        model.add(Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "        model.add(InstanceNormalization())\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "        model.add(Conv2D(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "        \n",
    "        res_path = tf.keras.models.Sequential()\n",
    "        if up_sample:\n",
    "            res_path.add(tf.keras.layers.UpSampling2D(size = (2, 2), interpolation = 'nearest'))\n",
    "        res_path.add(Conv2D(filters = filters, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "        \n",
    "        self.model = model\n",
    "        self.res_path = res_path\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(self.model(inputs), self.res_path(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c17d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRenderingEngine(tf.keras.layers.Layer):\n",
    "    def __init__(self, encoder_for = 'pacman', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(Linear(neurons = 7*7*512))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "        model.add(tf.keras.layers.Reshape((7, 7, 512)))\n",
    "        \n",
    "        if encoder_for == 'pacman':\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (3, 3), strides = (1, 1), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (3, 3), strides = (2, 2), \n",
    "                                                      padding = 'valid', output_padding = 1))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (4, 4), strides = (2, 2), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (4, 4), strides = (2, 2), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = (3, 3), strides = (1, 1), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            \n",
    "        elif encoder_for == 'vizdoom':\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (4, 4), strides = (1, 1), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (4, 4), strides = (1, 1), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (5, 5), strides = (2, 2), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (5, 5), strides = (2, 2), \n",
    "                                                      padding = 'valid', output_padding = 0))       \n",
    "            model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "            model.add(tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = (4, 4), strides = (1, 1), \n",
    "                                                      padding = 'valid', output_padding = 0))\n",
    "            \n",
    "        self.model = model\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82503158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisentanglingRenderingEngine(tf.keras.layers.Layer):\n",
    "    def __init__(self, res_blocks = True, relax_dynamic_constraint = True, con_h = False, render_for = 'pacman',\n",
    "                 apply_mask = True, sigmoid_maps = False, base_temperature = 0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.res_blocks = res_blocks\n",
    "        self.relax_dynamic_constraint = relax_dynamic_constraint\n",
    "        self.con_h = con_h\n",
    "        self.render_for = render_for\n",
    "        self.apply_mask = apply_mask\n",
    "        self.sigmoid_maps = sigmoid_maps\n",
    "        self.base_temperature = base_temperature\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        num_components = len(input_shape)\n",
    "        assert num_components >= 2\n",
    "        if num_components == 2:\n",
    "            assert self.con_h == False, 'More than two inputs required for concatenation, first two inputs are not concatenated'\n",
    "        \n",
    "        self.all_get_maps = []\n",
    "        self.proj_v = []\n",
    "        self.R_block = []\n",
    "        self.spade_layers = []\n",
    "        self.more_layers = []\n",
    "        self.output_layers = []\n",
    "        self.fine_masks = []\n",
    "        \n",
    "        d = 2 if self.con_h else num_components\n",
    "        for ind in range(d):\n",
    "            \n",
    "            ### ROUGH SKETCH STAGE\n",
    "            # Layers for Extracting attribute map (A) and object map (O) for each c_k vectors.\n",
    "            map_model = tf.keras.models.Sequential()\n",
    "            map_model.add(Linear(neurons = 3*3*128))\n",
    "            map_model.add(tf.keras.layers.Reshape((3, 3, 128)))\n",
    "            \n",
    "            if self.res_blocks:\n",
    "                map_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                map_model.add(tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (3, 3), strides = (1, 1), \n",
    "                                                              padding = 'valid', output_padding = 0))\n",
    "                map_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                map_model.add(tf.keras.layers.Conv2DTranspose(filters = 32 + 1, kernel_size = (3, 3), strides = (1, 1), \n",
    "                                                              padding = 'valid', output_padding = 0))\n",
    "                \n",
    "            else:\n",
    "                map_model.add(RenderingResidualBlock(filters = 512, up_sample = False))\n",
    "                map_model.add(RenderingResidualBlock(filters = 32+1, up_sample = False))\n",
    "            \n",
    "            self.all_get_maps.append(map_model)\n",
    "            \n",
    "            # layers for extracting v_k\n",
    "            v_model = tf.keras.models.Sequential()\n",
    "            if self.relax_dynamic_constraint:\n",
    "                v_model.add(Linear(neurons = 7*7*32))\n",
    "                v_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                v_model.add(tf.keras.layers.Reshape((7, 7, 32)))\n",
    "\n",
    "            else:\n",
    "                v_model.add(Linear(neurons = 32))\n",
    "                v_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                v_model.add(tf.keras.layers.Lambda(lambda x: tf.tile(x[:, tf.newaxis, tf.newaxis, :], \n",
    "                                                                     [1, 7, 7, 1])))\n",
    "\n",
    "            self.proj_v.append(v_model)\n",
    "            \n",
    "                \n",
    "            # For R_k\n",
    "            r_model = tf.keras.models.Sequential()\n",
    "            if self.res_blocks:\n",
    "                r_model.add(RenderingResidualBlock(filters = 256, up_sample = False))\n",
    "                r_model.add(RenderingResidualBlock(filters = 128, up_sample = True))\n",
    "\n",
    "            else:\n",
    "                r_model.add(tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (3, 3), strides = (1, 1), \n",
    "                                                            padding = 'valid', output_padding = 0))\n",
    "                r_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                \n",
    "                if self.render_for == 'pacman':\n",
    "                    r_model.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3, 3), strides = (2, 2), \n",
    "                                                                    padding = 'valid', output_padding = 1))\n",
    "                \n",
    "                elif self.render_for == 'vizdoom':\n",
    "                    r_model.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3, 3), strides = (2, 2), \n",
    "                                                                    padding = 'same', output_padding = 0))\n",
    "            \n",
    "            self.R_block.append(r_model)\n",
    "            \n",
    "            \n",
    "            ### ATTRIBUTE STAGE\n",
    "            # spade layers\n",
    "            self.spade_layers.append(SPADE())\n",
    "            \n",
    "            # some more transposed layers\n",
    "            more_layers_model = tf.keras.models.Sequential()\n",
    "            if self.render_for == 'pacman':\n",
    "                if self.res_blocks:\n",
    "                    more_layers_model.add(RenderingResidualBlock(filters = 64, up_sample = True))\n",
    "                    more_layers_model.add(RenderingResidualBlock(filters = 32, up_sample = True))\n",
    "                    \n",
    "                else:\n",
    "                    more_layers_model.add(tf.keras.layers.Conv2DTranspose(\n",
    "                        filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'valid', output_padding = 0))\n",
    "                    more_layers_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                    more_layers_model.add(tf.keras.layers.Conv2DTranspose(\n",
    "                        filters = 32, kernel_size = (4, 4), strides = (2, 2), padding = 'valid', output_padding = 0))\n",
    "                    more_layers_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                    \n",
    "            elif self.render_for == 'vizdoom':\n",
    "                if self.res_blocks:\n",
    "                    more_layers_model.add(RenderingResidualBlock(filters = 64, up_sample = True))\n",
    "                    more_layers_model.add(RenderingResidualBlock(filters = 32, up_sample = True))\n",
    "                    \n",
    "                else:\n",
    "                    more_layers_model.add(tf.keras.layers.Conv2DTranspose(\n",
    "                        filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'same', output_padding = 0))\n",
    "                    more_layers_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                    more_layers_model.add(tf.keras.layers.Conv2DTranspose(\n",
    "                        filters = 32, kernel_size = (3, 3), strides = (2, 2), padding = 'same', output_padding = 0))\n",
    "                    more_layers_model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "                    \n",
    "            self.more_layers.append(more_layers_model)\n",
    "            \n",
    "            \n",
    "            ### FINAL RENDERING STAGE\n",
    "            self.output_layers.append(\n",
    "                tf.keras.models.Sequential([\n",
    "                    InstanceNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "                    Conv2D(filters = 3, kernel_size = (3, 3), strides = (1, 1), padding = 'same')\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "            self.fine_masks.append(\n",
    "                tf.keras.models.Sequential([\n",
    "                    tf.keras.layers.ReLU(),\n",
    "                    Conv2D(filters = 1, kernel_size = (3, 3), strides = (1, 1), padding = 'same'),\n",
    "                    tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "        # does not effects much (as per paper)\n",
    "        if self.apply_mask: \n",
    "            self.mask_N = tf.keras.models.Sequential()\n",
    "            self.mask_N.add(Conv2D(filters = 512, kernel_size = (1, 1), strides = (1, 1), padding = 'valid'))\n",
    "            self.mask_N.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "\n",
    "            dim = 2 if self.con_h else num_components\n",
    "            self.mask_N.add(Conv2D(filters = dim, kernel_size = (1, 1), strides = (1, 1), padding = 'valid'))\n",
    "            \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        assert len(inputs) >= 2\n",
    "        # len(inputs) == # of components\n",
    "        \n",
    "        if len(inputs) == 2:\n",
    "            assert self.con_h == False, 'More than two inputs required for concatenation, first two inputs are not concatenated'\n",
    "            m, h = inputs\n",
    "            c_vector = [m, h]\n",
    "        elif len(inputs) > 2:\n",
    "            m, h = inputs[:2]\n",
    "            c_vector = [m, h]\n",
    "            if len(inputs[2:]) == 1:\n",
    "                v_inp = inputs[-1]\n",
    "                c_vector.append(v_inp)\n",
    "            else:\n",
    "                if self.con_h:\n",
    "                    v_inp = tf.concat(inputs[2:], axis = -1)\n",
    "                    c_vector.append(v_inp)\n",
    "                else:\n",
    "                    c_vector += inputs[2:]\n",
    "                \n",
    "        \n",
    "        attr_maps, obj_maps, vs = [], [], []\n",
    "        \n",
    "        d = 2 if self.con_h else len(inputs)\n",
    "        for i in range(d):\n",
    "            maps = self.all_get_maps[i](c_vector[i])\n",
    "            attr_maps.append(maps[:, :, :, 1:])\n",
    "            obj_maps.append(maps[:, :, :, :1])\n",
    "            \n",
    "            idx = -1 if self.con_h else i\n",
    "            vs.append(self.proj_v[i](c_vector[idx]))\n",
    "            \n",
    "        obj_len = len(obj_maps)\n",
    "        obj_maps = tf.concat(obj_maps, axis = -1)\n",
    "        if self.sigmoid_maps:\n",
    "            obj_maps = tf.nn.sigmoid(obj_maps / self.base_temperature)\n",
    "        else:\n",
    "            obj_maps = tf.nn.softmax(obj_maps / self.base_temperature, axis = -1)\n",
    "        obj_maps = tf.split(obj_maps, obj_len, -1)\n",
    "            \n",
    "        base_singles, unmasked_base_imgs = [], []\n",
    "        for i, (om, am, v_) in enumerate(zip(obj_maps, attr_maps, vs)):\n",
    "            r_out = self.R_block[i](om * v_)\n",
    "            spade_out = self.spade_layers[i]([r_out, om * am])\n",
    "            more_out = self.more_layers[i](spade_out)\n",
    "            \n",
    "            base_singles.append(self.fine_masks[i](more_out))\n",
    "            unmasked_base_imgs.append(tf.nn.tanh(self.output_layers[i](more_out)))\n",
    "\n",
    "        fine_mask = tf.concat(base_singles, axis = -1)\n",
    "        fine_mask = self.mask_N(mask) if self.apply_mask else mask\n",
    "        fine_mask = tf.nn.softmax(mask, axis = -1)\n",
    "        fine_mask = tf.split(mask, len(base_singles), -1)\n",
    "        \n",
    "        out_img, base_imgs = 0, []\n",
    "        for msk, umsk in zip(fine_mask, unmasked_base_imgs):\n",
    "            base_imgs.append(msk * umsk)\n",
    "            out_img += base_imgs[-1]\n",
    "            \n",
    "        for umsk in unmasked_base_imgs:\n",
    "            base_imgs.append(umsk)\n",
    "            \n",
    "        return out_img, fine_mask, obj_maps, base_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70de146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.models.Model):\n",
    "    def __init__(self, gen_for = 'pacman', dim = 512, use_memory = True, use_mem_h = False, mem_h = 441, \n",
    "                 simple_render_block = False, res_blocks = True, relax_dynamic_constraint = True, con_h = False, \n",
    "                 apply_mask = True, sigmoid_maps = False, base_temperature = 0.1, \n",
    "                 z_dim = 32, alpha_loss_multiplier = -1, cycle_loss = False, \n",
    "                 cycle_start_epoch = 0, rev_multiply_map = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.gen_for = gen_for\n",
    "        self.dim = dim\n",
    "        self.use_memory = use_memory\n",
    "        self.use_mem_h = use_mem_h\n",
    "        self.mem_h = mem_h\n",
    "        self.simple_render_block = simple_render_block\n",
    "        self.res_blocks = res_blocks\n",
    "        self.relax_dynamic_constraint = relax_dynamic_constraint\n",
    "        self.con_h = con_h\n",
    "        self.apply_mask = apply_mask\n",
    "        self.sigmoid_maps = sigmoid_maps\n",
    "        self.base_temperature = base_temperature\n",
    "        self.z_dim = z_dim\n",
    "        self.alpha_loss_multiplier= alpha_loss_multiplier\n",
    "        self.cycle_loss = cycle_loss\n",
    "        self.cycle_start_epoch = cycle_start_epoch\n",
    "        self.rev_multiply_map = rev_multiply_map\n",
    "        \n",
    "        # PARTS OF GENERATOR\n",
    "        # dynamics engine\n",
    "        self.dynamics_engine = DynamicsEngine(dim = dim, use_memory = use_memory)\n",
    "        \n",
    "        # memory module\n",
    "        if use_memory:\n",
    "            self.memory = Memory(dim = dim, use_mem_h = use_mem_h, memory_for = gen_for, mem_h = mem_h)\n",
    "            \n",
    "        # rendering engine\n",
    "        if simple_render_block:\n",
    "            self.render_engine = SimpleRenderingEngine(render_for = gen_for)\n",
    "        else:\n",
    "            self.render_engine = DisentanglingRenderingEngine(res_blocks = res_blocks, \n",
    "                                                              relax_dynamic_constraint = relax_dynamic_constraint, \n",
    "                                                              con_h = con_h, render_for = gen_for, \n",
    "                                                              apply_mask = apply_mask, sigmoid_maps = sigmoid_maps, \n",
    "                                                              base_temperature = base_temperature)\n",
    "\n",
    "    \n",
    "    def run_step(self, image, h, c, action, zdist, batch_size, prev_read, \n",
    "                 prev_alpha, M, read_only = False):\n",
    "            \n",
    "        # dynamics engine\n",
    "        z = zdist(shape = (batch_size, self.z_dim))\n",
    "        de_inp = [h, c, image, z, action]\n",
    "        de_inp += [prev_read] if self.use_memory else []\n",
    "        \n",
    "        new_h, new_c = self.dynamics_engine(de_inp)\n",
    "        \n",
    "        # memory module\n",
    "        if self.use_memory:\n",
    "            # hidden, action, prev_hidden, prev_alpha, M, read_only = False\n",
    "            read, M, alpha = self.memory(new_h, action, h, prev_alpha, M, read_only)\n",
    "            \n",
    "            assert self.simple_render_block == False\n",
    "            render_inp = [read, new_h]\n",
    "            \n",
    "            prev_alpha, prev_read = alpha, read\n",
    "        else:\n",
    "            assert self.simple_render_block == True\n",
    "            render_inp = new_h\n",
    "            \n",
    "        \n",
    "        # Render Engine\n",
    "        ### note: input to render engine is limited to at max 2 inputs\n",
    "        ### other inputs to it are not defined yet.\n",
    "        alpha_loss = 0\n",
    "        if self.simple_render_block:\n",
    "            render_out = self.render_engine(render_inp)\n",
    "            render_out = tf.nn.tanh(render_out)\n",
    "            \n",
    "        else:\n",
    "            render_out, fine_mask, obj_maps, base_imgs = self.render_engine(render_inp)\n",
    "            if self.alpha_loss_multiplier > 0:\n",
    "                # memory regularization\n",
    "                for i in range(1, len(fine_mask)):\n",
    "                    alpha_loss += tf.reduce_sum(tf.abs(m[i]))/batch_size\n",
    "            \n",
    "            \n",
    "        return (render_outs, fine_mask, prev_alpha, alpha_loss, z, M, prev_read, new_h, \n",
    "                new_c, obj_maps, base_imgs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # action, zdist, images, warmup_steps = 10, epoch = 0\n",
    "        action, zdist, images, warmup_steps, epoch = inputs\n",
    "        \n",
    "        batch_size = images[0].shape[0]\n",
    "        h_init, c_init = self.dynamics_engine.initialize_states(batch_size)\n",
    "        \n",
    "        if self.use_memory:\n",
    "            M_init = self.memory.initialize_memory(batch_size)\n",
    "            \n",
    "            alpha_init = tf.zeros((batch_size, self.mem_h))\n",
    "            mem_wh = int(tf.sqrt(self.mem_h))\n",
    "            alpha_init[:, mem_wh * (mem_wh//2) + mem_wh//2] = 1.0\n",
    "            \n",
    "            read_init = tf.zeros((batch_size, self.dim))\n",
    "            \n",
    "            \n",
    "        outputs, zs, alphas, base_imgs_all, hiddens, fine_masks, obj_maps = [], [], [], [], [], []\n",
    "        alpha_losses = 0\n",
    "        \n",
    "        h, c = h_init, c_init\n",
    "        prev_read, M, prev_alpha = read_init, M_init, alpha_init \n",
    "        \n",
    "        for i in range(len(actions) - 1):\n",
    "            out_img = out_img if i > warmup_steps else images[i]\n",
    "            \n",
    "            out_img, fm, prev_alpha, alpha_loss, z, M, prev_read, h,\\\n",
    "            c, obj_map, base_imgs = self.run_step(out_img, h, c, actions[i], zdist, \n",
    "                                                 batch_size, prev_read, prev_alpha, M)\n",
    "            \n",
    "            outputs.append(out_img)\n",
    "            fine_masks.append(fm)\n",
    "            alphas.append(prev_alpha)\n",
    "            alpha_losses += alpha_loss\n",
    "            zs.append(z)\n",
    "            base_imgs_all.append(base_imgs)\n",
    "            hiddens.append(h)\n",
    "            obj_maps.append(obj_map)\n",
    "            \n",
    "        alpha_losses /= (len(actions) - 1)\n",
    "        \n",
    "        rev_outputs, rev_base_imgs, rev_alphas, rev_maps = [], [], [], []\n",
    "        response = {}\n",
    "        if self.use_memory and (self.cycle_loss and (self.cycle_start_epoch <= 0)) and (self.simple_render_block == False):\n",
    "            # read from previously visited locations for cycle loss\n",
    "            for i in range(len(alphas) - 1, -1, -1):\n",
    "                cur_read = self.memory.read(alphas[i], M)\n",
    "                render_out, fm, om, bm = self.render_engine([cur_read, tf.zeros_like(cur_read)])\n",
    "                \n",
    "                if self.rev_multiply_map:\n",
    "                    rev_outputs.append(bm[2] * fine_masks[i][0])\n",
    "                else:\n",
    "                    rev_outputs.append(bm[2])\n",
    "                    \n",
    "                rev_maps.append(fm)\n",
    "                rev_base_imgs.append(base_imgs)\n",
    "                rev_alphas.append(alphas[i])\n",
    "                \n",
    "        \n",
    "        response['alpha_loss'] = alpha_losses\n",
    "        response['rev_outputs'] = rev_outputs\n",
    "        response['rev_alphas'] = rev_alphas\n",
    "        response['rev_maps'] = rev_maps\n",
    "        response['rev_base_imgs_all'] = rev_base_imgs\n",
    "        response['maps'] = fine_masks\n",
    "        response['obj_maps'] = obj_maps\n",
    "        response['zs'] = zs\n",
    "        response['outputs'] = outputs\n",
    "        response['alphas'] = alphas\n",
    "        response['base_imgs_all'] = base_imgs_all\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cf36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, use_bias = True, gain = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.layer = SpectralNormalization(Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, \n",
    "                                                  padding = padding, use_bias = use_bias, gain = gain))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.layer(inputs)\n",
    "    \n",
    "class SNLinear(tf.keras.layers.Layer):\n",
    "    def __init__(self, neurons, use_bias = True, gain = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.layer = SpectralNormalization(Linear(neurons = neurons, use_bias = use_bias, gain = gain))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5936547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiscriminator(tf.keras.layers.Layer):\n",
    "    def __init__(self, disc_for = 'pacman', apply_sn = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.apply_sn = apply_sn\n",
    "        \n",
    "        if disc_for == 'pacman':\n",
    "            self.model = tf.keras.models.Sequential([\n",
    "                self.get_conv(filters = 16, kernel_size = (5, 5), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 32, kernel_size = (5, 5), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 64, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                tf.keras.layers.Reshape((3, 3, 64)),\n",
    "            ])\n",
    "        elif disc_for == 'vizdoom':\n",
    "            self.model = tf.keras.models.Sequential([\n",
    "                self.get_conv(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 128, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 256, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                \n",
    "                self.get_conv(filters = 256, kernel_size = (3, 3), strides = (2, 2), padding = 'valid'),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "                tf.keras.layers.Reshape((3, 3, 256)),\n",
    "            ])\n",
    "            \n",
    "    def get_conv(self, filters, kernel_size, strides, padding):\n",
    "        if self.apply_sn:\n",
    "            return SNConv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        return Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3704291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleFrameDiscriminator(tf.keras.layers.Layer):\n",
    "    def __init__(self, disc_type, disc_for = 'pacman', apply_sn = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.apply_sn = apply_sn\n",
    "        if disc_for == 'pacman':\n",
    "            dim = 64\n",
    "        elif disc_for == 'vizdoom':\n",
    "            dim = 256\n",
    "        else:\n",
    "            raise Exception('')\n",
    "            \n",
    "        if disc_type == 'patch':\n",
    "            padding = (1, 1)\n",
    "            reshape = (3, 3, 1)\n",
    "        else:\n",
    "            padding = 'valid'\n",
    "            reshape = (1, )\n",
    "        \n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            self.get_conv(filters = dim, kernel_size = (2, 2), strides = (1, 1), padding = padding),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            self.get_conv(filters = 1, kernel_size = (1, 1), strides = (2, 2), padding = (1, 1)),\n",
    "            tf.keras.layers.Reshape(reshape)\n",
    "        ])\n",
    "            \n",
    "            \n",
    "    def get_conv(self, filters, kernel_size, strides, padding):\n",
    "        if self.apply_sn:\n",
    "            return SNConv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        return Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "458408fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, apply_sn = True, downsample = True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.apply_sn = apply_sn\n",
    "        \n",
    "        self.main_path = tf.keras.models.Sequential()\n",
    "        self.main_path.add(tf.keras.layers.ReLU())\n",
    "        self.main_path.add(self.get_conv(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "        self.main_path.add(tf.keras.layers.ReLU())\n",
    "        self.main_path.add(self.get_conv(filters = filters, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "        if downsample:\n",
    "            self.main_path.add(tf.keras.layers.AveragePooling2D())\n",
    "            \n",
    "        self.skip_path = tf.keras.models.Sequential()\n",
    "        self.skip_path.add(self.get_conv(filters = filters, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "        if downsample:\n",
    "            self.skip_path.add(tf.keras.layers.AveragePooling2D())\n",
    "        \n",
    "    def get_conv(self, filters, kernel_size, strides, padding):\n",
    "        if self.apply_sn:\n",
    "            return SNConv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        return Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.add(self.main_path(inputs), self.skip_path(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419b2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDiscriminator(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim = 64, r = [1, 2, 4, 8, 16], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        for i in r:\n",
    "            self.model.add(Residual_DBlock(filters = dim ** i))\n",
    "            \n",
    "        self.model.add(tf.keras.layers.ReLU())\n",
    "        \n",
    "        self.linear = SNLinear(neurons = 1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.model(inputs)\n",
    "        out = self.linear(tf.math.reduce_sum(x, axis = [1, 2]))\n",
    "        return out, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db38a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_netD_temporal(dim, window, first_spatial_filter = 2, simple_block = False, \n",
    "                         d_temp_mode = 'sn'):\n",
    "    extractors, finals = [], []\n",
    "    \n",
    "    if simple_block:\n",
    "        net1 = tf.keras.models.Sequential([\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = dim, kernel_size = (2, 2, 2), strides = (1, 1, 1))),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 2, kernel_size = (3, 2, 2), strides = (2, 1, 1))),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "        ])\n",
    "        head1 = tf.keras.models.Sequential([\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (2, 1, 1), strides = (2, 1, 1)))\n",
    "        ])\n",
    "        \n",
    "        extractors.append(net1)\n",
    "        finals.append(head1)\n",
    "        \n",
    "        if window > 6: # 18\n",
    "            net2 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 4, kernel_size = (3, 1, 1), \n",
    "                                                             strides = (2, 1, 1))),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            head2 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (2, 1, 1)))\n",
    "            ])\n",
    "            \n",
    "            extractors.append(net2)\n",
    "            finals.append(head2)\n",
    "            \n",
    "        if window > 18: #32\n",
    "            net3 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 8, kernel_size = (3, 1, 1), \n",
    "                                                             strides = (2, 1, 1))),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            head3 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (3, 1, 1)))\n",
    "            ])\n",
    "            \n",
    "            extractors.append(net3)\n",
    "            finals.append(head3)\n",
    "            \n",
    "    elif 'sn' in d_temp_mode:\n",
    "        net1 = tf.keras.models.Sequential([\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = dim, \n",
    "                                                         kernel_size = (2, first_spatial_filter, first_spatial_filter), \n",
    "                                                         strides = (1, 1, 1))),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 2, kernel_size = (3, 3, 3), strides = (2, 1, 1))),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "        ])\n",
    "        head1 = tf.keras.models.Sequential([\n",
    "            SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (2, 1, 1), strides = (1, 1, 1)))\n",
    "        ])\n",
    "        \n",
    "        extractors.append(net1)\n",
    "        finals.append(head1)\n",
    "        \n",
    "        if window >= 12: # 12\n",
    "            net2 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 4, kernel_size = (3, 1, 1), \n",
    "                                                             strides = (1, 1, 1))),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            head2 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (3, 1, 1)))\n",
    "            ])\n",
    "            \n",
    "            extractors.append(net2)\n",
    "            finals.append(head2)\n",
    "            \n",
    "        if window >= 18: # 18\n",
    "            net3 = tf.keras.models.Sequential([\n",
    "                SpectralNormalization(tf.keras.layers.Conv3D(filters = dim * 8, kernel_size = (3, 1, 1), \n",
    "                                                             strides = (1, 1, 1))),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            if window == 18 or window == 28:\n",
    "                head3 = tf.keras.models.Sequential([\n",
    "                    SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (2, 1, 1), \n",
    "                                                                 strides = (1, 1, 1)))\n",
    "                ])\n",
    "            else:\n",
    "                head3 = tf.keras.models.Sequential([\n",
    "                    SpectralNormalization(tf.keras.layers.Conv3D(filters = 1, kernel_size = (4, 1, 1), \n",
    "                                                                 strides = (2, 1, 1)))\n",
    "                ])\n",
    "            \n",
    "            extractors.append(net3)\n",
    "            finals.append(head3)\n",
    "            \n",
    "    else:\n",
    "        net1 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv3D(filters = dim, kernel_size = (2, 3, 3), strides = (1, 1, 1)),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            tf.keras.layers.Conv3D(filters = dim * 2, kernel_size = (3, 3, 3), strides = (2, 1, 1)),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "        ])\n",
    "        head1 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv3D(filters = 1, kernel_size = (2, 1, 1), strides = (1, 1, 1)),\n",
    "        ])\n",
    "        extractors.append(net1)\n",
    "        finals.append(head1)\n",
    "        \n",
    "        if window >= 12: #12\n",
    "            net2 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Conv3D(filters = dim * 4, kernel_size = (3, 1, 1), strides = (1, 1, 1)),\n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            head2 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Conv3D(filters = 1, kernel_size = (3, 1, 1))\n",
    "            ])\n",
    "            extractors.append(net2)\n",
    "            finals.append(head2)\n",
    "            \n",
    "        if window >= 18: #18\n",
    "            net3 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Conv3D(filters = dim * 8, kernel_size = (2, 1, 1), strides = (2, 1, 1)), \n",
    "                tf.keras.layers.LeakyReLU(alpha = 0.2)\n",
    "            ])\n",
    "            head3 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Conv3D(filters = 1, kernel_size = (3, 1, 1))\n",
    "            ])\n",
    "            \n",
    "            extractors.append(net3)\n",
    "            finals.append(head3)\n",
    "            \n",
    "    return extractors, finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6014a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.models.Model):\n",
    "    def __init__(self, simple_block = False, d_dim = 64, z_dim = 32, action_space = 10, \n",
    "                 temporal_window = 18, temporal_hierarchy = True, \n",
    "                 temporal_hierarchy_epoch = 0, num_steps = 15, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.action_space = action_space\n",
    "        self.z_dim = z_dim\n",
    "        self.temporal_window = temporal_window\n",
    "        self.temporal_hierarchy = temporal_hierarchy\n",
    "        self.temporal_hierarchy_epoch = temporal_hierarchy_epoch\n",
    "        self.num_steps = num_steps\n",
    "        \n",
    "        if simple_block:\n",
    "            self.DS = SimpleDiscriminator()\n",
    "            self.single_frame_discriminator_patch = SingleFrameDiscriminator(disc_type = 'patch')\n",
    "            self.single_frame_discriminator_full = SingleFrameDiscriminator(disc_type = 'full')\n",
    "            \n",
    "        else:\n",
    "            self.DS = ResidualDiscriminator(dim = d_dim)\n",
    "            \n",
    "        \n",
    "        # action-conditioned discriminator\n",
    "        self.action_to_feat = Linear(neurons = 256)\n",
    "        self.to_transition_feature = tf.keras.models.Sequential([\n",
    "            SNConv2D(filters = 256, kernel_size = (4, 4), strides = (1, 1), padding = 'valid'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            tf.keras.layers.Reshape((256, ))\n",
    "        ])\n",
    "        self.action_discriminator = tf.keras.models.Sequential([\n",
    "            SNLinear(neurons = 512),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "            SNLinear(neurons = 1)\n",
    "        ])\n",
    "        self.reconstruction_action_z = tf.keras.models.Sequential([\n",
    "            Linear(neurons = action_space + z_dim)\n",
    "        ])\n",
    "        \n",
    "        # temporal discriminator\n",
    "        self.conv3d, self.conv3d_final = choose_netD_temporal(dim = 64, window = temporal_window, \n",
    "                                                              simple_block = simple_block)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        images, actions, states, warm_up, neg_actions, epoch = inputs\n",
    "        neg_action_predictions, rev_predictions, content_predictions = None, None, []\n",
    "        \n",
    "        batch_size = actions[0].shape[0]\n",
    "        \n",
    "        if warm_up == 0:\n",
    "            warm_up = 1 # even if warm_up is 0, the first screen is from GT\n",
    "            \n",
    "        # run single frame discriminator\n",
    "        gt_states = tf.concat(states[:warm_up], dim = 0)\n",
    "        single_frame_predictions_patch = None\n",
    "        if self.simple_block:\n",
    "            tmp_gt = self.DS(gt_states)\n",
    "            tmp_gen = self.DS(images)\n",
    "            tmp_features = tf.concat([tmp_gt, tmp_gen], axis = 0)\n",
    "            single_frame_predictions_patch = self.single_frame_discriminator_patch(tmp_gen)\n",
    "            single_frame_predictions_full = self.single_frame_discriminator_full(tmp_gen)\n",
    "        else:\n",
    "            single_frame_predictions_full, tmp_features = self.DS(tf.concat([gt_states, images], axis = 0))\n",
    "            single_frame_predictions_full = single_frame_predictions_full[warm_up*batch_size:]\n",
    "            \n",
    "        frame_features = tmp_features[warm_up*batch_size:]\n",
    "        \n",
    "        # run action-conditioned discriminator and reconstruct action, z\n",
    "        prev_frames = tf.concat([tmp_features[:warm_up * batch_size],\n",
    "                                 tmp_features[(warm_up + warm_up - 1) * batch_size:-batch_size]], axis = 0)\n",
    "        \n",
    "        transition_features = self.to_transition_feature(tf.concat([prev_frames, frame_features], axis = -1))\n",
    "        action_features = self.action_to_feat(tf.concat(actions[:-1], axis = 0))\n",
    "        action_predictions = self.action_discriminator(tf.concat([action_features, transition_features], axis = -1))\n",
    "        \n",
    "        if neg_actions is not None:\n",
    "            neg_action_features = self.action_to_feat(tf.concat(neg_actions[:-1], axis = 0))\n",
    "            neg_action_predictions = self.action_discriminator(\n",
    "                tf.concat([neg_action_features, transition_features], axis = -1)\n",
    "            )\n",
    "            \n",
    "        action_z_recon = self.reconstruction_action_z(transition_features)\n",
    "        action_recon = action_z_recon[:, :self.action_space]\n",
    "        z_recon = action_z_recon[:, self.action_space:self.action_space+self.z_dim]\n",
    "        \n",
    "        # run temporal discriminator\n",
    "        if self.temporal_hierarchy and self.num_steps > 4:\n",
    "            new_l = []\n",
    "            temporal_predictions = []\n",
    "            for entry in tf.split(tmp_features[:warm_up * batch_size], warm_up, axis = 0):\n",
    "                new_l.append(entry)\n",
    "            for entry in tf.split(tmp_features[(warm_up*2 - 1)*batch_size:], warm_up, axis = 0):\n",
    "                new_l.append(entry)\n",
    "                \n",
    "            window_size = len(new_l)\n",
    "            start = np.random.randint(0, len(new_l) - window_size + 1)\n",
    "            stacked = tf.stack(new_l[start:start+window_size], axis = 1)\n",
    "            \n",
    "            aa = self.conv3d[0](stacked)\n",
    "            a_out = self.conv3d_final[0](aa)\n",
    "            temporal_predictions.append(tf.reshape(a_out, (batch_size, -1)))\n",
    "            \n",
    "            if self.temporal_window >= 12 and epoch >= self.temporal_hierarchy_epoch:\n",
    "                bb = self.conv3d[1](aa)\n",
    "                b_out = self.conv3d_final[1](bb)\n",
    "                temporal_predictions.append(tf.reshape(b_out, (batch_size, -1)))\n",
    "                \n",
    "            if self.temporal_window >= 18 and epoch >= self.temporal_hierarchy_epoch:\n",
    "                cc = self.conv3d[2](bb)\n",
    "                c_out = self.conv3d_final[2](cc)\n",
    "                temporal_predictions.append(tf.reshape(c_out, (batch_size, - 1)))\n",
    "                \n",
    "        d_out = {}\n",
    "        ddout['disc_features'] = frame_features[:(len(states)-1)*batch_size]\n",
    "        dout['action_predictions'] = action_predictions\n",
    "        dout['single_frame_predictions_all'] = single_frame_predictions_full\n",
    "        dout['content_predictions'] = temporal_predictions\n",
    "        dout['neg_action_predictions'] = neg_action_predictions\n",
    "        dout['action_recon'] = action_recon\n",
    "        dout['z_recon'] = z_recon\n",
    "        dout['single_frame_predictions_patch'] = single_frame_predictions_patch\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da7630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
