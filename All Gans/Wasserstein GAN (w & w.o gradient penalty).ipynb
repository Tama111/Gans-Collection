{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3a9075",
   "metadata": {},
   "source": [
    "# Wasserstein Gan (w & w/o gradient penalty)\n",
    "\n",
    "This is an attempt to re-implement the paper WGAN & WGAN-GP\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1701.07875v3.pdf, https://arxiv.org/pdf/1704.00028v3.pdf\n",
    "\n",
    "Other Resources: \n",
    "* https://github.com/igul222/improved_wgan_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3d18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ede262",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "channels = 1\n",
    "batch_size = 256\n",
    "latent_dim = 100\n",
    "(x_train, x_label), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cc5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data, labels, c_num = -1):\n",
    "        \n",
    "        if c_num != -1:\n",
    "            data = data[np.where(x_label == c_num)]\n",
    "            \n",
    "        x_train = ((data/255)*2)-1\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_size, img_size, channels)\n",
    "        x_train = tf.cast(x_train, tf.float32)\n",
    "        x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(batch_size)\n",
    "        \n",
    "        return x_train\n",
    "    \n",
    "data = load_dataset(x_train, x_label, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81c06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipConstraint(tf.keras.constraints.Constraint):\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "        \n",
    "    def __call__(self, weights):\n",
    "        return tf.keras.backend.clip(weights, self.clip_value[0], self.clip_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a194244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dim = latent_dim):\n",
    "    init = tf.random_normal_initializer(0.0, 0.02)\n",
    "    inp = tf.keras.layers.Input(shape = (dim), dtype = tf.float32, name = 'Generator_input')\n",
    "    \n",
    "    x = tf.keras.layers.Dense(7 * 7 *128, kernel_initializer = init)(inp)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    x = tf.keras.layers.Reshape((7, 7, 128))(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (4, 4), strides = (2, 2), \n",
    "                                        padding = 'same', kernel_initializer = init)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (4, 4), strides = (2, 2), \n",
    "                                        padding = 'same', kernel_initializer = init)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters = 1, kernel_size = (7, 7), strides = (1, 1), padding = 'same', \n",
    "               kernel_initializer = init)(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inp, x, name = 'Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6158fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def critic(img_size = img_size, channels = channels, clip_range = None):\n",
    "    init = tf.random_normal_initializer(0.0, 1.0)\n",
    "    inp = tf.keras.layers.Input(shape = (img_size, img_size, channels), dtype = tf.float32, name = 'Critic_input')\n",
    "\n",
    "    if clip_range is not None:\n",
    "        clip = ClipConstraint(clip_range)\n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                                   kernel_initializer = init, kernel_constraint = clip)(inp)\n",
    "    else:\n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                                   kernel_initializer = init)(inp)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "\n",
    "    if clip_range is not None:\n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                                   kernel_initializer = init, kernel_constraint = clip)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', \n",
    "                                   kernel_initializer = init)(x)\n",
    "        \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units = 1)(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inp, x, name = 'Critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830e3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01a3d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(crit_gen_out):\n",
    "    return -tf.math.reduce_mean(crit_gen_out)\n",
    "\n",
    "def gradient_penalty(crit, real, gen, gp_weight = 10):\n",
    "    \n",
    "    epsilon = tf.random.uniform(shape = (real.shape[0], 1, 1, 1), minval = 0.0, maxval = 1.0)\n",
    "    interpolated = ((1 - epsilon) * real) + (epsilon * gen)\n",
    "    \n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        out = crit(interpolated)\n",
    "        \n",
    "    grads = gp_tape.gradient(out, [interpolated])[0]\n",
    "    norm = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(grads), axis = [1, 2, 3], keepdims = True))\n",
    "    gp = tf.math.reduce_mean(tf.square(norm - 1))\n",
    "    return gp * gp_weight\n",
    "\n",
    "def critic_loss(crit_real_out, crit_gen_out):\n",
    "    return tf.math.reduce_mean(crit_gen_out) - tf.math.reduce_mean(crit_real_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7473194",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_opt_gp = tf.keras.optimizers.Adam(learning_rate = 1e-4, beta_1 = 0, beta_2 = 0.9)\n",
    "crit_opt = tf.keras.optimizers.RMSprop(learning_rate = 5e-5)\n",
    "\n",
    "gen_opt_gp = tf.keras.optimizers.Adam(learning_rate = 1e-4, beta_1 = 0, beta_2 = 0.9)\n",
    "gen_opt = tf.keras.optimizers.RMSprop(learning_rate = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6432ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img, n_critics = 5, apply_gp = True):\n",
    "    \n",
    "    noise = tf.random.normal((img.shape[0], latent_dim))\n",
    "    for _ in range(n_critics):\n",
    "        with tf.GradientTape() as crit_tape:\n",
    "            gen_out = gen(noise, training = True)\n",
    "            \n",
    "            crit_real_out = crit(img, training = True)\n",
    "            crit_gen_out  = crit(gen_out, training = True)\n",
    "            \n",
    "            crit_loss = critic_loss(crit_real_out, crit_gen_out)\n",
    "            if apply_gp:\n",
    "                crit_loss += gradient_penalty(crit, img, gen_out)\n",
    "                \n",
    "        crit_grads = crit_tape.gradient(crit_loss, crit.trainable_variables)\n",
    "        if apply_gp:\n",
    "            crit_opt_gp.apply_gradients(zip(crit_grads, crit.trainable_variables))\n",
    "        else:\n",
    "            crit_opt.apply_gradients(zip(crit_grads, crit.trainable_variables))\n",
    "            \n",
    "    \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        gen_out = gen(noise, training = True)\n",
    "        crit_gen_out = crit(gen_out, training = True)\n",
    "        gen_loss = generator_loss(crit_gen_out)\n",
    "        \n",
    "    gen_grads = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    if apply_gp:\n",
    "        gen_opt_gp.apply_gradients(zip(gen_grads, gen.trainable_variables))\n",
    "    else:\n",
    "        gen_opt.apply_gradients(zip(gen_grads, gen.trainable_variables))\n",
    "        \n",
    "    return crit_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "193d4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, epochs = 3):\n",
    "    for e in range(epochs):\n",
    "        print(f'Epoch {e} Starts')\n",
    "        for img in data:\n",
    "            crit_loss, gen_loss = train_step(img, n_critics = 5, apply_gp = True)\n",
    "            print('.', end='')\n",
    "\n",
    "        print(f'\\nGenerator Loss : {gen_loss} \\t Critic Loss : {crit_loss}')\n",
    "        print(f'Epoch {e} Ends\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e619f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Starts\n",
      ".......................\n",
      "Generator Loss : -5.056664943695068 \t Critic Loss : 5.805514335632324\n",
      "Epoch 0 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1 Starts\n",
      ".......................\n",
      "Generator Loss : -9.912121772766113 \t Critic Loss : 5.832494735717773\n",
      "Epoch 1 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2 Starts\n",
      ".......................\n",
      "Generator Loss : -12.92257022857666 \t Critic Loss : 8.173518180847168\n",
      "Epoch 2 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3 Starts\n",
      ".......................\n",
      "Generator Loss : -10.856505393981934 \t Critic Loss : 8.49040412902832\n",
      "Epoch 3 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4 Starts\n",
      ".......................\n",
      "Generator Loss : -7.461540699005127 \t Critic Loss : 7.467710971832275\n",
      "Epoch 4 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5 Starts\n",
      ".......................\n",
      "Generator Loss : -8.229317665100098 \t Critic Loss : 7.972630977630615\n",
      "Epoch 5 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6 Starts\n",
      ".......................\n",
      "Generator Loss : -9.519908905029297 \t Critic Loss : 7.111380100250244\n",
      "Epoch 6 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7 Starts\n",
      ".......................\n",
      "Generator Loss : -10.872139930725098 \t Critic Loss : 7.150426864624023\n",
      "Epoch 7 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8 Starts\n",
      ".......................\n",
      "Generator Loss : -10.192315101623535 \t Critic Loss : 6.712001323699951\n",
      "Epoch 8 Ends\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9 Starts\n",
      ".......................\n",
      "Generator Loss : -11.227761268615723 \t Critic Loss : 6.31659460067749\n",
      "Epoch 9 Ends\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen = generator()\n",
    "# crit = critic(clip_range = (-0.01, 0.01))\n",
    "crit = critic(clip_range = None)\n",
    "train(data, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54d4cd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(((gen(tf.random.normal((1, 100)))[0]+1)*127.5).numpy()\\\n",
    "           .astype('uint8'), cmap = 'binary_r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
